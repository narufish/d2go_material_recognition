module __torch__.detectron2.export.flatten.___torch_mangle_6662.TracingAdapter {
  parameters {
  }
  attributes {
    training = True
    _is_full_backward_hook = None
    model = <__torch__.d2go.modeling.meta_arch.rcnn.___torch_mangle_6661.D2RCNNInferenceWrapper object at 0000018BE9FEA670>
  }
  methods {
    method forward {
      graph(%self.1 : __torch__.detectron2.export.flatten.___torch_mangle_6662.TracingAdapter,
            %4225 : Float(3, 224, 299, strides=[1, 897, 3], requires_grad=0, device=cpu)):
        %model : __torch__.d2go.modeling.meta_arch.rcnn.___torch_mangle_6661.D2RCNNInferenceWrapper = prim::GetAttr[name="model"](%self.1)
        %11416 : (Tensor, Tensor, Tensor, Tensor, Tensor) = prim::CallMethod[name="forward"](%model, %4225)
        %11411 : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu), %11412 : Long(1, strides=[2], requires_grad=0, device=cpu), %11413 : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu), %11414 : Float(1, strides=[1], requires_grad=0, device=cpu), %11415 : Long(2, strides=[1], requires_grad=0, device=cpu) = prim::TupleUnpack(%11416)
        %8916 : (Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu), Long(1, strides=[2], requires_grad=0, device=cpu), Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu), Float(1, strides=[1], requires_grad=0, device=cpu), Long(2, strides=[1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%11411, %11412, %11413, %11414, %11415)
        return (%8916)
  
    }
  }
  submodules {
    module __torch__.d2go.modeling.meta_arch.rcnn.___torch_mangle_6661.D2RCNNInferenceWrapper {
      parameters {
      }
      attributes {
        training = True
        _is_full_backward_hook = None
        model = <__torch__.d2go.modeling.meta_arch.rcnn.___torch_mangle_6660.GeneralizedRCNN object at 0000018BE9FEA170>
      }
      methods {
        method forward {
          graph(%self.3 : __torch__.d2go.modeling.meta_arch.rcnn.___torch_mangle_6661.D2RCNNInferenceWrapper,
                %13 : Float(3, 224, 299, strides=[1, 897, 3], requires_grad=0, device=cpu)):
            %model.9 : __torch__.d2go.modeling.meta_arch.rcnn.___torch_mangle_6660.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %roi_heads : __torch__.detectron2.modeling.roi_heads.roi_heads.___torch_mangle_6659.StandardROIHeads = prim::GetAttr[name="roi_heads"](%model.9)
            %model.7 : __torch__.d2go.modeling.meta_arch.rcnn.___torch_mangle_6660.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %proposal_generator : __torch__.detectron2.modeling.proposal_generator.rpn.___torch_mangle_6423.RPN = prim::GetAttr[name="proposal_generator"](%model.7)
            %model.5 : __torch__.d2go.modeling.meta_arch.rcnn.___torch_mangle_6660.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %backbone : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6287.QuantWrapSubClass = prim::GetAttr[name="backbone"](%model.5)
            %model.3 : __torch__.d2go.modeling.meta_arch.rcnn.___torch_mangle_6660.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %pixel_std : Tensor = prim::GetAttr[name="pixel_std"](%model.3)
            %model.1 : __torch__.d2go.modeling.meta_arch.rcnn.___torch_mangle_6660.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %pixel_mean : Tensor = prim::GetAttr[name="pixel_mean"](%model.1)
            %11 : Function = prim::Constant[name="move_device_like"](), scope: __module.model
            %x.1 : Tensor = prim::CallFunction(%11, %13, %pixel_mean), scope: __module.model
            %14 : int = prim::Constant[value=1](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\meta_arch\rcnn.py:228:0
            %15 : Float(3, 224, 299, strides=[1, 897, 3], requires_grad=0, device=cpu) = aten::sub(%x.1, %pixel_mean, %14), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\meta_arch\rcnn.py:228:0
            %t : Float(3, 224, 299, strides=[1, 897, 3], requires_grad=0, device=cpu) = aten::div(%15, %pixel_std), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\meta_arch\rcnn.py:228:0
            %39 : int = prim::Constant[value=1](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:87:0
            %40 : int = aten::size(%t, %39), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:87:0
            %41 : Long(device=cpu) = prim::NumToTensor(%40), scope: __module.model
            %51 : int = prim::Constant[value=2](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:87:0
            %52 : int = aten::size(%t, %51), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:87:0
            %53 : Long(device=cpu) = prim::NumToTensor(%52), scope: __module.model
            %54 : Tensor[] = prim::ListConstruct(%41, %53), scope: __module.model
            %55 : int = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\wrappers.py:32:0
            %image_size : Long(2, strides=[1], requires_grad=0, device=cpu) = aten::stack(%54, %55), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\wrappers.py:32:0
            %57 : Tensor[] = prim::ListConstruct(%image_size), scope: __module.model
            %58 : int = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:89:0
            %59 : Long(1, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::stack(%57, %58), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:89:0
            %60 : int = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:89:0
            %61 : bool = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:89:0
            %max_size : Long(2, strides=[1], requires_grad=0, device=cpu), %63 : Long(2, strides=[1], requires_grad=0, device=cpu) = aten::max(%59, %60, %61), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:89:0
            %64 : int = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %65 : int = prim::Constant[value=-1](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %66 : Long(requires_grad=0, device=cpu) = aten::select(%max_size, %64, %65), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %67 : int = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %68 : int = prim::Constant[value=1](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %69 : Long(requires_grad=0, device=cpu) = aten::select(%image_size, %67, %68), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %70 : int = prim::Constant[value=1](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %71 : Long(requires_grad=0, device=cpu) = aten::sub(%66, %69, %70), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %72 : int = aten::Int(%71), scope: __module.model
            %73 : int = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %74 : int = prim::Constant[value=-2](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %75 : Long(requires_grad=0, device=cpu) = aten::select(%max_size, %73, %74), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %76 : int = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %77 : int = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %78 : Long(requires_grad=0, device=cpu) = aten::select(%image_size, %76, %77), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %79 : int = prim::Constant[value=1](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %80 : Long(requires_grad=0, device=cpu) = aten::sub(%75, %78, %79), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:114:0
            %81 : int = aten::Int(%80), scope: __module.model
            %82 : int = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:115:0
            %83 : int = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:115:0
            %84 : int[] = prim::ListConstruct(%82, %72, %83, %81), scope: __module.model
            %85 : str = prim::Constant[value="constant"](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:115:0
            %86 : float = prim::Constant[value=0.](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:115:0
            %87 : Float(3, 224, 299, strides=[1, 897, 3], requires_grad=0, device=cpu) = aten::pad(%t, %84, %85, %86), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:115:0
            %88 : int = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:115:0
            %batched_imgs : Float(1, 3, 224, 299, strides=[3, 1, 897, 3], requires_grad=0, device=cpu) = aten::unsqueeze_(%87, %88), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:115:0
            %90 : int = prim::Constant[value=0](), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:129:0
            %X.1 : Float(1, 3, 224, 299, strides=[200928, 66976, 299, 1], requires_grad=0, device=cpu) = aten::contiguous(%batched_imgs, %90), scope: __module.model # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\image_list.py:129:0
            %100 : Tensor = prim::CallMethod[name="forward"](%backbone, %X.1)
            %101 : Tensor = prim::CallMethod[name="forward"](%proposal_generator, %100, %image_size)
            %102 : (Tensor, Tensor, Tensor, Tensor) = prim::CallMethod[name="forward"](%roi_heads, %100, %101, %image_size)
            %95 : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu), %96 : Long(1, strides=[2], requires_grad=0, device=cpu), %97 : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu), %98 : Float(1, strides=[1], requires_grad=0, device=cpu) = prim::TupleUnpack(%102)
            %99 : (Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu), Long(1, strides=[2], requires_grad=0, device=cpu), Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu), Float(1, strides=[1], requires_grad=0, device=cpu), Long(2, strides=[1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%95, %96, %97, %98, %image_size)
            return (%99)
      
        }
      }
      submodules {
        module __torch__.d2go.modeling.meta_arch.rcnn.___torch_mangle_6660.GeneralizedRCNN {
          parameters {
          }
          attributes {
            pixel_mean = ...
            pixel_std = ...
            training = False
            _is_full_backward_hook = None
            backbone = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6287.QuantWrapSubClass object at 0000018BEA02DAE0>
            proposal_generator = <__torch__.detectron2.modeling.proposal_generator.rpn.___torch_mangle_6423.RPN object at 0000018BEACBB070>
            roi_heads = <__torch__.detectron2.modeling.roi_heads.roi_heads.___torch_mangle_6659.StandardROIHeads object at 0000018BE9FE9970>
          }
          methods {
          }
          submodules {
            module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6287.QuantWrapSubClass {
              parameters {
              }
              attributes {
                training = False
                _is_full_backward_hook = None
                body = <__torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6277.FBNetV2Backbone object at 0000018BEA02EA60>
                quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6280.QuantStubNested object at 0000018BEA02EDE0>
                dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6286.QuantStubNested object at 0000018BEA02D8E0>
              }
              methods {
                method forward {
                  graph(%self.5 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6287.QuantWrapSubClass,
                        %X.1 : Float(1, 3, 224, 299, strides=[200928, 66976, 299, 1], requires_grad=0, device=cpu)):
                    %dequant_stubs.1 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6286.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.5)
                    %body : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6277.FBNetV2Backbone = prim::GetAttr[name="body"](%self.5)
                    %quant_stubs.1 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6280.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.5)
                    %12 : Tensor = prim::CallMethod[name="forward"](%quant_stubs.1, %X.1)
                    %13 : (Tensor, Tensor, Tensor, Tensor) = prim::CallMethod[name="forward"](%body, %12)
                    %7 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu), %8 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu), %9 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu), %10 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = prim::TupleUnpack(%13)
                    %14 : Tensor = prim::CallMethod[name="forward"](%dequant_stubs.1, %7, %8, %9, %10)
                    return (%14)
              
                }
              }
              submodules {
                module __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6277.FBNetV2Backbone {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    trunk0 = <__torch__.torch.nn.modules.container.___torch_mangle_5941.Sequential object at 0000018BE6D4FBF0>
                    trunk1 = <__torch__.torch.nn.modules.container.___torch_mangle_5991.Sequential object at 0000018BE5FE72F0>
                    trunk2 = <__torch__.torch.nn.modules.container.___torch_mangle_6085.Sequential object at 0000018BE8732C60>
                    trunk3 = <__torch__.torch.nn.modules.container.___torch_mangle_6276.Sequential object at 0000018BEA02E7E0>
                  }
                  methods {
                    method forward {
                      graph(%self.11 : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6277.FBNetV2Backbone,
                            %1 : QUInt8(1, 3, 224, 299, strides=[200928, 66976, 299, 1], requires_grad=0, device=cpu)):
                        %trunk3 : __torch__.torch.nn.modules.container.___torch_mangle_6276.Sequential = prim::GetAttr[name="trunk3"](%self.11)
                        %trunk2 : __torch__.torch.nn.modules.container.___torch_mangle_6085.Sequential = prim::GetAttr[name="trunk2"](%self.11)
                        %trunk1 : __torch__.torch.nn.modules.container.___torch_mangle_5991.Sequential = prim::GetAttr[name="trunk1"](%self.11)
                        %trunk0 : __torch__.torch.nn.modules.container.___torch_mangle_5941.Sequential = prim::GetAttr[name="trunk0"](%self.11)
                        %11 : Tensor = prim::CallMethod[name="forward"](%trunk0, %1)
                        %12 : Tensor = prim::CallMethod[name="forward"](%trunk1, %11)
                        %13 : Tensor = prim::CallMethod[name="forward"](%trunk2, %12)
                        %14 : Tensor = prim::CallMethod[name="forward"](%trunk3, %13)
                        %10 : (QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu), QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu), QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu), QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)) = prim::TupleConstruct(%11, %12, %13, %14)
                        return (%10)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.___torch_mangle_5941.Sequential {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        fbnetv2_0_0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5922.ConvBNRelu object at 0000018BE6D40370>
                        fbnetv2_0_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5931.IRFBlock object at 0000018BE6D46BF0>
                        fbnetv2_0_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5940.IRFBlock object at 0000018BE6D4E170>
                      }
                      methods {
                        method forward {
                          graph(%self.13 : __torch__.torch.nn.modules.container.___torch_mangle_5941.Sequential,
                                %1 : QUInt8(1, 3, 224, 299, strides=[200928, 66976, 299, 1], requires_grad=0, device=cpu)):
                            %fbnetv2_0_2.1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5940.IRFBlock = prim::GetAttr[name="fbnetv2_0_2"](%self.13)
                            %fbnetv2_0_1.1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5931.IRFBlock = prim::GetAttr[name="fbnetv2_0_1"](%self.13)
                            %fbnetv2_0_0.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5922.ConvBNRelu = prim::GetAttr[name="fbnetv2_0_0"](%self.13)
                            %8 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_0.1, %1)
                            %9 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_1.1, %8)
                            %10 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_2.1, %9)
                            return (%10)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5922.ConvBNRelu {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5919.ConvReLU2d object at 0000018BE6D3F9F0>
                            bn = <__torch__.torch.nn.modules.linear.___torch_mangle_5920.Identity object at 0000018BE6D3E170>
                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_5921.Identity object at 0000018BE6D3E570>
                          }
                          methods {
                            method forward {
                              graph(%self.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5922.ConvBNRelu,
                                    %1 : QUInt8(1, 3, 224, 299, strides=[200928, 66976, 299, 1], requires_grad=0, device=cpu)):
                                %relu.1 : __torch__.torch.nn.modules.linear.___torch_mangle_5921.Identity = prim::GetAttr[name="relu"](%self.15)
                                %bn.1 : __torch__.torch.nn.modules.linear.___torch_mangle_5920.Identity = prim::GetAttr[name="bn"](%self.15)
                                %conv.1 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5919.ConvReLU2d = prim::GetAttr[name="conv"](%self.15)
                                %8 : Tensor = prim::CallMethod[name="forward"](%conv.1, %1)
                                %9 : NoneType = prim::CallMethod[name="forward"](%bn.1)
                                %10 : NoneType = prim::CallMethod[name="forward"](%relu.1)
                                return (%8)
                          
                            }
                          }
                          submodules {
                            module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5919.ConvReLU2d {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                                in_channels = 3
                                out_channels = 16
                                kernel_size = (3, 3)
                                stride = (2, 2)
                                padding = (1, 1)
                                dilation = (1, 1)
                                transposed = False
                                output_padding = (0, 0)
                                groups = 1
                                padding_mode = zeros
                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D39BF0>
                                scale = 0.11331272125244141
                                zero_point = 0
                              }
                              methods {
                                method __getstate__ {
                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5919.ConvReLU2d):
                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                    %training : bool = prim::GetAttr[name="training"](%self)
                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                    return (%19)
                              
                                }
                                method __setstate__ {
                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5919.ConvReLU2d,
                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                    %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                    %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                    %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                    %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                    %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                    %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                    %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                    %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                    %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                    %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                    %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                    %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                    %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                    %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                    %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                    %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                     = prim::SetAttr[name="stride"](%self, %13)
                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                     = prim::SetAttr[name="padding"](%self, %16)
                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                     = prim::SetAttr[name="dilation"](%self, %19)
                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                     = prim::SetAttr[name="transposed"](%self, %22)
                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                     = prim::SetAttr[name="groups"](%self, %28)
                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                     = prim::SetAttr[name="scale"](%self, %41)
                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                     = prim::SetAttr[name="training"](%self, %47)
                                    return (%48)
                              
                                }
                                method _weight_bias {
                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5919.ConvReLU2d):
                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                    return (%2)
                              
                                }
                                method set_weight_bias {
                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5919.ConvReLU2d,
                                        %w.1 : Tensor,
                                        %b.1 : Tensor?):
                                    %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                    %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                    %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                     = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                      block0():
                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                        -> ()
                                      block1():
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                        -> ()
                                    return (%37)
                              
                                }
                                method forward {
                                  graph(%self.17 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5919.ConvReLU2d,
                                        %1 : QUInt8(1, 3, 224, 299, strides=[200928, 66976, 299, 1], requires_grad=0, device=cpu)):
                                    %_packed_params.1 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.17)
                                    %15 : float = prim::Constant[value=0.11331272125244141](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.3 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.1, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    return (%input.3)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.torch.nn.modules.linear.___torch_mangle_5920.Identity {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.19 : __torch__.torch.nn.modules.linear.___torch_mangle_5920.Identity):
                                    %1 : NoneType = prim::Constant()
                                    return (%1)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.torch.nn.modules.linear.___torch_mangle_5921.Identity {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.21 : __torch__.torch.nn.modules.linear.___torch_mangle_5921.Identity):
                                    %1 : NoneType = prim::Constant()
                                    return (%1)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5931.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5924.ConvBNRelu object at 0000018BE6D416F0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5927.ConvBNRelu object at 0000018BE6D47E70>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5930.TorchAdd object at 0000018BE6D46570>
                          }
                          methods {
                            method forward {
                              graph(%self.23 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5931.IRFBlock,
                                    %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                %res_conn.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5930.TorchAdd = prim::GetAttr[name="res_conn"](%self.23)
                                %pwl.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5927.ConvBNRelu = prim::GetAttr[name="pwl"](%self.23)
                                %dw.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5924.ConvBNRelu = prim::GetAttr[name="dw"](%self.23)
                                %8 : Tensor = prim::CallMethod[name="forward"](%dw.9, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%pwl.1, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%res_conn.1, %9, %1)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5924.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5923.Conv2d object at 0000018BE6D40470>
                              }
                              methods {
                                method forward {
                                  graph(%self.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5924.ConvBNRelu,
                                        %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                    %conv.3 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5923.Conv2d = prim::GetAttr[name="conv"](%self.25)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.3, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5923.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 16
                                    out_channels = 16
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 16
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D38E70>
                                    scale = 0.080030634999275208
                                    zero_point = 51
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5923.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5923.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5923.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5923.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.27 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5923.Conv2d,
                                            %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                        %_packed_params.3 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.27)
                                        %15 : float = prim::Constant[value=0.080030634999275208](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=51](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.5 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.3, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.5)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5927.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5925.Conv2d object at 0000018BE6D408F0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_5926.Identity object at 0000018BE6D42170>
                              }
                              methods {
                                method forward {
                                  graph(%self.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5927.ConvBNRelu,
                                        %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                    %bn.3 : __torch__.torch.nn.modules.linear.___torch_mangle_5926.Identity = prim::GetAttr[name="bn"](%self.29)
                                    %conv.5 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5925.Conv2d = prim::GetAttr[name="conv"](%self.29)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.5, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.3)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5925.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 16
                                    out_channels = 16
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D39070>
                                    scale = 0.30488735437393188
                                    zero_point = 66
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5925.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5925.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5925.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5925.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.31 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5925.Conv2d,
                                            %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                        %_packed_params.5 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.31)
                                        %15 : float = prim::Constant[value=0.30488735437393188](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.5, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5926.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.33 : __torch__.torch.nn.modules.linear.___torch_mangle_5926.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5930.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5929.QFunctional object at 0000018BE6D480F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5930.TorchAdd,
                                        %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                    %add_func.1 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5929.QFunctional = prim::GetAttr[name="add_func"](%self.35)
                                    %activation_post_process.1 : __torch__.torch.nn.modules.linear.___torch_mangle_5928.Identity = prim::GetAttr[name="activation_post_process"](%add_func.1)
                                    %5 : float = prim::Constant[value=0.30115282535552979](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.7 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.1)
                                    return (%input.7)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5929.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_5928.Identity object at 0000018BE6D47EF0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_5928.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.37 : __torch__.torch.nn.modules.linear.___torch_mangle_5928.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5940.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5933.ConvBNRelu object at 0000018BE6D48470>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5936.ConvBNRelu object at 0000018BE6D4B6F0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5939.TorchAdd object at 0000018BE6D4CE70>
                          }
                          methods {
                            method forward {
                              graph(%self.39 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5940.IRFBlock,
                                    %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                %res_conn.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5939.TorchAdd = prim::GetAttr[name="res_conn"](%self.39)
                                %pwl.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5936.ConvBNRelu = prim::GetAttr[name="pwl"](%self.39)
                                %dw.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5933.ConvBNRelu = prim::GetAttr[name="dw"](%self.39)
                                %8 : Tensor = prim::CallMethod[name="forward"](%dw.11, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%pwl.3, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%res_conn.3, %9, %1)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5933.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5932.Conv2d object at 0000018BE6D492F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.41 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5933.ConvBNRelu,
                                        %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                    %conv.7 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5932.Conv2d = prim::GetAttr[name="conv"](%self.41)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.7, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5932.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 16
                                    out_channels = 16
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 16
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D38C70>
                                    scale = 0.10007268935441971
                                    zero_point = 62
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5932.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5932.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5932.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5932.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.43 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5932.Conv2d,
                                            %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                        %_packed_params.7 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.43)
                                        %15 : float = prim::Constant[value=0.10007268935441971](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_2/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.dw/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_2/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.dw/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.9 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.7, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_2/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.dw/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.9)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5936.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5934.Conv2d object at 0000018BE6D48E70>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_5935.Identity object at 0000018BE6D4ABF0>
                              }
                              methods {
                                method forward {
                                  graph(%self.45 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5936.ConvBNRelu,
                                        %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                    %bn.5 : __torch__.torch.nn.modules.linear.___torch_mangle_5935.Identity = prim::GetAttr[name="bn"](%self.45)
                                    %conv.9 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5934.Conv2d = prim::GetAttr[name="conv"](%self.45)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.9, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.5)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5934.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 16
                                    out_channels = 16
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D390F0>
                                    scale = 0.34575763344764709
                                    zero_point = 66
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5934.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5934.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5934.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5934.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.47 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5934.Conv2d,
                                            %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                        %_packed_params.9 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.47)
                                        %15 : float = prim::Constant[value=0.34575763344764709](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_2/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.pwl/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_2/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.pwl/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.9, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_2/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.pwl/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5935.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.49 : __torch__.torch.nn.modules.linear.___torch_mangle_5935.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5939.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5938.QFunctional object at 0000018BE6D4CCF0>
                              }
                              methods {
                                method forward {
                                  graph(%self.51 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5939.TorchAdd,
                                        %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                    %add_func.3 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5938.QFunctional = prim::GetAttr[name="add_func"](%self.51)
                                    %activation_post_process.3 : __torch__.torch.nn.modules.linear.___torch_mangle_5937.Identity = prim::GetAttr[name="activation_post_process"](%add_func.3)
                                    %5 : float = prim::Constant[value=0.37972483038902283](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_2/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_2/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.11 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_2/__module.model.model.backbone.body.trunk0.fbnetv2_0_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.3)
                                    return (%input.11)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5938.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_5937.Identity object at 0000018BE6D4DBF0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_5937.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.53 : __torch__.torch.nn.modules.linear.___torch_mangle_5937.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_5991.Sequential {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        fbnetv2_1_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5951.IRFBlock object at 0000018BE6D576F0>
                        fbnetv2_1_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5964.IRFBlock object at 0000018BE5FD44F0>
                        fbnetv2_1_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5977.IRFBlock object at 0000018BE5FDB6F0>
                        fbnetv2_1_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5990.IRFBlock object at 0000018BE5FE5770>
                      }
                      methods {
                        method forward {
                          graph(%self.55 : __torch__.torch.nn.modules.container.___torch_mangle_5991.Sequential,
                                %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                            %fbnetv2_1_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5990.IRFBlock = prim::GetAttr[name="fbnetv2_1_3"](%self.55)
                            %fbnetv2_1_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5977.IRFBlock = prim::GetAttr[name="fbnetv2_1_2"](%self.55)
                            %fbnetv2_1_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5964.IRFBlock = prim::GetAttr[name="fbnetv2_1_1"](%self.55)
                            %fbnetv2_1_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5951.IRFBlock = prim::GetAttr[name="fbnetv2_1_0"](%self.55)
                            %10 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_1_0, %1)
                            %11 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_1_1, %10)
                            %12 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_1_2, %11)
                            %13 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_1_3, %12)
                            return (%13)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5951.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5945.ConvBNRelu object at 0000018BE6D51C70>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5947.ConvBNRelu object at 0000018BE6D51DF0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5950.ConvBNRelu object at 0000018BE6D55AF0>
                          }
                          methods {
                            method forward {
                              graph(%self.57 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5951.IRFBlock,
                                    %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                %pwl.5 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5950.ConvBNRelu = prim::GetAttr[name="pwl"](%self.57)
                                %dw.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5947.ConvBNRelu = prim::GetAttr[name="dw"](%self.57)
                                %pw.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5945.ConvBNRelu = prim::GetAttr[name="pw"](%self.57)
                                %8 : Tensor = prim::CallMethod[name="forward"](%pw.1, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%dw.13, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pwl.5, %9)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5945.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5942.ConvReLU2d object at 0000018BE6D4FE70>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_5943.Identity object at 0000018BE6D4FF70>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_5944.Identity object at 0000018BE6D517F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.59 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5945.ConvBNRelu,
                                        %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                    %relu.3 : __torch__.torch.nn.modules.linear.___torch_mangle_5944.Identity = prim::GetAttr[name="relu"](%self.59)
                                    %bn.7 : __torch__.torch.nn.modules.linear.___torch_mangle_5943.Identity = prim::GetAttr[name="bn"](%self.59)
                                    %conv.11 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5942.ConvReLU2d = prim::GetAttr[name="conv"](%self.59)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.11, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.7)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.3)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5942.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 16
                                    out_channels = 64
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D39470>
                                    scale = 0.11048972606658936
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5942.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5942.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5942.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5942.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.61 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5942.ConvReLU2d,
                                            %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                        %_packed_params.11 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.61)
                                        %15 : float = prim::Constant[value=0.11048972606658936](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.13 : QUInt8(1, 64, 112, 150, strides=[1075200, 1, 9600, 64], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.11, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.13)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5943.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.63 : __torch__.torch.nn.modules.linear.___torch_mangle_5943.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5944.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.65 : __torch__.torch.nn.modules.linear.___torch_mangle_5944.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5947.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5946.Conv2d object at 0000018BE6D508F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.67 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5947.ConvBNRelu,
                                        %1 : QUInt8(1, 64, 112, 150, strides=[1075200, 1, 9600, 64], requires_grad=0, device=cpu)):
                                    %conv.13 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5946.Conv2d = prim::GetAttr[name="conv"](%self.67)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.13, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5946.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 64
                                    out_channels = 64
                                    kernel_size = (5, 5)
                                    stride = (2, 2)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 64
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D39370>
                                    scale = 0.13561369478702545
                                    zero_point = 68
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5946.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5946.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5946.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5946.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.69 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5946.Conv2d,
                                            %1 : QUInt8(1, 64, 112, 150, strides=[1075200, 1, 9600, 64], requires_grad=0, device=cpu)):
                                        %_packed_params.13 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.69)
                                        %15 : float = prim::Constant[value=0.13561369478702545](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=68](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.15 : QUInt8(1, 64, 56, 75, strides=[268800, 1, 4800, 64], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.13, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.15)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5950.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5948.Conv2d object at 0000018BE6D52870>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_5949.Identity object at 0000018BE6D54270>
                              }
                              methods {
                                method forward {
                                  graph(%self.71 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5950.ConvBNRelu,
                                        %1 : QUInt8(1, 64, 56, 75, strides=[268800, 1, 4800, 64], requires_grad=0, device=cpu)):
                                    %bn.9 : __torch__.torch.nn.modules.linear.___torch_mangle_5949.Identity = prim::GetAttr[name="bn"](%self.71)
                                    %conv.15 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5948.Conv2d = prim::GetAttr[name="conv"](%self.71)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.15, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.9)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5948.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 64
                                    out_channels = 24
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D39570>
                                    scale = 0.29513248801231384
                                    zero_point = 61
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5948.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5948.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5948.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5948.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.73 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5948.Conv2d,
                                            %1 : QUInt8(1, 64, 56, 75, strides=[268800, 1, 4800, 64], requires_grad=0, device=cpu)):
                                        %_packed_params.15 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.73)
                                        %15 : float = prim::Constant[value=0.29513248801231384](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.17 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.15, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5949.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.75 : __torch__.torch.nn.modules.linear.___torch_mangle_5949.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5964.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5955.ConvBNRelu object at 0000018BF96B7160>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5957.ConvBNRelu object at 0000018BF96B7F60>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5960.ConvBNRelu object at 0000018BE5FD2470>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5963.TorchAdd object at 0000018BE5FD26F0>
                          }
                          methods {
                            method forward {
                              graph(%self.77 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5964.IRFBlock,
                                    %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                %res_conn.5 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5963.TorchAdd = prim::GetAttr[name="res_conn"](%self.77)
                                %pwl.7 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5960.ConvBNRelu = prim::GetAttr[name="pwl"](%self.77)
                                %dw.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5957.ConvBNRelu = prim::GetAttr[name="dw"](%self.77)
                                %pw.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5955.ConvBNRelu = prim::GetAttr[name="pw"](%self.77)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.3, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.15, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.7, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.5, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5955.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5952.ConvReLU2d object at 0000018BE6D57770>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_5953.Identity object at 0000018BF96B9060>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_5954.Identity object at 0000018BF96B86E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.79 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5955.ConvBNRelu,
                                        %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                    %relu.5 : __torch__.torch.nn.modules.linear.___torch_mangle_5954.Identity = prim::GetAttr[name="relu"](%self.79)
                                    %bn.11 : __torch__.torch.nn.modules.linear.___torch_mangle_5953.Identity = prim::GetAttr[name="bn"](%self.79)
                                    %conv.17 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5952.ConvReLU2d = prim::GetAttr[name="conv"](%self.79)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.17, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.11)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.5)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5952.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 24
                                    out_channels = 72
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D39CF0>
                                    scale = 0.049111630767583847
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5952.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5952.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5952.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5952.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.81 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5952.ConvReLU2d,
                                            %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                        %_packed_params.17 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.81)
                                        %15 : float = prim::Constant[value=0.049111630767583847](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.19 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.17, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.19)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5953.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.83 : __torch__.torch.nn.modules.linear.___torch_mangle_5953.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5954.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.85 : __torch__.torch.nn.modules.linear.___torch_mangle_5954.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5957.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5956.Conv2d object at 0000018BF96B8660>
                              }
                              methods {
                                method forward {
                                  graph(%self.87 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5957.ConvBNRelu,
                                        %1 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu)):
                                    %conv.19 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5956.Conv2d = prim::GetAttr[name="conv"](%self.87)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.19, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5956.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 72
                                    out_channels = 72
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 72
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3BE70>
                                    scale = 0.027580782771110535
                                    zero_point = 64
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5956.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5956.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5956.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5956.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.89 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5956.Conv2d,
                                            %1 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu)):
                                        %_packed_params.19 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.89)
                                        %15 : float = prim::Constant[value=0.027580782771110535](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.21 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.19, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.21)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5960.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5958.Conv2d object at 0000018BF96B8F60>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_5959.Identity object at 0000018BE5FD1C70>
                              }
                              methods {
                                method forward {
                                  graph(%self.91 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5960.ConvBNRelu,
                                        %1 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu)):
                                    %bn.13 : __torch__.torch.nn.modules.linear.___torch_mangle_5959.Identity = prim::GetAttr[name="bn"](%self.91)
                                    %conv.21 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5958.Conv2d = prim::GetAttr[name="conv"](%self.91)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.21, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.13)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5958.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 72
                                    out_channels = 24
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A670>
                                    scale = 0.14964845776557922
                                    zero_point = 61
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5958.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5958.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5958.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5958.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.93 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5958.Conv2d,
                                            %1 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu)):
                                        %_packed_params.21 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.93)
                                        %15 : float = prim::Constant[value=0.14964845776557922](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.21, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5959.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.95 : __torch__.torch.nn.modules.linear.___torch_mangle_5959.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5963.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5962.QFunctional object at 0000018BE5FD25F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.97 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5963.TorchAdd,
                                        %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                    %add_func.5 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5962.QFunctional = prim::GetAttr[name="add_func"](%self.97)
                                    %activation_post_process.5 : __torch__.torch.nn.modules.linear.___torch_mangle_5961.Identity = prim::GetAttr[name="activation_post_process"](%add_func.5)
                                    %5 : float = prim::Constant[value=0.2888323962688446](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.23 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.5)
                                    return (%input.23)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5962.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_5961.Identity object at 0000018BE5FD1EF0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_5961.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.99 : __torch__.torch.nn.modules.linear.___torch_mangle_5961.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5977.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5968.ConvBNRelu object at 0000018BE5FD50F0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5970.ConvBNRelu object at 0000018BE5FD6E70>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5973.ConvBNRelu object at 0000018BE5FD81F0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5976.TorchAdd object at 0000018BE5FDC9F0>
                          }
                          methods {
                            method forward {
                              graph(%self.101 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5977.IRFBlock,
                                    %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                %res_conn.7 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5976.TorchAdd = prim::GetAttr[name="res_conn"](%self.101)
                                %pwl.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5973.ConvBNRelu = prim::GetAttr[name="pwl"](%self.101)
                                %dw.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5970.ConvBNRelu = prim::GetAttr[name="dw"](%self.101)
                                %pw.5 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5968.ConvBNRelu = prim::GetAttr[name="pw"](%self.101)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.5, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.17, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.9, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.7, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5968.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5965.ConvReLU2d object at 0000018BE5FD4D70>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_5966.Identity object at 0000018BE5FD38F0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_5967.Identity object at 0000018BE5FD3270>
                              }
                              methods {
                                method forward {
                                  graph(%self.103 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5968.ConvBNRelu,
                                        %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                    %relu.7 : __torch__.torch.nn.modules.linear.___torch_mangle_5967.Identity = prim::GetAttr[name="relu"](%self.103)
                                    %bn.15 : __torch__.torch.nn.modules.linear.___torch_mangle_5966.Identity = prim::GetAttr[name="bn"](%self.103)
                                    %conv.23 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5965.ConvReLU2d = prim::GetAttr[name="conv"](%self.103)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.23, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.15)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.7)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5965.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 24
                                    out_channels = 72
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3ADF0>
                                    scale = 0.063758514821529388
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5965.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5965.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5965.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5965.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.105 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5965.ConvReLU2d,
                                            %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                        %_packed_params.23 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.105)
                                        %15 : float = prim::Constant[value=0.063758514821529388](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_2/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_2/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.25 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.23, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_2/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.25)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5966.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.107 : __torch__.torch.nn.modules.linear.___torch_mangle_5966.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5967.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.109 : __torch__.torch.nn.modules.linear.___torch_mangle_5967.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5970.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5969.Conv2d object at 0000018BE5FD3570>
                              }
                              methods {
                                method forward {
                                  graph(%self.111 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5970.ConvBNRelu,
                                        %1 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu)):
                                    %conv.25 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5969.Conv2d = prim::GetAttr[name="conv"](%self.111)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.25, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5969.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 72
                                    out_channels = 72
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 72
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A770>
                                    scale = 0.0355181023478508
                                    zero_point = 68
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5969.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5969.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5969.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5969.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.113 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5969.Conv2d,
                                            %1 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu)):
                                        %_packed_params.25 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.113)
                                        %15 : float = prim::Constant[value=0.0355181023478508](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_2/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=68](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_2/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.27 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.25, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_2/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.27)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5973.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5971.Conv2d object at 0000018BE5FD6F70>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_5972.Identity object at 0000018BE5FD7470>
                              }
                              methods {
                                method forward {
                                  graph(%self.115 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5973.ConvBNRelu,
                                        %1 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu)):
                                    %bn.17 : __torch__.torch.nn.modules.linear.___torch_mangle_5972.Identity = prim::GetAttr[name="bn"](%self.115)
                                    %conv.27 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5971.Conv2d = prim::GetAttr[name="conv"](%self.115)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.27, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.17)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5971.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 72
                                    out_channels = 24
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A5F0>
                                    scale = 0.17543162405490875
                                    zero_point = 68
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5971.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5971.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5971.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5971.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.117 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5971.Conv2d,
                                            %1 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu)):
                                        %_packed_params.27 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.117)
                                        %15 : float = prim::Constant[value=0.17543162405490875](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_2/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=68](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_2/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.27, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_2/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5972.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.119 : __torch__.torch.nn.modules.linear.___torch_mangle_5972.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5976.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5975.QFunctional object at 0000018BE5FDC7F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.121 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5976.TorchAdd,
                                        %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                    %add_func.7 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5975.QFunctional = prim::GetAttr[name="add_func"](%self.121)
                                    %activation_post_process.7 : __torch__.torch.nn.modules.linear.___torch_mangle_5974.Identity = prim::GetAttr[name="activation_post_process"](%add_func.7)
                                    %5 : float = prim::Constant[value=0.31409719586372375](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_2/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_2/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.29 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_2/__module.model.model.backbone.body.trunk1.fbnetv2_1_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.7)
                                    return (%input.29)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5975.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_5974.Identity object at 0000018BE5FDCBF0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_5974.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.123 : __torch__.torch.nn.modules.linear.___torch_mangle_5974.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5990.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5981.ConvBNRelu object at 0000018BE5FDF070>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5983.ConvBNRelu object at 0000018BE5FE07F0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5986.ConvBNRelu object at 0000018BE5FE2CF0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5989.TorchAdd object at 0000018BE5FE53F0>
                          }
                          methods {
                            method forward {
                              graph(%self.125 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_5990.IRFBlock,
                                    %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                %res_conn.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5989.TorchAdd = prim::GetAttr[name="res_conn"](%self.125)
                                %pwl.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5986.ConvBNRelu = prim::GetAttr[name="pwl"](%self.125)
                                %dw.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5983.ConvBNRelu = prim::GetAttr[name="dw"](%self.125)
                                %pw.7 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5981.ConvBNRelu = prim::GetAttr[name="pw"](%self.125)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.7, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.19, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.11, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.9, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5981.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5978.ConvReLU2d object at 0000018BE5FDE1F0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_5979.Identity object at 0000018BE5FDE0F0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_5980.Identity object at 0000018BE5FDE6F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.127 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5981.ConvBNRelu,
                                        %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                    %relu.9 : __torch__.torch.nn.modules.linear.___torch_mangle_5980.Identity = prim::GetAttr[name="relu"](%self.127)
                                    %bn.19 : __torch__.torch.nn.modules.linear.___torch_mangle_5979.Identity = prim::GetAttr[name="bn"](%self.127)
                                    %conv.29 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5978.ConvReLU2d = prim::GetAttr[name="conv"](%self.127)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.29, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.19)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.9)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5978.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 24
                                    out_channels = 72
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3BFF0>
                                    scale = 0.047454677522182465
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5978.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5978.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5978.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5978.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.129 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5978.ConvReLU2d,
                                            %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                        %_packed_params.29 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.129)
                                        %15 : float = prim::Constant[value=0.047454677522182465](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_3/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_3/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.31 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.29, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_3/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.31)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5979.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.131 : __torch__.torch.nn.modules.linear.___torch_mangle_5979.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5980.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.133 : __torch__.torch.nn.modules.linear.___torch_mangle_5980.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5983.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5982.Conv2d object at 0000018BE5FE03F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.135 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5983.ConvBNRelu,
                                        %1 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu)):
                                    %conv.31 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5982.Conv2d = prim::GetAttr[name="conv"](%self.135)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.31, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5982.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 72
                                    out_channels = 72
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 72
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B770>
                                    scale = 0.027043014764785767
                                    zero_point = 66
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5982.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5982.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5982.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5982.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.137 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5982.Conv2d,
                                            %1 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu)):
                                        %_packed_params.31 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.137)
                                        %15 : float = prim::Constant[value=0.027043014764785767](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_3/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_3/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.33 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.31, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_3/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.33)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5986.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5984.Conv2d object at 0000018BE5FDF7F0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_5985.Identity object at 0000018BE5FE25F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.139 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5986.ConvBNRelu,
                                        %1 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu)):
                                    %bn.21 : __torch__.torch.nn.modules.linear.___torch_mangle_5985.Identity = prim::GetAttr[name="bn"](%self.139)
                                    %conv.33 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5984.Conv2d = prim::GetAttr[name="conv"](%self.139)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.33, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.21)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5984.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 72
                                    out_channels = 24
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B0F0>
                                    scale = 0.21583858132362366
                                    zero_point = 63
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5984.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5984.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5984.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5984.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.141 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5984.Conv2d,
                                            %1 : QUInt8(1, 72, 56, 75, strides=[302400, 1, 5400, 72], requires_grad=0, device=cpu)):
                                        %_packed_params.33 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.141)
                                        %15 : float = prim::Constant[value=0.21583858132362366](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_3/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_3/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.33, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_3/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5985.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.143 : __torch__.torch.nn.modules.linear.___torch_mangle_5985.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5989.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5988.QFunctional object at 0000018BE5FE6B70>
                              }
                              methods {
                                method forward {
                                  graph(%self.145 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5989.TorchAdd,
                                        %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                    %add_func.9 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5988.QFunctional = prim::GetAttr[name="add_func"](%self.145)
                                    %activation_post_process.9 : __torch__.torch.nn.modules.linear.___torch_mangle_5987.Identity = prim::GetAttr[name="activation_post_process"](%add_func.9)
                                    %5 : float = prim::Constant[value=0.33375874161720276](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_3/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_3/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.35 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_3/__module.model.model.backbone.body.trunk1.fbnetv2_1_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.9)
                                    return (%input.35)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_5988.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_5987.Identity object at 0000018BE5FE59F0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_5987.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.147 : __torch__.torch.nn.modules.linear.___torch_mangle_5987.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_6085.Sequential {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        fbnetv2_2_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6012.IRFBlock object at 0000018BE5FF6F70>
                        fbnetv2_2_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6036.IRFBlock object at 0000018BE60083F0>
                        fbnetv2_2_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6060.IRFBlock object at 0000018BE87208E0>
                        fbnetv2_2_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6084.IRFBlock object at 0000018BE87305E0>
                      }
                      methods {
                        method forward {
                          graph(%self.149 : __torch__.torch.nn.modules.container.___torch_mangle_6085.Sequential,
                                %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                            %fbnetv2_2_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6084.IRFBlock = prim::GetAttr[name="fbnetv2_2_3"](%self.149)
                            %fbnetv2_2_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6060.IRFBlock = prim::GetAttr[name="fbnetv2_2_2"](%self.149)
                            %fbnetv2_2_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6036.IRFBlock = prim::GetAttr[name="fbnetv2_2_1"](%self.149)
                            %fbnetv2_2_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6012.IRFBlock = prim::GetAttr[name="fbnetv2_2_0"](%self.149)
                            %10 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_2_0, %1)
                            %11 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_2_1, %10)
                            %12 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_2_2, %11)
                            %13 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_2_3, %12)
                            return (%13)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6012.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5995.ConvBNRelu object at 0000018BE5FEAFF0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5997.ConvBNRelu object at 0000018BE5FEB0F0>
                            se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6008.SEModule object at 0000018BE5FF31F0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6011.ConvBNRelu object at 0000018BE5FF6170>
                          }
                          methods {
                            method forward {
                              graph(%self.151 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6012.IRFBlock,
                                    %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                %pwl.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6011.ConvBNRelu = prim::GetAttr[name="pwl"](%self.151)
                                %se.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6008.SEModule = prim::GetAttr[name="se"](%self.151)
                                %dw.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5997.ConvBNRelu = prim::GetAttr[name="dw"](%self.151)
                                %pw.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5995.ConvBNRelu = prim::GetAttr[name="pw"](%self.151)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.9, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.21, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%se.3, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%pwl.13, %12)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5995.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5992.ConvReLU2d object at 0000018BE5FE7B70>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_5993.Identity object at 0000018BE5FE8BF0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_5994.Identity object at 0000018BE5FE7770>
                              }
                              methods {
                                method forward {
                                  graph(%self.153 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5995.ConvBNRelu,
                                        %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                    %relu.11 : __torch__.torch.nn.modules.linear.___torch_mangle_5994.Identity = prim::GetAttr[name="relu"](%self.153)
                                    %bn.23 : __torch__.torch.nn.modules.linear.___torch_mangle_5993.Identity = prim::GetAttr[name="bn"](%self.153)
                                    %conv.35 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5992.ConvReLU2d = prim::GetAttr[name="conv"](%self.153)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.35, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.23)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.11)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5992.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 24
                                    out_channels = 96
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A970>
                                    scale = 0.10718471556901932
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5992.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5992.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5992.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5992.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.155 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5992.ConvReLU2d,
                                            %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                        %_packed_params.35 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.155)
                                        %15 : float = prim::Constant[value=0.10718471556901932](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.37 : QUInt8(1, 96, 56, 75, strides=[403200, 1, 7200, 96], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.35, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.37)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5993.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.157 : __torch__.torch.nn.modules.linear.___torch_mangle_5993.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_5994.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.159 : __torch__.torch.nn.modules.linear.___torch_mangle_5994.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5997.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5996.Conv2d object at 0000018BE5FE9670>
                              }
                              methods {
                                method forward {
                                  graph(%self.161 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_5997.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 56, 75, strides=[403200, 1, 7200, 96], requires_grad=0, device=cpu)):
                                    %conv.37 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5996.Conv2d = prim::GetAttr[name="conv"](%self.161)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.37, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5996.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 96
                                    kernel_size = (5, 5)
                                    stride = (2, 2)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 96
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3BF70>
                                    scale = 0.20592471957206726
                                    zero_point = 57
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5996.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5996.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5996.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5996.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.163 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_5996.Conv2d,
                                            %1 : QUInt8(1, 96, 56, 75, strides=[403200, 1, 7200, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.37 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.163)
                                        %15 : float = prim::Constant[value=0.20592471957206726](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=57](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %x.3 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.37, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%x.3)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6008.SEModule {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_5998.AdaptiveAvgPool2d object at 0000018BE5FE9DF0>
                                se = <__torch__.torch.nn.modules.container.___torch_mangle_6004.Sequential object at 0000018BE5FF25F0>
                                mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6007.TorchMultiply object at 0000018BE5FF4A70>
                              }
                              methods {
                                method forward {
                                  graph(%self.165 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6008.SEModule,
                                        %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                    %mul.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6007.TorchMultiply = prim::GetAttr[name="mul"](%self.165)
                                    %se.1 : __torch__.torch.nn.modules.container.___torch_mangle_6004.Sequential = prim::GetAttr[name="se"](%self.165)
                                    %avg_pool.1 : __torch__.torch.nn.modules.pooling.___torch_mangle_5998.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.165)
                                    %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.1, %1)
                                    %33 : Tensor = prim::CallMethod[name="forward"](%se.1, %32)
                                    %34 : Tensor = prim::CallMethod[name="forward"](%mul.1, %1, %33)
                                    return (%34)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.pooling.___torch_mangle_5998.AdaptiveAvgPool2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.167 : __torch__.torch.nn.modules.pooling.___torch_mangle_5998.AdaptiveAvgPool2d,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                        %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.avg_pool
                                        %input.39 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        return (%input.39)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.container.___torch_mangle_6004.Sequential {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6001.ConvBNRelu object at 0000018BE5FEF8F0>
                                    1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6002.Conv2d object at 0000018BE5FEF570>
                                    2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6003.Sigmoid object at 0000018BE5FEFCF0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.169 : __torch__.torch.nn.modules.container.___torch_mangle_6004.Sequential,
                                            %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                        %_2.1 : __torch__.torch.nn.modules.activation.___torch_mangle_6003.Sigmoid = prim::GetAttr[name="2"](%self.169)
                                        %_1.1 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6002.Conv2d = prim::GetAttr[name="1"](%self.169)
                                        %_0.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6001.ConvBNRelu = prim::GetAttr[name="0"](%self.169)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%_0.3, %1)
                                        %9 : Tensor = prim::CallMethod[name="forward"](%_1.1, %8)
                                        %10 : Tensor = prim::CallMethod[name="forward"](%_2.1, %9)
                                        return (%10)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6001.ConvBNRelu {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5999.ConvReLU2d object at 0000018BE5FEC770>
                                        relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6000.Identity object at 0000018BE5FECAF0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.171 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6001.ConvBNRelu,
                                                %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                            %relu.13 : __torch__.torch.nn.modules.linear.___torch_mangle_6000.Identity = prim::GetAttr[name="relu"](%self.171)
                                            %conv.39 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5999.ConvReLU2d = prim::GetAttr[name="conv"](%self.171)
                                            %6 : Tensor = prim::CallMethod[name="forward"](%conv.39, %1)
                                            %7 : NoneType = prim::CallMethod[name="forward"](%relu.13)
                                            return (%6)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5999.ConvReLU2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 96
                                            out_channels = 24
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A9F0>
                                            scale = 0.023411024361848831
                                            zero_point = 0
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5999.ConvReLU2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5999.ConvReLU2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5999.ConvReLU2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5999.ConvReLU2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.173 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_5999.ConvReLU2d,
                                                    %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                                %_packed_params.39 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.173)
                                                %15 : float = prim::Constant[value=0.023411024361848831](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se.0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se.0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.41 : QUInt8(1, 24, 1, 1, strides=[24, 1, 24, 24], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.39, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se.0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.41)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6000.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.175 : __torch__.torch.nn.modules.linear.___torch_mangle_6000.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6002.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 24
                                        out_channels = 96
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3ABF0>
                                        scale = 0.026023637503385544
                                        zero_point = 106
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6002.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6002.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6002.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6002.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.177 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6002.Conv2d,
                                                %1 : QUInt8(1, 24, 1, 1, strides=[24, 1, 24, 24], requires_grad=0, device=cpu)):
                                            %_packed_params.41 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.177)
                                            %15 : float = prim::Constant[value=0.026023637503385544](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=106](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.43 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.41, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.43)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.activation.___torch_mangle_6003.Sigmoid {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.179 : __torch__.torch.nn.modules.activation.___torch_mangle_6003.Sigmoid,
                                                %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                            %2 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                            return (%2)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6007.TorchMultiply {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6006.QFunctional object at 0000018BE5FF3570>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.181 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6007.TorchMultiply,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                        %mul_func.1 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6006.QFunctional = prim::GetAttr[name="mul_func"](%self.181)
                                        %activation_post_process.11 : __torch__.torch.nn.modules.linear.___torch_mangle_6005.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.1)
                                        %5 : float = prim::Constant[value=0.032910376787185669](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.45 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.11)
                                        return (%input.45)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6006.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6005.Identity object at 0000018BE5FF3E70>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6005.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.183 : __torch__.torch.nn.modules.linear.___torch_mangle_6005.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6011.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6009.Conv2d object at 0000018BE5FF5B70>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6010.Identity object at 0000018BE5FF64F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.185 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6011.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                    %bn.25 : __torch__.torch.nn.modules.linear.___torch_mangle_6010.Identity = prim::GetAttr[name="bn"](%self.185)
                                    %conv.41 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6009.Conv2d = prim::GetAttr[name="conv"](%self.185)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.41, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.25)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6009.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 32
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B070>
                                    scale = 0.20294657349586487
                                    zero_point = 60
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6009.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6009.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6009.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6009.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.187 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6009.Conv2d,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.43 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.187)
                                        %15 : float = prim::Constant[value=0.20294657349586487](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.47 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.43, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.47)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6010.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.189 : __torch__.torch.nn.modules.linear.___torch_mangle_6010.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6036.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6016.ConvBNRelu object at 0000018BE5FFAFF0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6018.ConvBNRelu object at 0000018BE5FF96F0>
                            se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6029.SEModule object at 0000018BE60053F0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6032.ConvBNRelu object at 0000018BE6007AF0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6035.TorchAdd object at 0000018BE6008C70>
                          }
                          methods {
                            method forward {
                              graph(%self.191 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6036.IRFBlock,
                                    %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                %res_conn.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6035.TorchAdd = prim::GetAttr[name="res_conn"](%self.191)
                                %pwl.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6032.ConvBNRelu = prim::GetAttr[name="pwl"](%self.191)
                                %se.7 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6029.SEModule = prim::GetAttr[name="se"](%self.191)
                                %dw.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6018.ConvBNRelu = prim::GetAttr[name="dw"](%self.191)
                                %pw.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6016.ConvBNRelu = prim::GetAttr[name="pw"](%self.191)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pw.11, %1)
                                %13 : Tensor = prim::CallMethod[name="forward"](%dw.23, %12)
                                %14 : Tensor = prim::CallMethod[name="forward"](%se.7, %13)
                                %15 : Tensor = prim::CallMethod[name="forward"](%pwl.15, %14)
                                %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.11, %15, %1)
                                return (%16)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6016.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6013.ConvReLU2d object at 0000018BE5FF83F0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6014.Identity object at 0000018BE5FF7AF0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6015.Identity object at 0000018BE5FF9E70>
                              }
                              methods {
                                method forward {
                                  graph(%self.193 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6016.ConvBNRelu,
                                        %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                    %relu.15 : __torch__.torch.nn.modules.linear.___torch_mangle_6015.Identity = prim::GetAttr[name="relu"](%self.193)
                                    %bn.27 : __torch__.torch.nn.modules.linear.___torch_mangle_6014.Identity = prim::GetAttr[name="bn"](%self.193)
                                    %conv.43 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6013.ConvReLU2d = prim::GetAttr[name="conv"](%self.193)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.43, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.27)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.15)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6013.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 32
                                    out_channels = 96
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A2F0>
                                    scale = 0.044782720506191254
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6013.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6013.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6013.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6013.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.195 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6013.ConvReLU2d,
                                            %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                        %_packed_params.45 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.195)
                                        %15 : float = prim::Constant[value=0.044782720506191254](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.49 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.45, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.49)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6014.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.197 : __torch__.torch.nn.modules.linear.___torch_mangle_6014.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6015.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.199 : __torch__.torch.nn.modules.linear.___torch_mangle_6015.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6018.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6017.Conv2d object at 0000018BE5FFA6F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.201 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6018.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                    %conv.45 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6017.Conv2d = prim::GetAttr[name="conv"](%self.201)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.45, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6017.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 96
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 96
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B7F0>
                                    scale = 0.025387858971953392
                                    zero_point = 74
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6017.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6017.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6017.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6017.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.203 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6017.Conv2d,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.47 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.203)
                                        %15 : float = prim::Constant[value=0.025387858971953392](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=74](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %x.5 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.47, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%x.5)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6029.SEModule {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6019.AdaptiveAvgPool2d object at 0000018BE5FFBEF0>
                                se = <__torch__.torch.nn.modules.container.___torch_mangle_6025.Sequential object at 0000018BE6002EF0>
                                mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6028.TorchMultiply object at 0000018BE6006570>
                              }
                              methods {
                                method forward {
                                  graph(%self.205 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6029.SEModule,
                                        %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                    %mul.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6028.TorchMultiply = prim::GetAttr[name="mul"](%self.205)
                                    %se.5 : __torch__.torch.nn.modules.container.___torch_mangle_6025.Sequential = prim::GetAttr[name="se"](%self.205)
                                    %avg_pool.3 : __torch__.torch.nn.modules.pooling.___torch_mangle_6019.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.205)
                                    %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.3, %1)
                                    %33 : Tensor = prim::CallMethod[name="forward"](%se.5, %32)
                                    %34 : Tensor = prim::CallMethod[name="forward"](%mul.3, %1, %33)
                                    return (%34)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.pooling.___torch_mangle_6019.AdaptiveAvgPool2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.207 : __torch__.torch.nn.modules.pooling.___torch_mangle_6019.AdaptiveAvgPool2d,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                        %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.avg_pool
                                        %input.51 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        return (%input.51)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.container.___torch_mangle_6025.Sequential {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6022.ConvBNRelu object at 0000018BE5FFF870>
                                    1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6023.Conv2d object at 0000018BE6001DF0>
                                    2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6024.Sigmoid object at 0000018BE6002CF0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.209 : __torch__.torch.nn.modules.container.___torch_mangle_6025.Sequential,
                                            %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                        %_2.3 : __torch__.torch.nn.modules.activation.___torch_mangle_6024.Sigmoid = prim::GetAttr[name="2"](%self.209)
                                        %_1.3 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6023.Conv2d = prim::GetAttr[name="1"](%self.209)
                                        %_0.5 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6022.ConvBNRelu = prim::GetAttr[name="0"](%self.209)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%_0.5, %1)
                                        %9 : Tensor = prim::CallMethod[name="forward"](%_1.3, %8)
                                        %10 : Tensor = prim::CallMethod[name="forward"](%_2.3, %9)
                                        return (%10)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6022.ConvBNRelu {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6020.ConvReLU2d object at 0000018BE5FFE970>
                                        relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6021.Identity object at 0000018BE5FFEBF0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.211 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6022.ConvBNRelu,
                                                %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                            %relu.17 : __torch__.torch.nn.modules.linear.___torch_mangle_6021.Identity = prim::GetAttr[name="relu"](%self.211)
                                            %conv.47 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6020.ConvReLU2d = prim::GetAttr[name="conv"](%self.211)
                                            %6 : Tensor = prim::CallMethod[name="forward"](%conv.47, %1)
                                            %7 : NoneType = prim::CallMethod[name="forward"](%relu.17)
                                            return (%6)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6020.ConvReLU2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 96
                                            out_channels = 24
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B9F0>
                                            scale = 1.1920928955078125e-07
                                            zero_point = 0
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6020.ConvReLU2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6020.ConvReLU2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6020.ConvReLU2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6020.ConvReLU2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.213 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6020.ConvReLU2d,
                                                    %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                                %_packed_params.49 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.213)
                                                %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se.0/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se.0/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.53 : QUInt8(1, 24, 1, 1, strides=[24, 1, 24, 24], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.49, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se.0/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.53)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6021.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.215 : __torch__.torch.nn.modules.linear.___torch_mangle_6021.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6023.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 24
                                        out_channels = 96
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A370>
                                        scale = 0.00023171157226897776
                                        zero_point = 43
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6023.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6023.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6023.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6023.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.217 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6023.Conv2d,
                                                %1 : QUInt8(1, 24, 1, 1, strides=[24, 1, 24, 24], requires_grad=0, device=cpu)):
                                            %_packed_params.51 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.217)
                                            %15 : float = prim::Constant[value=0.00023171157226897776](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=43](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.55 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.51, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.55)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.activation.___torch_mangle_6024.Sigmoid {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.219 : __torch__.torch.nn.modules.activation.___torch_mangle_6024.Sigmoid,
                                                %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                            %2 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                            return (%2)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6028.TorchMultiply {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6027.QFunctional object at 0000018BE6004B70>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.221 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6028.TorchMultiply,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                        %mul_func.3 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6027.QFunctional = prim::GetAttr[name="mul_func"](%self.221)
                                        %activation_post_process.13 : __torch__.torch.nn.modules.linear.___torch_mangle_6026.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.3)
                                        %5 : float = prim::Constant[value=0.012559558264911175](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=75](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.57 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.13)
                                        return (%input.57)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6027.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6026.Identity object at 0000018BE60047F0>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6026.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.223 : __torch__.torch.nn.modules.linear.___torch_mangle_6026.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6032.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6030.Conv2d object at 0000018BE60059F0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6031.Identity object at 0000018BE6006670>
                              }
                              methods {
                                method forward {
                                  graph(%self.225 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6032.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                    %bn.29 : __torch__.torch.nn.modules.linear.___torch_mangle_6031.Identity = prim::GetAttr[name="bn"](%self.225)
                                    %conv.49 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6030.Conv2d = prim::GetAttr[name="conv"](%self.225)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.49, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.29)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6030.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 32
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B870>
                                    scale = 0.20045576989650726
                                    zero_point = 70
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6030.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6030.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6030.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6030.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.227 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6030.Conv2d,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.53 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.227)
                                        %15 : float = prim::Constant[value=0.20045576989650726](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=70](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.53, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6031.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.229 : __torch__.torch.nn.modules.linear.___torch_mangle_6031.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6035.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6034.QFunctional object at 0000018BE60089F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.231 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6035.TorchAdd,
                                        %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                    %add_func.11 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6034.QFunctional = prim::GetAttr[name="add_func"](%self.231)
                                    %activation_post_process.15 : __torch__.torch.nn.modules.linear.___torch_mangle_6033.Identity = prim::GetAttr[name="activation_post_process"](%add_func.11)
                                    %5 : float = prim::Constant[value=0.25609633326530457](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.59 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.15)
                                    return (%input.59)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6034.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6033.Identity object at 0000018BE60080F0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6033.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.233 : __torch__.torch.nn.modules.linear.___torch_mangle_6033.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6060.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6040.ConvBNRelu object at 0000018BE600BD70>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6042.ConvBNRelu object at 0000018BE600CD70>
                            se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6053.SEModule object at 0000018BE871C460>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6056.ConvBNRelu object at 0000018BE87200E0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6059.TorchAdd object at 0000018BE8721A60>
                          }
                          methods {
                            method forward {
                              graph(%self.235 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6060.IRFBlock,
                                    %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                %res_conn.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6059.TorchAdd = prim::GetAttr[name="res_conn"](%self.235)
                                %pwl.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6056.ConvBNRelu = prim::GetAttr[name="pwl"](%self.235)
                                %se.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6053.SEModule = prim::GetAttr[name="se"](%self.235)
                                %dw.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6042.ConvBNRelu = prim::GetAttr[name="dw"](%self.235)
                                %pw.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6040.ConvBNRelu = prim::GetAttr[name="pw"](%self.235)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pw.13, %1)
                                %13 : Tensor = prim::CallMethod[name="forward"](%dw.25, %12)
                                %14 : Tensor = prim::CallMethod[name="forward"](%se.11, %13)
                                %15 : Tensor = prim::CallMethod[name="forward"](%pwl.17, %14)
                                %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.13, %15, %1)
                                return (%16)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6040.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6037.ConvReLU2d object at 0000018BE60091F0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6038.Identity object at 0000018BE6009CF0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6039.Identity object at 0000018BE600BA70>
                              }
                              methods {
                                method forward {
                                  graph(%self.237 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6040.ConvBNRelu,
                                        %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                    %relu.19 : __torch__.torch.nn.modules.linear.___torch_mangle_6039.Identity = prim::GetAttr[name="relu"](%self.237)
                                    %bn.31 : __torch__.torch.nn.modules.linear.___torch_mangle_6038.Identity = prim::GetAttr[name="bn"](%self.237)
                                    %conv.51 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6037.ConvReLU2d = prim::GetAttr[name="conv"](%self.237)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.51, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.31)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.19)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6037.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 32
                                    out_channels = 96
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B270>
                                    scale = 0.037047538906335831
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6037.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6037.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6037.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6037.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.239 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6037.ConvReLU2d,
                                            %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                        %_packed_params.55 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.239)
                                        %15 : float = prim::Constant[value=0.037047538906335831](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.61 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.55, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.61)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6038.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.241 : __torch__.torch.nn.modules.linear.___torch_mangle_6038.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6039.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.243 : __torch__.torch.nn.modules.linear.___torch_mangle_6039.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6042.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6041.Conv2d object at 0000018BE600C4F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.245 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6042.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                    %conv.53 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6041.Conv2d = prim::GetAttr[name="conv"](%self.245)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.53, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6041.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 96
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 96
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A6F0>
                                    scale = 0.013652492314577103
                                    zero_point = 55
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6041.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6041.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6041.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6041.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.247 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6041.Conv2d,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.57 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.247)
                                        %15 : float = prim::Constant[value=0.013652492314577103](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=55](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %x.7 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.57, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%x.7)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6053.SEModule {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6043.AdaptiveAvgPool2d object at 0000018BE600D970>
                                se = <__torch__.torch.nn.modules.container.___torch_mangle_6049.Sequential object at 0000018BE871B360>
                                mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6052.TorchMultiply object at 0000018BE871CDE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.249 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6053.SEModule,
                                        %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                    %mul.5 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6052.TorchMultiply = prim::GetAttr[name="mul"](%self.249)
                                    %se.9 : __torch__.torch.nn.modules.container.___torch_mangle_6049.Sequential = prim::GetAttr[name="se"](%self.249)
                                    %avg_pool.5 : __torch__.torch.nn.modules.pooling.___torch_mangle_6043.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.249)
                                    %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.5, %1)
                                    %33 : Tensor = prim::CallMethod[name="forward"](%se.9, %32)
                                    %34 : Tensor = prim::CallMethod[name="forward"](%mul.5, %1, %33)
                                    return (%34)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.pooling.___torch_mangle_6043.AdaptiveAvgPool2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.251 : __torch__.torch.nn.modules.pooling.___torch_mangle_6043.AdaptiveAvgPool2d,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                        %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.avg_pool
                                        %input.63 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        return (%input.63)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.container.___torch_mangle_6049.Sequential {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6046.ConvBNRelu object at 0000018BE871B060>
                                    1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6047.Conv2d object at 0000018BE871AB60>
                                    2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6048.Sigmoid object at 0000018BE871A760>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.253 : __torch__.torch.nn.modules.container.___torch_mangle_6049.Sequential,
                                            %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                        %_2.5 : __torch__.torch.nn.modules.activation.___torch_mangle_6048.Sigmoid = prim::GetAttr[name="2"](%self.253)
                                        %_1.5 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6047.Conv2d = prim::GetAttr[name="1"](%self.253)
                                        %_0.7 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6046.ConvBNRelu = prim::GetAttr[name="0"](%self.253)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%_0.7, %1)
                                        %9 : Tensor = prim::CallMethod[name="forward"](%_1.5, %8)
                                        %10 : Tensor = prim::CallMethod[name="forward"](%_2.5, %9)
                                        return (%10)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6046.ConvBNRelu {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6044.ConvReLU2d object at 0000018BE600FA70>
                                        relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6045.Identity object at 0000018BE871AFE0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.255 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6046.ConvBNRelu,
                                                %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                            %relu.21 : __torch__.torch.nn.modules.linear.___torch_mangle_6045.Identity = prim::GetAttr[name="relu"](%self.255)
                                            %conv.55 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6044.ConvReLU2d = prim::GetAttr[name="conv"](%self.255)
                                            %6 : Tensor = prim::CallMethod[name="forward"](%conv.55, %1)
                                            %7 : NoneType = prim::CallMethod[name="forward"](%relu.21)
                                            return (%6)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6044.ConvReLU2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 96
                                            out_channels = 24
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C070>
                                            scale = 1.1920928955078125e-07
                                            zero_point = 0
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6044.ConvReLU2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6044.ConvReLU2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6044.ConvReLU2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6044.ConvReLU2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.257 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6044.ConvReLU2d,
                                                    %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                                %_packed_params.59 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.257)
                                                %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se.0/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se.0/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.65 : QUInt8(1, 24, 1, 1, strides=[24, 1, 24, 24], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.59, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se.0/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.65)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6045.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.259 : __torch__.torch.nn.modules.linear.___torch_mangle_6045.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6047.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 24
                                        out_channels = 96
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3AA70>
                                        scale = 0.00023374080774374306
                                        zero_point = 36
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6047.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6047.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6047.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6047.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.261 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6047.Conv2d,
                                                %1 : QUInt8(1, 24, 1, 1, strides=[24, 1, 24, 24], requires_grad=0, device=cpu)):
                                            %_packed_params.61 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.261)
                                            %15 : float = prim::Constant[value=0.00023374080774374306](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=36](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.67 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.61, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.67)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.activation.___torch_mangle_6048.Sigmoid {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.263 : __torch__.torch.nn.modules.activation.___torch_mangle_6048.Sigmoid,
                                                %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                            %2 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                            return (%2)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6052.TorchMultiply {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6051.QFunctional object at 0000018BE871C1E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.265 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6052.TorchMultiply,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                        %mul_func.5 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6051.QFunctional = prim::GetAttr[name="mul_func"](%self.265)
                                        %activation_post_process.17 : __torch__.torch.nn.modules.linear.___torch_mangle_6050.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.5)
                                        %5 : float = prim::Constant[value=0.0082591529935598373](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.69 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.17)
                                        return (%input.69)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6051.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6050.Identity object at 0000018BE871E0E0>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6050.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.267 : __torch__.torch.nn.modules.linear.___torch_mangle_6050.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6056.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6054.Conv2d object at 0000018BE871EEE0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6055.Identity object at 0000018BE871EE60>
                              }
                              methods {
                                method forward {
                                  graph(%self.269 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6056.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                    %bn.33 : __torch__.torch.nn.modules.linear.___torch_mangle_6055.Identity = prim::GetAttr[name="bn"](%self.269)
                                    %conv.57 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6054.Conv2d = prim::GetAttr[name="conv"](%self.269)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.57, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.33)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6054.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 32
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C0F0>
                                    scale = 0.12843473255634308
                                    zero_point = 64
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6054.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6054.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6054.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6054.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.271 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6054.Conv2d,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.63 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.271)
                                        %15 : float = prim::Constant[value=0.12843473255634308](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.63, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6055.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.273 : __torch__.torch.nn.modules.linear.___torch_mangle_6055.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6059.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6058.QFunctional object at 0000018BE871EBE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.275 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6059.TorchAdd,
                                        %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                    %add_func.13 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6058.QFunctional = prim::GetAttr[name="add_func"](%self.275)
                                    %activation_post_process.19 : __torch__.torch.nn.modules.linear.___torch_mangle_6057.Identity = prim::GetAttr[name="activation_post_process"](%add_func.13)
                                    %5 : float = prim::Constant[value=0.24500380456447601](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.71 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.19)
                                    return (%input.71)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6058.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6057.Identity object at 0000018BE871E160>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6057.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.277 : __torch__.torch.nn.modules.linear.___torch_mangle_6057.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6084.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6064.ConvBNRelu object at 0000018BE87240E0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6066.ConvBNRelu object at 0000018BE8722B60>
                            se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6077.SEModule object at 0000018BE872EEE0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6080.ConvBNRelu object at 0000018BE8731860>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6083.TorchAdd object at 0000018BE8730260>
                          }
                          methods {
                            method forward {
                              graph(%self.279 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6084.IRFBlock,
                                    %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                %res_conn.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6083.TorchAdd = prim::GetAttr[name="res_conn"](%self.279)
                                %pwl.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6080.ConvBNRelu = prim::GetAttr[name="pwl"](%self.279)
                                %se.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6077.SEModule = prim::GetAttr[name="se"](%self.279)
                                %dw.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6066.ConvBNRelu = prim::GetAttr[name="dw"](%self.279)
                                %pw.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6064.ConvBNRelu = prim::GetAttr[name="pw"](%self.279)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pw.15, %1)
                                %13 : Tensor = prim::CallMethod[name="forward"](%dw.27, %12)
                                %14 : Tensor = prim::CallMethod[name="forward"](%se.15, %13)
                                %15 : Tensor = prim::CallMethod[name="forward"](%pwl.19, %14)
                                %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.15, %15, %1)
                                return (%16)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6064.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6061.ConvReLU2d object at 0000018BE8720C60>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6062.Identity object at 0000018BE8720E60>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6063.Identity object at 0000018BE8723DE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.281 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6064.ConvBNRelu,
                                        %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                    %relu.23 : __torch__.torch.nn.modules.linear.___torch_mangle_6063.Identity = prim::GetAttr[name="relu"](%self.281)
                                    %bn.35 : __torch__.torch.nn.modules.linear.___torch_mangle_6062.Identity = prim::GetAttr[name="bn"](%self.281)
                                    %conv.59 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6061.ConvReLU2d = prim::GetAttr[name="conv"](%self.281)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.59, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.35)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.23)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6061.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 32
                                    out_channels = 96
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B2F0>
                                    scale = 0.036591872572898865
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6061.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6061.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6061.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6061.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.283 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6061.ConvReLU2d,
                                            %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                        %_packed_params.65 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.283)
                                        %15 : float = prim::Constant[value=0.036591872572898865](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.73 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.65, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.73)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6062.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.285 : __torch__.torch.nn.modules.linear.___torch_mangle_6062.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6063.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.287 : __torch__.torch.nn.modules.linear.___torch_mangle_6063.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6066.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6065.Conv2d object at 0000018BE8723EE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.289 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6066.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                    %conv.61 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6065.Conv2d = prim::GetAttr[name="conv"](%self.289)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.61, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6065.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 96
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 96
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B5F0>
                                    scale = 0.012937571853399277
                                    zero_point = 61
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6065.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6065.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6065.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6065.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.291 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6065.Conv2d,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.67 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.291)
                                        %15 : float = prim::Constant[value=0.012937571853399277](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %x.9 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.67, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%x.9)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6077.SEModule {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6067.AdaptiveAvgPool2d object at 0000018BE8725160>
                                se = <__torch__.torch.nn.modules.container.___torch_mangle_6073.Sequential object at 0000018BE872B760>
                                mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6076.TorchMultiply object at 0000018BE872FEE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.293 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6077.SEModule,
                                        %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                    %mul.7 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6076.TorchMultiply = prim::GetAttr[name="mul"](%self.293)
                                    %se.13 : __torch__.torch.nn.modules.container.___torch_mangle_6073.Sequential = prim::GetAttr[name="se"](%self.293)
                                    %avg_pool.7 : __torch__.torch.nn.modules.pooling.___torch_mangle_6067.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.293)
                                    %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.7, %1)
                                    %33 : Tensor = prim::CallMethod[name="forward"](%se.13, %32)
                                    %34 : Tensor = prim::CallMethod[name="forward"](%mul.7, %1, %33)
                                    return (%34)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.pooling.___torch_mangle_6067.AdaptiveAvgPool2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.295 : __torch__.torch.nn.modules.pooling.___torch_mangle_6067.AdaptiveAvgPool2d,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                        %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.avg_pool
                                        %input.75 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        return (%input.75)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.container.___torch_mangle_6073.Sequential {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6070.ConvBNRelu object at 0000018BE8729560>
                                    1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6071.Conv2d object at 0000018BE872B960>
                                    2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6072.Sigmoid object at 0000018BE872ABE0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.297 : __torch__.torch.nn.modules.container.___torch_mangle_6073.Sequential,
                                            %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                        %_2.7 : __torch__.torch.nn.modules.activation.___torch_mangle_6072.Sigmoid = prim::GetAttr[name="2"](%self.297)
                                        %_1.7 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6071.Conv2d = prim::GetAttr[name="1"](%self.297)
                                        %_0.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6070.ConvBNRelu = prim::GetAttr[name="0"](%self.297)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%_0.9, %1)
                                        %9 : Tensor = prim::CallMethod[name="forward"](%_1.7, %8)
                                        %10 : Tensor = prim::CallMethod[name="forward"](%_2.7, %9)
                                        return (%10)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6070.ConvBNRelu {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6068.ConvReLU2d object at 0000018BE87271E0>
                                        relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6069.Identity object at 0000018BE8727460>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.299 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6070.ConvBNRelu,
                                                %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                            %relu.25 : __torch__.torch.nn.modules.linear.___torch_mangle_6069.Identity = prim::GetAttr[name="relu"](%self.299)
                                            %conv.63 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6068.ConvReLU2d = prim::GetAttr[name="conv"](%self.299)
                                            %6 : Tensor = prim::CallMethod[name="forward"](%conv.63, %1)
                                            %7 : NoneType = prim::CallMethod[name="forward"](%relu.25)
                                            return (%6)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6068.ConvReLU2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 96
                                            out_channels = 24
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B8F0>
                                            scale = 1.1920928955078125e-07
                                            zero_point = 0
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6068.ConvReLU2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6068.ConvReLU2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6068.ConvReLU2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6068.ConvReLU2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.301 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6068.ConvReLU2d,
                                                    %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                                %_packed_params.69 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.301)
                                                %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se.0/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se.0/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.77 : QUInt8(1, 24, 1, 1, strides=[24, 1, 24, 24], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.69, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se.0/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.77)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6069.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.303 : __torch__.torch.nn.modules.linear.___torch_mangle_6069.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6071.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 24
                                        out_channels = 96
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A7F0>
                                        scale = 0.00020581403805408627
                                        zero_point = 56
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6071.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6071.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6071.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6071.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.305 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6071.Conv2d,
                                                %1 : QUInt8(1, 24, 1, 1, strides=[24, 1, 24, 24], requires_grad=0, device=cpu)):
                                            %_packed_params.71 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.305)
                                            %15 : float = prim::Constant[value=0.00020581403805408627](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=56](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.79 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.71, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.79)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.activation.___torch_mangle_6072.Sigmoid {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.307 : __torch__.torch.nn.modules.activation.___torch_mangle_6072.Sigmoid,
                                                %1 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                            %2 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                            return (%2)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6076.TorchMultiply {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6075.QFunctional object at 0000018BE872DEE0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.309 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6076.TorchMultiply,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 96, 1, 1, strides=[96, 1, 96, 96], requires_grad=0, device=cpu)):
                                        %mul_func.7 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6075.QFunctional = prim::GetAttr[name="mul_func"](%self.309)
                                        %activation_post_process.21 : __torch__.torch.nn.modules.linear.___torch_mangle_6074.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.7)
                                        %5 : float = prim::Constant[value=0.0065461643971502781](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.81 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.21)
                                        return (%input.81)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6075.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6074.Identity object at 0000018BE872DE60>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6074.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.311 : __torch__.torch.nn.modules.linear.___torch_mangle_6074.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6080.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6078.Conv2d object at 0000018BE872FFE0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6079.Identity object at 0000018BE872E560>
                              }
                              methods {
                                method forward {
                                  graph(%self.313 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6080.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                    %bn.37 : __torch__.torch.nn.modules.linear.___torch_mangle_6079.Identity = prim::GetAttr[name="bn"](%self.313)
                                    %conv.65 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6078.Conv2d = prim::GetAttr[name="conv"](%self.313)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.65, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.37)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6078.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 32
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B1F0>
                                    scale = 0.12938554584980011
                                    zero_point = 61
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6078.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6078.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6078.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6078.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.315 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6078.Conv2d,
                                            %1 : QUInt8(1, 96, 28, 38, strides=[102144, 1, 3648, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.73 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.315)
                                        %15 : float = prim::Constant[value=0.12938554584980011](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.73, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6079.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.317 : __torch__.torch.nn.modules.linear.___torch_mangle_6079.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6083.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6082.QFunctional object at 0000018BE8731BE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.319 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6083.TorchAdd,
                                        %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                    %add_func.15 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6082.QFunctional = prim::GetAttr[name="add_func"](%self.319)
                                    %activation_post_process.23 : __torch__.torch.nn.modules.linear.___torch_mangle_6081.Identity = prim::GetAttr[name="activation_post_process"](%add_func.15)
                                    %5 : float = prim::Constant[value=0.28174278140068054](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.83 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.23)
                                    return (%input.83)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6082.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6081.Identity object at 0000018BE8731B60>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6081.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.321 : __torch__.torch.nn.modules.linear.___torch_mangle_6081.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_6276.Sequential {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        fbnetv2_3_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6095.IRFBlock object at 0000018BE873BBE0>
                        fbnetv2_3_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6108.IRFBlock object at 0000018BE8747B60>
                        fbnetv2_3_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6121.IRFBlock object at 0000018BE8752060>
                        fbnetv2_3_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6134.IRFBlock object at 0000018BEA3BBFE0>
                        fbnetv2_3_4 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6155.IRFBlock object at 0000018BEA3CBC60>
                        fbnetv2_3_5 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6179.IRFBlock object at 0000018BEA3DCEE0>
                        fbnetv2_3_6 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6203.IRFBlock object at 0000018BEA3ED260>
                        fbnetv2_3_7 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6227.IRFBlock object at 0000018BEA009660>
                        fbnetv2_3_8 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6251.IRFBlock object at 0000018BEA01CA60>
                        fbnetv2_3_9 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6275.IRFBlock object at 0000018BEA02CAE0>
                      }
                      methods {
                        method forward {
                          graph(%self.323 : __torch__.torch.nn.modules.container.___torch_mangle_6276.Sequential,
                                %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                            %fbnetv2_3_9 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6275.IRFBlock = prim::GetAttr[name="fbnetv2_3_9"](%self.323)
                            %fbnetv2_3_8 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6251.IRFBlock = prim::GetAttr[name="fbnetv2_3_8"](%self.323)
                            %fbnetv2_3_7 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6227.IRFBlock = prim::GetAttr[name="fbnetv2_3_7"](%self.323)
                            %fbnetv2_3_6 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6203.IRFBlock = prim::GetAttr[name="fbnetv2_3_6"](%self.323)
                            %fbnetv2_3_5 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6179.IRFBlock = prim::GetAttr[name="fbnetv2_3_5"](%self.323)
                            %fbnetv2_3_4 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6155.IRFBlock = prim::GetAttr[name="fbnetv2_3_4"](%self.323)
                            %fbnetv2_3_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6134.IRFBlock = prim::GetAttr[name="fbnetv2_3_3"](%self.323)
                            %fbnetv2_3_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6121.IRFBlock = prim::GetAttr[name="fbnetv2_3_2"](%self.323)
                            %fbnetv2_3_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6108.IRFBlock = prim::GetAttr[name="fbnetv2_3_1"](%self.323)
                            %fbnetv2_3_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6095.IRFBlock = prim::GetAttr[name="fbnetv2_3_0"](%self.323)
                            %22 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_0, %1)
                            %23 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_1, %22)
                            %24 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_2, %23)
                            %25 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_3, %24)
                            %26 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_4, %25)
                            %27 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_5, %26)
                            %28 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_6, %27)
                            %29 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_7, %28)
                            %30 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_8, %29)
                            %31 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_9, %30)
                            return (%31)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6095.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6089.ConvBNRelu object at 0000018BE8734860>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6091.ConvBNRelu object at 0000018BE8735760>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6094.ConvBNRelu object at 0000018BE873A560>
                          }
                          methods {
                            method forward {
                              graph(%self.325 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6095.IRFBlock,
                                    %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                %pwl.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6094.ConvBNRelu = prim::GetAttr[name="pwl"](%self.325)
                                %dw.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6091.ConvBNRelu = prim::GetAttr[name="dw"](%self.325)
                                %pw.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6089.ConvBNRelu = prim::GetAttr[name="pw"](%self.325)
                                %8 : Tensor = prim::CallMethod[name="forward"](%pw.17, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%dw.29, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pwl.21, %9)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6089.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6086.ConvReLU2d object at 0000018BE8733BE0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6087.Identity object at 0000018BE8733060>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6088.Identity object at 0000018BE8734E60>
                              }
                              methods {
                                method forward {
                                  graph(%self.327 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6089.ConvBNRelu,
                                        %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                    %relu.27 : __torch__.torch.nn.modules.linear.___torch_mangle_6088.Identity = prim::GetAttr[name="relu"](%self.327)
                                    %bn.39 : __torch__.torch.nn.modules.linear.___torch_mangle_6087.Identity = prim::GetAttr[name="bn"](%self.327)
                                    %conv.67 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6086.ConvReLU2d = prim::GetAttr[name="conv"](%self.327)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.67, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.39)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.27)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6086.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 32
                                    out_channels = 128
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B670>
                                    scale = 0.054890166968107224
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6086.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6086.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6086.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6086.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.329 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6086.ConvReLU2d,
                                            %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                        %_packed_params.75 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.329)
                                        %15 : float = prim::Constant[value=0.054890166968107224](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.85 : QUInt8(1, 128, 28, 38, strides=[136192, 1, 4864, 128], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.75, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.85)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6087.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.331 : __torch__.torch.nn.modules.linear.___torch_mangle_6087.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6088.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.333 : __torch__.torch.nn.modules.linear.___torch_mangle_6088.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6091.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6090.Conv2d object at 0000018BE8734960>
                              }
                              methods {
                                method forward {
                                  graph(%self.335 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6091.ConvBNRelu,
                                        %1 : QUInt8(1, 128, 28, 38, strides=[136192, 1, 4864, 128], requires_grad=0, device=cpu)):
                                    %conv.69 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6090.Conv2d = prim::GetAttr[name="conv"](%self.335)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.69, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6090.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 128
                                    out_channels = 128
                                    kernel_size = (5, 5)
                                    stride = (2, 2)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 128
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3AE70>
                                    scale = 0.039220698177814484
                                    zero_point = 73
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6090.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6090.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6090.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6090.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.337 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6090.Conv2d,
                                            %1 : QUInt8(1, 128, 28, 38, strides=[136192, 1, 4864, 128], requires_grad=0, device=cpu)):
                                        %_packed_params.77 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.337)
                                        %15 : float = prim::Constant[value=0.039220698177814484](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=73](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.87 : QUInt8(1, 128, 14, 19, strides=[34048, 1, 2432, 128], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.77, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.87)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6094.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6092.Conv2d object at 0000018BE8737C60>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6093.Identity object at 0000018BE8739A60>
                              }
                              methods {
                                method forward {
                                  graph(%self.339 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6094.ConvBNRelu,
                                        %1 : QUInt8(1, 128, 14, 19, strides=[34048, 1, 2432, 128], requires_grad=0, device=cpu)):
                                    %bn.41 : __torch__.torch.nn.modules.linear.___torch_mangle_6093.Identity = prim::GetAttr[name="bn"](%self.339)
                                    %conv.71 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6092.Conv2d = prim::GetAttr[name="conv"](%self.339)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.71, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.41)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6092.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 128
                                    out_channels = 64
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3BA70>
                                    scale = 0.22968432307243347
                                    zero_point = 56
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6092.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6092.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6092.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6092.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.341 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6092.Conv2d,
                                            %1 : QUInt8(1, 128, 14, 19, strides=[34048, 1, 2432, 128], requires_grad=0, device=cpu)):
                                        %_packed_params.79 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.341)
                                        %15 : float = prim::Constant[value=0.22968432307243347](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=56](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.89 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.79, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.89)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6093.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.343 : __torch__.torch.nn.modules.linear.___torch_mangle_6093.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6108.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6099.ConvBNRelu object at 0000018BE873F2E0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6101.ConvBNRelu object at 0000018BE873FD60>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6104.ConvBNRelu object at 0000018BE87435E0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6107.TorchAdd object at 0000018BE8747AE0>
                          }
                          methods {
                            method forward {
                              graph(%self.345 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6108.IRFBlock,
                                    %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                %res_conn.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6107.TorchAdd = prim::GetAttr[name="res_conn"](%self.345)
                                %pwl.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6104.ConvBNRelu = prim::GetAttr[name="pwl"](%self.345)
                                %dw.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6101.ConvBNRelu = prim::GetAttr[name="dw"](%self.345)
                                %pw.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6099.ConvBNRelu = prim::GetAttr[name="pw"](%self.345)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.19, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.31, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.23, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.17, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6099.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6096.ConvReLU2d object at 0000018BE873AA60>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6097.Identity object at 0000018BE873C8E0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6098.Identity object at 0000018BE873E560>
                              }
                              methods {
                                method forward {
                                  graph(%self.347 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6099.ConvBNRelu,
                                        %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                    %relu.29 : __torch__.torch.nn.modules.linear.___torch_mangle_6098.Identity = prim::GetAttr[name="relu"](%self.347)
                                    %bn.43 : __torch__.torch.nn.modules.linear.___torch_mangle_6097.Identity = prim::GetAttr[name="bn"](%self.347)
                                    %conv.73 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6096.ConvReLU2d = prim::GetAttr[name="conv"](%self.347)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.73, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.43)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.29)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6096.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 64
                                    out_channels = 192
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A1F0>
                                    scale = 0.040818940848112106
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6096.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6096.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6096.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6096.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.349 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6096.ConvReLU2d,
                                            %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                        %_packed_params.81 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.349)
                                        %15 : float = prim::Constant[value=0.040818940848112106](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.91 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.81, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.91)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6097.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.351 : __torch__.torch.nn.modules.linear.___torch_mangle_6097.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6098.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.353 : __torch__.torch.nn.modules.linear.___torch_mangle_6098.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6101.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6100.Conv2d object at 0000018BE873E6E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.355 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6101.ConvBNRelu,
                                        %1 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu)):
                                    %conv.75 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6100.Conv2d = prim::GetAttr[name="conv"](%self.355)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.75, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6100.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 192
                                    out_channels = 192
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 192
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B3F0>
                                    scale = 0.013504836708307266
                                    zero_point = 64
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6100.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6100.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6100.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6100.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.357 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6100.Conv2d,
                                            %1 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu)):
                                        %_packed_params.83 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.357)
                                        %15 : float = prim::Constant[value=0.013504836708307266](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.93 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.83, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.93)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6104.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6102.Conv2d object at 0000018BE8740C60>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6103.Identity object at 0000018BE87425E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.359 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6104.ConvBNRelu,
                                        %1 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu)):
                                    %bn.45 : __torch__.torch.nn.modules.linear.___torch_mangle_6103.Identity = prim::GetAttr[name="bn"](%self.359)
                                    %conv.77 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6102.Conv2d = prim::GetAttr[name="conv"](%self.359)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.77, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.45)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6102.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 192
                                    out_channels = 64
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3AEF0>
                                    scale = 0.16801944375038147
                                    zero_point = 67
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6102.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6102.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6102.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6102.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.361 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6102.Conv2d,
                                            %1 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu)):
                                        %_packed_params.85 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.361)
                                        %15 : float = prim::Constant[value=0.16801944375038147](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=67](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.85, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6103.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.363 : __torch__.torch.nn.modules.linear.___torch_mangle_6103.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6107.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6106.QFunctional object at 0000018BE87454E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.365 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6107.TorchAdd,
                                        %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                    %add_func.17 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6106.QFunctional = prim::GetAttr[name="add_func"](%self.365)
                                    %activation_post_process.25 : __torch__.torch.nn.modules.linear.___torch_mangle_6105.Identity = prim::GetAttr[name="activation_post_process"](%add_func.17)
                                    %5 : float = prim::Constant[value=0.23104783892631531](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=58](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.95 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.25)
                                    return (%input.95)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6106.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6105.Identity object at 0000018BE8744D60>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6105.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.367 : __torch__.torch.nn.modules.linear.___torch_mangle_6105.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6121.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6112.ConvBNRelu object at 0000018BE87495E0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6114.ConvBNRelu object at 0000018BE8749A60>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6117.ConvBNRelu object at 0000018BE874CA60>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6120.TorchAdd object at 0000018BE8751FE0>
                          }
                          methods {
                            method forward {
                              graph(%self.369 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6121.IRFBlock,
                                    %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                %res_conn.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6120.TorchAdd = prim::GetAttr[name="res_conn"](%self.369)
                                %pwl.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6117.ConvBNRelu = prim::GetAttr[name="pwl"](%self.369)
                                %dw.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6114.ConvBNRelu = prim::GetAttr[name="dw"](%self.369)
                                %pw.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6112.ConvBNRelu = prim::GetAttr[name="pw"](%self.369)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.21, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.33, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.25, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.19, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6112.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6109.ConvReLU2d object at 0000018BE8746B60>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6110.Identity object at 0000018BE8746BE0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6111.Identity object at 0000018BE8748660>
                              }
                              methods {
                                method forward {
                                  graph(%self.371 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6112.ConvBNRelu,
                                        %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                    %relu.31 : __torch__.torch.nn.modules.linear.___torch_mangle_6111.Identity = prim::GetAttr[name="relu"](%self.371)
                                    %bn.47 : __torch__.torch.nn.modules.linear.___torch_mangle_6110.Identity = prim::GetAttr[name="bn"](%self.371)
                                    %conv.79 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6109.ConvReLU2d = prim::GetAttr[name="conv"](%self.371)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.79, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.47)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.31)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6109.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 64
                                    out_channels = 192
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3AAF0>
                                    scale = 0.033009432256221771
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6109.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6109.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6109.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6109.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.373 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6109.ConvReLU2d,
                                            %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                        %_packed_params.87 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.373)
                                        %15 : float = prim::Constant[value=0.033009432256221771](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.97 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.87, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.97)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6110.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.375 : __torch__.torch.nn.modules.linear.___torch_mangle_6110.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6111.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.377 : __torch__.torch.nn.modules.linear.___torch_mangle_6111.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6114.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6113.Conv2d object at 0000018BE87497E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.379 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6114.ConvBNRelu,
                                        %1 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu)):
                                    %conv.81 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6113.Conv2d = prim::GetAttr[name="conv"](%self.379)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.81, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6113.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 192
                                    out_channels = 192
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 192
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B6F0>
                                    scale = 0.011241423897445202
                                    zero_point = 72
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6113.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6113.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6113.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6113.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.381 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6113.Conv2d,
                                            %1 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu)):
                                        %_packed_params.89 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.381)
                                        %15 : float = prim::Constant[value=0.011241423897445202](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=72](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.99 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.89, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.99)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6117.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6115.Conv2d object at 0000018BE874A360>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6116.Identity object at 0000018BE874C560>
                              }
                              methods {
                                method forward {
                                  graph(%self.383 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6117.ConvBNRelu,
                                        %1 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu)):
                                    %bn.49 : __torch__.torch.nn.modules.linear.___torch_mangle_6116.Identity = prim::GetAttr[name="bn"](%self.383)
                                    %conv.83 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6115.Conv2d = prim::GetAttr[name="conv"](%self.383)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.83, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.49)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6115.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 192
                                    out_channels = 64
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A570>
                                    scale = 0.1849026083946228
                                    zero_point = 79
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6115.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6115.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6115.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6115.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.385 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6115.Conv2d,
                                            %1 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu)):
                                        %_packed_params.91 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.385)
                                        %15 : float = prim::Constant[value=0.1849026083946228](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=79](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.91, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6116.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.387 : __torch__.torch.nn.modules.linear.___torch_mangle_6116.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6120.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6119.QFunctional object at 0000018BE87514E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.389 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6120.TorchAdd,
                                        %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                    %add_func.19 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6119.QFunctional = prim::GetAttr[name="add_func"](%self.389)
                                    %activation_post_process.27 : __torch__.torch.nn.modules.linear.___torch_mangle_6118.Identity = prim::GetAttr[name="activation_post_process"](%add_func.19)
                                    %5 : float = prim::Constant[value=0.22170177102088928](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.101 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.27)
                                    return (%input.101)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6119.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6118.Identity object at 0000018BE874F4E0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6118.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.391 : __torch__.torch.nn.modules.linear.___torch_mangle_6118.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6134.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6125.ConvBNRelu object at 0000018BE8753760>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6127.ConvBNRelu object at 0000018BE8755960>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6130.ConvBNRelu object at 0000018BEA3B8360>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6133.TorchAdd object at 0000018BEA3BB5E0>
                          }
                          methods {
                            method forward {
                              graph(%self.393 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6134.IRFBlock,
                                    %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                %res_conn.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6133.TorchAdd = prim::GetAttr[name="res_conn"](%self.393)
                                %pwl.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6130.ConvBNRelu = prim::GetAttr[name="pwl"](%self.393)
                                %dw.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6127.ConvBNRelu = prim::GetAttr[name="dw"](%self.393)
                                %pw.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6125.ConvBNRelu = prim::GetAttr[name="pw"](%self.393)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.23, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.35, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.27, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.21, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6125.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6122.ConvReLU2d object at 0000018BE8750360>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6123.Identity object at 0000018BE8753360>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6124.Identity object at 0000018BE87540E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.395 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6125.ConvBNRelu,
                                        %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                    %relu.33 : __torch__.torch.nn.modules.linear.___torch_mangle_6124.Identity = prim::GetAttr[name="relu"](%self.395)
                                    %bn.51 : __torch__.torch.nn.modules.linear.___torch_mangle_6123.Identity = prim::GetAttr[name="bn"](%self.395)
                                    %conv.85 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6122.ConvReLU2d = prim::GetAttr[name="conv"](%self.395)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.85, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.51)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.33)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6122.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 64
                                    out_channels = 192
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3AB70>
                                    scale = 0.021955253556370735
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6122.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6122.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6122.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6122.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.397 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6122.ConvReLU2d,
                                            %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                        %_packed_params.93 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.397)
                                        %15 : float = prim::Constant[value=0.021955253556370735](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.103 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.93, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.103)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6123.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.399 : __torch__.torch.nn.modules.linear.___torch_mangle_6123.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6124.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.401 : __torch__.torch.nn.modules.linear.___torch_mangle_6124.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6127.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6126.Conv2d object at 0000018BE87521E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.403 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6127.ConvBNRelu,
                                        %1 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu)):
                                    %conv.87 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6126.Conv2d = prim::GetAttr[name="conv"](%self.403)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.87, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6126.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 192
                                    out_channels = 192
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 192
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A8F0>
                                    scale = 0.0094504542648792267
                                    zero_point = 70
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6126.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6126.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6126.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6126.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.405 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6126.Conv2d,
                                            %1 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu)):
                                        %_packed_params.95 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.405)
                                        %15 : float = prim::Constant[value=0.0094504542648792267](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=70](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.105 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.95, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.105)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6130.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6128.Conv2d object at 0000018BE8754460>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6129.Identity object at 0000018BEA3B94E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.407 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6130.ConvBNRelu,
                                        %1 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu)):
                                    %bn.53 : __torch__.torch.nn.modules.linear.___torch_mangle_6129.Identity = prim::GetAttr[name="bn"](%self.407)
                                    %conv.89 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6128.Conv2d = prim::GetAttr[name="conv"](%self.407)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.89, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.53)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6128.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 192
                                    out_channels = 64
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B170>
                                    scale = 0.12464980036020279
                                    zero_point = 65
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6128.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6128.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6128.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6128.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.409 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6128.Conv2d,
                                            %1 : QUInt8(1, 192, 14, 19, strides=[51072, 1, 3648, 192], requires_grad=0, device=cpu)):
                                        %_packed_params.97 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.409)
                                        %15 : float = prim::Constant[value=0.12464980036020279](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.97, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6129.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.411 : __torch__.torch.nn.modules.linear.___torch_mangle_6129.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6133.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6132.QFunctional object at 0000018BEA3B9AE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.413 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6133.TorchAdd,
                                        %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                    %add_func.21 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6132.QFunctional = prim::GetAttr[name="add_func"](%self.413)
                                    %activation_post_process.29 : __torch__.torch.nn.modules.linear.___torch_mangle_6131.Identity = prim::GetAttr[name="activation_post_process"](%add_func.21)
                                    %5 : float = prim::Constant[value=0.23290327191352844](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.107 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.29)
                                    return (%input.107)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6132.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6131.Identity object at 0000018BEA3B8560>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6131.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.415 : __torch__.torch.nn.modules.linear.___torch_mangle_6131.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6155.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6138.ConvBNRelu object at 0000018BEA3BCD60>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6140.ConvBNRelu object at 0000018BEA3BC260>
                            se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6151.SEModule object at 0000018BEA3C7AE0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6154.ConvBNRelu object at 0000018BEA3C87E0>
                          }
                          methods {
                            method forward {
                              graph(%self.417 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6155.IRFBlock,
                                    %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                %pwl.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6154.ConvBNRelu = prim::GetAttr[name="pwl"](%self.417)
                                %se.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6151.SEModule = prim::GetAttr[name="se"](%self.417)
                                %dw.37 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6140.ConvBNRelu = prim::GetAttr[name="dw"](%self.417)
                                %pw.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6138.ConvBNRelu = prim::GetAttr[name="pw"](%self.417)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.25, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.37, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%se.19, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%pwl.29, %12)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6138.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6135.ConvReLU2d object at 0000018BEA3BA660>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6136.Identity object at 0000018BEA3BA860>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6137.Identity object at 0000018BEA3BB660>
                              }
                              methods {
                                method forward {
                                  graph(%self.419 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6138.ConvBNRelu,
                                        %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                    %relu.35 : __torch__.torch.nn.modules.linear.___torch_mangle_6137.Identity = prim::GetAttr[name="relu"](%self.419)
                                    %bn.55 : __torch__.torch.nn.modules.linear.___torch_mangle_6136.Identity = prim::GetAttr[name="bn"](%self.419)
                                    %conv.91 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6135.ConvReLU2d = prim::GetAttr[name="conv"](%self.419)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.91, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.55)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.35)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6135.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 64
                                    out_channels = 256
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3BD70>
                                    scale = 0.23348763585090637
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6135.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6135.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6135.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6135.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.421 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6135.ConvReLU2d,
                                            %1 : QUInt8(1, 64, 14, 19, strides=[17024, 1, 1216, 64], requires_grad=0, device=cpu)):
                                        %_packed_params.99 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.421)
                                        %15 : float = prim::Constant[value=0.23348763585090637](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.109 : QUInt8(1, 256, 14, 19, strides=[68096, 1, 4864, 256], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.99, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.109)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6136.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.423 : __torch__.torch.nn.modules.linear.___torch_mangle_6136.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6137.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.425 : __torch__.torch.nn.modules.linear.___torch_mangle_6137.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6140.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6139.Conv2d object at 0000018BEA3BC1E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.427 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6140.ConvBNRelu,
                                        %1 : QUInt8(1, 256, 14, 19, strides=[68096, 1, 4864, 256], requires_grad=0, device=cpu)):
                                    %conv.93 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6139.Conv2d = prim::GetAttr[name="conv"](%self.427)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.93, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6139.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 256
                                    out_channels = 256
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 256
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A4F0>
                                    scale = 0.46659347414970398
                                    zero_point = 53
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6139.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6139.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6139.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6139.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.429 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6139.Conv2d,
                                            %1 : QUInt8(1, 256, 14, 19, strides=[68096, 1, 4864, 256], requires_grad=0, device=cpu)):
                                        %_packed_params.101 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.429)
                                        %15 : float = prim::Constant[value=0.46659347414970398](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=53](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %x.11 : QUInt8(1, 256, 14, 19, strides=[68096, 1, 4864, 256], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.101, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%x.11)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6151.SEModule {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6141.AdaptiveAvgPool2d object at 0000018BEA3BC9E0>
                                se = <__torch__.torch.nn.modules.container.___torch_mangle_6147.Sequential object at 0000018BEA3C75E0>
                                mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6150.TorchMultiply object at 0000018BEA3C7A60>
                              }
                              methods {
                                method forward {
                                  graph(%self.431 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6151.SEModule,
                                        %1 : QUInt8(1, 256, 14, 19, strides=[68096, 1, 4864, 256], requires_grad=0, device=cpu)):
                                    %mul.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6150.TorchMultiply = prim::GetAttr[name="mul"](%self.431)
                                    %se.17 : __torch__.torch.nn.modules.container.___torch_mangle_6147.Sequential = prim::GetAttr[name="se"](%self.431)
                                    %avg_pool.9 : __torch__.torch.nn.modules.pooling.___torch_mangle_6141.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.431)
                                    %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.9, %1)
                                    %33 : Tensor = prim::CallMethod[name="forward"](%se.17, %32)
                                    %34 : Tensor = prim::CallMethod[name="forward"](%mul.9, %1, %33)
                                    return (%34)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.pooling.___torch_mangle_6141.AdaptiveAvgPool2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.433 : __torch__.torch.nn.modules.pooling.___torch_mangle_6141.AdaptiveAvgPool2d,
                                            %1 : QUInt8(1, 256, 14, 19, strides=[68096, 1, 4864, 256], requires_grad=0, device=cpu)):
                                        %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.avg_pool
                                        %input.111 : QUInt8(1, 256, 1, 1, strides=[256, 1, 256, 256], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        return (%input.111)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.container.___torch_mangle_6147.Sequential {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6144.ConvBNRelu object at 0000018BEA3C3B60>
                                    1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6145.Conv2d object at 0000018BEA3C3FE0>
                                    2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6146.Sigmoid object at 0000018BEA3C40E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.435 : __torch__.torch.nn.modules.container.___torch_mangle_6147.Sequential,
                                            %1 : QUInt8(1, 256, 1, 1, strides=[256, 1, 256, 256], requires_grad=0, device=cpu)):
                                        %_2.9 : __torch__.torch.nn.modules.activation.___torch_mangle_6146.Sigmoid = prim::GetAttr[name="2"](%self.435)
                                        %_1.9 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6145.Conv2d = prim::GetAttr[name="1"](%self.435)
                                        %_0.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6144.ConvBNRelu = prim::GetAttr[name="0"](%self.435)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%_0.11, %1)
                                        %9 : Tensor = prim::CallMethod[name="forward"](%_1.9, %8)
                                        %10 : Tensor = prim::CallMethod[name="forward"](%_2.9, %9)
                                        return (%10)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6144.ConvBNRelu {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6142.ConvReLU2d object at 0000018BEA3BEA60>
                                        relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6143.Identity object at 0000018BEA3C1660>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.437 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6144.ConvBNRelu,
                                                %1 : QUInt8(1, 256, 1, 1, strides=[256, 1, 256, 256], requires_grad=0, device=cpu)):
                                            %relu.37 : __torch__.torch.nn.modules.linear.___torch_mangle_6143.Identity = prim::GetAttr[name="relu"](%self.437)
                                            %conv.95 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6142.ConvReLU2d = prim::GetAttr[name="conv"](%self.437)
                                            %6 : Tensor = prim::CallMethod[name="forward"](%conv.95, %1)
                                            %7 : NoneType = prim::CallMethod[name="forward"](%relu.37)
                                            return (%6)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6142.ConvReLU2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 256
                                            out_channels = 64
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B470>
                                            scale = 0.037842597812414169
                                            zero_point = 0
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6142.ConvReLU2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6142.ConvReLU2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6142.ConvReLU2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6142.ConvReLU2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.439 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6142.ConvReLU2d,
                                                    %1 : QUInt8(1, 256, 1, 1, strides=[256, 1, 256, 256], requires_grad=0, device=cpu)):
                                                %_packed_params.103 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.439)
                                                %15 : float = prim::Constant[value=0.037842597812414169](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.113 : QUInt8(1, 64, 1, 1, strides=[64, 1, 64, 64], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.103, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.113)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6143.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.441 : __torch__.torch.nn.modules.linear.___torch_mangle_6143.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6145.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 64
                                        out_channels = 256
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3BDF0>
                                        scale = 0.0612945556640625
                                        zero_point = 96
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6145.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6145.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6145.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6145.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.443 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6145.Conv2d,
                                                %1 : QUInt8(1, 64, 1, 1, strides=[64, 1, 64, 64], requires_grad=0, device=cpu)):
                                            %_packed_params.105 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.443)
                                            %15 : float = prim::Constant[value=0.0612945556640625](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=96](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.115 : QUInt8(1, 256, 1, 1, strides=[256, 1, 256, 256], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.105, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.115)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.activation.___torch_mangle_6146.Sigmoid {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.445 : __torch__.torch.nn.modules.activation.___torch_mangle_6146.Sigmoid,
                                                %1 : QUInt8(1, 256, 1, 1, strides=[256, 1, 256, 256], requires_grad=0, device=cpu)):
                                            %2 : QUInt8(1, 256, 1, 1, strides=[256, 1, 256, 256], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                            return (%2)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6150.TorchMultiply {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6149.QFunctional object at 0000018BEA3C78E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.447 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6150.TorchMultiply,
                                            %1 : QUInt8(1, 256, 14, 19, strides=[68096, 1, 4864, 256], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 256, 1, 1, strides=[256, 1, 256, 256], requires_grad=0, device=cpu)):
                                        %mul_func.9 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6149.QFunctional = prim::GetAttr[name="mul_func"](%self.447)
                                        %activation_post_process.31 : __torch__.torch.nn.modules.linear.___torch_mangle_6148.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.9)
                                        %5 : float = prim::Constant[value=0.019502054899930954](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=54](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.117 : QUInt8(1, 256, 14, 19, strides=[68096, 1, 4864, 256], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.31)
                                        return (%input.117)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6149.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6148.Identity object at 0000018BEA3C6260>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6148.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.449 : __torch__.torch.nn.modules.linear.___torch_mangle_6148.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6154.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6152.Conv2d object at 0000018BEA3C9260>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6153.Identity object at 0000018BEA3C97E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.451 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6154.ConvBNRelu,
                                        %1 : QUInt8(1, 256, 14, 19, strides=[68096, 1, 4864, 256], requires_grad=0, device=cpu)):
                                    %bn.57 : __torch__.torch.nn.modules.linear.___torch_mangle_6153.Identity = prim::GetAttr[name="bn"](%self.451)
                                    %conv.97 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6152.Conv2d = prim::GetAttr[name="conv"](%self.451)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.97, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.57)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6152.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 256
                                    out_channels = 112
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A870>
                                    scale = 0.03663257509469986
                                    zero_point = 64
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6152.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6152.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6152.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6152.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.453 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6152.Conv2d,
                                            %1 : QUInt8(1, 256, 14, 19, strides=[68096, 1, 4864, 256], requires_grad=0, device=cpu)):
                                        %_packed_params.107 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.453)
                                        %15 : float = prim::Constant[value=0.03663257509469986](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.119 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.107, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.119)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6153.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.455 : __torch__.torch.nn.modules.linear.___torch_mangle_6153.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6179.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6159.ConvBNRelu object at 0000018BEA3CDAE0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6161.ConvBNRelu object at 0000018BEA3CEEE0>
                            se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6172.SEModule object at 0000018BEA3D9D60>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6175.ConvBNRelu object at 0000018BEA3DB160>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6178.TorchAdd object at 0000018BEA3DBA60>
                          }
                          methods {
                            method forward {
                              graph(%self.457 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6179.IRFBlock,
                                    %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                %res_conn.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6178.TorchAdd = prim::GetAttr[name="res_conn"](%self.457)
                                %pwl.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6175.ConvBNRelu = prim::GetAttr[name="pwl"](%self.457)
                                %se.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6172.SEModule = prim::GetAttr[name="se"](%self.457)
                                %dw.39 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6161.ConvBNRelu = prim::GetAttr[name="dw"](%self.457)
                                %pw.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6159.ConvBNRelu = prim::GetAttr[name="pw"](%self.457)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pw.27, %1)
                                %13 : Tensor = prim::CallMethod[name="forward"](%dw.39, %12)
                                %14 : Tensor = prim::CallMethod[name="forward"](%se.23, %13)
                                %15 : Tensor = prim::CallMethod[name="forward"](%pwl.31, %14)
                                %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.23, %15, %1)
                                return (%16)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6159.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6156.ConvReLU2d object at 0000018BEA3CADE0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6157.Identity object at 0000018BEA3CAFE0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6158.Identity object at 0000018BEA3CDFE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.459 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6159.ConvBNRelu,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %relu.39 : __torch__.torch.nn.modules.linear.___torch_mangle_6158.Identity = prim::GetAttr[name="relu"](%self.459)
                                    %bn.59 : __torch__.torch.nn.modules.linear.___torch_mangle_6157.Identity = prim::GetAttr[name="bn"](%self.459)
                                    %conv.99 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6156.ConvReLU2d = prim::GetAttr[name="conv"](%self.459)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.99, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.59)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.39)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6156.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 112
                                    out_channels = 336
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3AC70>
                                    scale = 0.025703277438879013
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6156.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6156.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6156.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6156.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.461 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6156.ConvReLU2d,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %_packed_params.109 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.461)
                                        %15 : float = prim::Constant[value=0.025703277438879013](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.121 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.109, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.121)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6157.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.463 : __torch__.torch.nn.modules.linear.___torch_mangle_6157.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6158.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.465 : __torch__.torch.nn.modules.linear.___torch_mangle_6158.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6161.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6160.Conv2d object at 0000018BEA3CDD60>
                              }
                              methods {
                                method forward {
                                  graph(%self.467 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6161.ConvBNRelu,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %conv.101 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6160.Conv2d = prim::GetAttr[name="conv"](%self.467)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.101, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6160.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 336
                                    out_channels = 336
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 336
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3BB70>
                                    scale = 0.012948849238455296
                                    zero_point = 67
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6160.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6160.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6160.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6160.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.469 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6160.Conv2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %_packed_params.111 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.469)
                                        %15 : float = prim::Constant[value=0.012948849238455296](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=67](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %x.13 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.111, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%x.13)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6172.SEModule {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6162.AdaptiveAvgPool2d object at 0000018BEA3CE160>
                                se = <__torch__.torch.nn.modules.container.___torch_mangle_6168.Sequential object at 0000018BEA3D6A60>
                                mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6171.TorchMultiply object at 0000018BEA3D9C60>
                              }
                              methods {
                                method forward {
                                  graph(%self.471 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6172.SEModule,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %mul.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6171.TorchMultiply = prim::GetAttr[name="mul"](%self.471)
                                    %se.21 : __torch__.torch.nn.modules.container.___torch_mangle_6168.Sequential = prim::GetAttr[name="se"](%self.471)
                                    %avg_pool.11 : __torch__.torch.nn.modules.pooling.___torch_mangle_6162.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.471)
                                    %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.11, %1)
                                    %33 : Tensor = prim::CallMethod[name="forward"](%se.21, %32)
                                    %34 : Tensor = prim::CallMethod[name="forward"](%mul.11, %1, %33)
                                    return (%34)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.pooling.___torch_mangle_6162.AdaptiveAvgPool2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.473 : __torch__.torch.nn.modules.pooling.___torch_mangle_6162.AdaptiveAvgPool2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.avg_pool
                                        %input.123 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        return (%input.123)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.container.___torch_mangle_6168.Sequential {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6165.ConvBNRelu object at 0000018BEA3D3E60>
                                    1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6166.Conv2d object at 0000018BEA3D57E0>
                                    2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6167.Sigmoid object at 0000018BEA3D5B60>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.475 : __torch__.torch.nn.modules.container.___torch_mangle_6168.Sequential,
                                            %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                        %_2.11 : __torch__.torch.nn.modules.activation.___torch_mangle_6167.Sigmoid = prim::GetAttr[name="2"](%self.475)
                                        %_1.11 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6166.Conv2d = prim::GetAttr[name="1"](%self.475)
                                        %_0.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6165.ConvBNRelu = prim::GetAttr[name="0"](%self.475)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%_0.13, %1)
                                        %9 : Tensor = prim::CallMethod[name="forward"](%_1.11, %8)
                                        %10 : Tensor = prim::CallMethod[name="forward"](%_2.11, %9)
                                        return (%10)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6165.ConvBNRelu {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6163.ConvReLU2d object at 0000018BEA3D15E0>
                                        relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6164.Identity object at 0000018BEA3D0AE0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.477 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6165.ConvBNRelu,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %relu.41 : __torch__.torch.nn.modules.linear.___torch_mangle_6164.Identity = prim::GetAttr[name="relu"](%self.477)
                                            %conv.103 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6163.ConvReLU2d = prim::GetAttr[name="conv"](%self.477)
                                            %6 : Tensor = prim::CallMethod[name="forward"](%conv.103, %1)
                                            %7 : NoneType = prim::CallMethod[name="forward"](%relu.41)
                                            return (%6)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6163.ConvReLU2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 336
                                            out_channels = 88
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3AF70>
                                            scale = 1.1920928955078125e-07
                                            zero_point = 0
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6163.ConvReLU2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6163.ConvReLU2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6163.ConvReLU2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6163.ConvReLU2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.479 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6163.ConvReLU2d,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %_packed_params.113 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.479)
                                                %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.125 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.113, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.125)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6164.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.481 : __torch__.torch.nn.modules.linear.___torch_mangle_6164.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6166.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 88
                                        out_channels = 336
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B970>
                                        scale = 0.00021384170395322144
                                        zero_point = 57
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6166.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6166.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6166.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6166.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.483 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6166.Conv2d,
                                                %1 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu)):
                                            %_packed_params.115 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.483)
                                            %15 : float = prim::Constant[value=0.00021384170395322144](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=57](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.127 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.115, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.127)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.activation.___torch_mangle_6167.Sigmoid {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.485 : __torch__.torch.nn.modules.activation.___torch_mangle_6167.Sigmoid,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                            return (%2)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6171.TorchMultiply {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6170.QFunctional object at 0000018BEA3D90E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.487 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6171.TorchMultiply,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                        %mul_func.11 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6170.QFunctional = prim::GetAttr[name="mul_func"](%self.487)
                                        %activation_post_process.33 : __torch__.torch.nn.modules.linear.___torch_mangle_6169.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.11)
                                        %5 : float = prim::Constant[value=0.0068242447450757027](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=77](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.129 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.33)
                                        return (%input.129)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6170.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6169.Identity object at 0000018BEA3D6D60>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6169.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.489 : __torch__.torch.nn.modules.linear.___torch_mangle_6169.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6175.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6173.Conv2d object at 0000018BEA3DA0E0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6174.Identity object at 0000018BEA3DBB60>
                              }
                              methods {
                                method forward {
                                  graph(%self.491 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6175.ConvBNRelu,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %bn.61 : __torch__.torch.nn.modules.linear.___torch_mangle_6174.Identity = prim::GetAttr[name="bn"](%self.491)
                                    %conv.105 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6173.Conv2d = prim::GetAttr[name="conv"](%self.491)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.105, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.61)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6173.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 336
                                    out_channels = 112
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A170>
                                    scale = 0.023744378238916397
                                    zero_point = 68
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6173.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6173.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6173.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6173.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.493 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6173.Conv2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %_packed_params.117 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.493)
                                        %15 : float = prim::Constant[value=0.023744378238916397](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=68](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.117, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6174.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.495 : __torch__.torch.nn.modules.linear.___torch_mangle_6174.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6178.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6177.QFunctional object at 0000018BEA3DB660>
                              }
                              methods {
                                method forward {
                                  graph(%self.497 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6178.TorchAdd,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %add_func.23 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6177.QFunctional = prim::GetAttr[name="add_func"](%self.497)
                                    %activation_post_process.35 : __torch__.torch.nn.modules.linear.___torch_mangle_6176.Identity = prim::GetAttr[name="activation_post_process"](%add_func.23)
                                    %5 : float = prim::Constant[value=0.041550789028406143](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.131 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.35)
                                    return (%input.131)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6177.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6176.Identity object at 0000018BEA3DBD60>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6176.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.499 : __torch__.torch.nn.modules.linear.___torch_mangle_6176.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6203.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6183.ConvBNRelu object at 0000018BEA3DF3E0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6185.ConvBNRelu object at 0000018BEA3DFEE0>
                            se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6196.SEModule object at 0000018BEA3E8F60>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6199.ConvBNRelu object at 0000018BEA3ECDE0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6202.TorchAdd object at 0000018BEA3ED060>
                          }
                          methods {
                            method forward {
                              graph(%self.501 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6203.IRFBlock,
                                    %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                %res_conn.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6202.TorchAdd = prim::GetAttr[name="res_conn"](%self.501)
                                %pwl.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6199.ConvBNRelu = prim::GetAttr[name="pwl"](%self.501)
                                %se.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6196.SEModule = prim::GetAttr[name="se"](%self.501)
                                %dw.41 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6185.ConvBNRelu = prim::GetAttr[name="dw"](%self.501)
                                %pw.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6183.ConvBNRelu = prim::GetAttr[name="pw"](%self.501)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pw.29, %1)
                                %13 : Tensor = prim::CallMethod[name="forward"](%dw.41, %12)
                                %14 : Tensor = prim::CallMethod[name="forward"](%se.27, %13)
                                %15 : Tensor = prim::CallMethod[name="forward"](%pwl.33, %14)
                                %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.25, %15, %1)
                                return (%16)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6183.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6180.ConvReLU2d object at 0000018BEA3DD260>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6181.Identity object at 0000018BEA3DD4E0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6182.Identity object at 0000018BEA3DFD60>
                              }
                              methods {
                                method forward {
                                  graph(%self.503 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6183.ConvBNRelu,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %relu.43 : __torch__.torch.nn.modules.linear.___torch_mangle_6182.Identity = prim::GetAttr[name="relu"](%self.503)
                                    %bn.63 : __torch__.torch.nn.modules.linear.___torch_mangle_6181.Identity = prim::GetAttr[name="bn"](%self.503)
                                    %conv.107 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6180.ConvReLU2d = prim::GetAttr[name="conv"](%self.503)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.107, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.63)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.43)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6180.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 112
                                    out_channels = 336
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3BEF0>
                                    scale = 0.02115413174033165
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6180.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6180.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6180.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6180.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.505 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6180.ConvReLU2d,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %_packed_params.119 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.505)
                                        %15 : float = prim::Constant[value=0.02115413174033165](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.133 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.119, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.133)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6181.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.507 : __torch__.torch.nn.modules.linear.___torch_mangle_6181.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6182.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.509 : __torch__.torch.nn.modules.linear.___torch_mangle_6182.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6185.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6184.Conv2d object at 0000018BEA3DF7E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.511 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6185.ConvBNRelu,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %conv.109 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6184.Conv2d = prim::GetAttr[name="conv"](%self.511)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.109, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6184.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 336
                                    out_channels = 336
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 336
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A270>
                                    scale = 0.0069300001487135887
                                    zero_point = 66
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6184.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6184.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6184.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6184.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.513 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6184.Conv2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %_packed_params.121 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.513)
                                        %15 : float = prim::Constant[value=0.0069300001487135887](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %x.15 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.121, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%x.15)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6196.SEModule {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6186.AdaptiveAvgPool2d object at 0000018BEA3E19E0>
                                se = <__torch__.torch.nn.modules.container.___torch_mangle_6192.Sequential object at 0000018BEA3E63E0>
                                mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6195.TorchMultiply object at 0000018BEA3E86E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.515 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6196.SEModule,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %mul.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6195.TorchMultiply = prim::GetAttr[name="mul"](%self.515)
                                    %se.25 : __torch__.torch.nn.modules.container.___torch_mangle_6192.Sequential = prim::GetAttr[name="se"](%self.515)
                                    %avg_pool.13 : __torch__.torch.nn.modules.pooling.___torch_mangle_6186.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.515)
                                    %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.13, %1)
                                    %33 : Tensor = prim::CallMethod[name="forward"](%se.25, %32)
                                    %34 : Tensor = prim::CallMethod[name="forward"](%mul.13, %1, %33)
                                    return (%34)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.pooling.___torch_mangle_6186.AdaptiveAvgPool2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.517 : __torch__.torch.nn.modules.pooling.___torch_mangle_6186.AdaptiveAvgPool2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.avg_pool
                                        %input.135 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        return (%input.135)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.container.___torch_mangle_6192.Sequential {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6189.ConvBNRelu object at 0000018BEA3E6060>
                                    1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6190.Conv2d object at 0000018BEA3E44E0>
                                    2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6191.Sigmoid object at 0000018BEA3E77E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.519 : __torch__.torch.nn.modules.container.___torch_mangle_6192.Sequential,
                                            %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                        %_2.13 : __torch__.torch.nn.modules.activation.___torch_mangle_6191.Sigmoid = prim::GetAttr[name="2"](%self.519)
                                        %_1.13 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6190.Conv2d = prim::GetAttr[name="1"](%self.519)
                                        %_0.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6189.ConvBNRelu = prim::GetAttr[name="0"](%self.519)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%_0.15, %1)
                                        %9 : Tensor = prim::CallMethod[name="forward"](%_1.13, %8)
                                        %10 : Tensor = prim::CallMethod[name="forward"](%_2.13, %9)
                                        return (%10)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6189.ConvBNRelu {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6187.ConvReLU2d object at 0000018BEA3E2760>
                                        relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6188.Identity object at 0000018BEA3E3160>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.521 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6189.ConvBNRelu,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %relu.45 : __torch__.torch.nn.modules.linear.___torch_mangle_6188.Identity = prim::GetAttr[name="relu"](%self.521)
                                            %conv.111 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6187.ConvReLU2d = prim::GetAttr[name="conv"](%self.521)
                                            %6 : Tensor = prim::CallMethod[name="forward"](%conv.111, %1)
                                            %7 : NoneType = prim::CallMethod[name="forward"](%relu.45)
                                            return (%6)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6187.ConvReLU2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 336
                                            out_channels = 88
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3ACF0>
                                            scale = 1.1920928955078125e-07
                                            zero_point = 0
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6187.ConvReLU2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6187.ConvReLU2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6187.ConvReLU2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6187.ConvReLU2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.523 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6187.ConvReLU2d,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %_packed_params.123 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.523)
                                                %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.137 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.123, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.137)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6188.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.525 : __torch__.torch.nn.modules.linear.___torch_mangle_6188.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6190.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 88
                                        out_channels = 336
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3AFF0>
                                        scale = 0.0002809857833199203
                                        zero_point = 56
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6190.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6190.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6190.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6190.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.527 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6190.Conv2d,
                                                %1 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu)):
                                            %_packed_params.125 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.527)
                                            %15 : float = prim::Constant[value=0.0002809857833199203](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=56](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.139 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.125, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.139)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.activation.___torch_mangle_6191.Sigmoid {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.529 : __torch__.torch.nn.modules.activation.___torch_mangle_6191.Sigmoid,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                            return (%2)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6195.TorchMultiply {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6194.QFunctional object at 0000018BEA3E87E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.531 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6195.TorchMultiply,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                        %mul_func.13 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6194.QFunctional = prim::GetAttr[name="mul_func"](%self.531)
                                        %activation_post_process.37 : __torch__.torch.nn.modules.linear.___torch_mangle_6193.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.13)
                                        %5 : float = prim::Constant[value=0.0036316744517534971](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.141 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.37)
                                        return (%input.141)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6194.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6193.Identity object at 0000018BEA3E84E0>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6193.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.533 : __torch__.torch.nn.modules.linear.___torch_mangle_6193.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6199.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6197.Conv2d object at 0000018BEA3EACE0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6198.Identity object at 0000018BEA3EAAE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.535 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6199.ConvBNRelu,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %bn.65 : __torch__.torch.nn.modules.linear.___torch_mangle_6198.Identity = prim::GetAttr[name="bn"](%self.535)
                                    %conv.113 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6197.Conv2d = prim::GetAttr[name="conv"](%self.535)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.113, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.65)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6197.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 336
                                    out_channels = 112
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3AD70>
                                    scale = 0.021655313670635223
                                    zero_point = 60
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6197.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6197.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6197.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6197.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.537 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6197.Conv2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %_packed_params.127 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.537)
                                        %15 : float = prim::Constant[value=0.021655313670635223](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.127, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6198.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.539 : __torch__.torch.nn.modules.linear.___torch_mangle_6198.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6202.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6201.QFunctional object at 0000018BEA3ECA60>
                              }
                              methods {
                                method forward {
                                  graph(%self.541 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6202.TorchAdd,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %add_func.25 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6201.QFunctional = prim::GetAttr[name="add_func"](%self.541)
                                    %activation_post_process.39 : __torch__.torch.nn.modules.linear.___torch_mangle_6200.Identity = prim::GetAttr[name="activation_post_process"](%add_func.25)
                                    %5 : float = prim::Constant[value=0.045002754777669907](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.143 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.39)
                                    return (%input.143)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6201.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6200.Identity object at 0000018BEA3ED7E0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6200.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.543 : __torch__.torch.nn.modules.linear.___torch_mangle_6200.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6227.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6207.ConvBNRelu object at 0000018BEA3F1E60>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6209.ConvBNRelu object at 0000018BEA3F0260>
                            se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6220.SEModule object at 0000018BEA0070E0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6223.ConvBNRelu object at 0000018BEA008360>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6226.TorchAdd object at 0000018BEA0092E0>
                          }
                          methods {
                            method forward {
                              graph(%self.545 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6227.IRFBlock,
                                    %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                %res_conn.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6226.TorchAdd = prim::GetAttr[name="res_conn"](%self.545)
                                %pwl.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6223.ConvBNRelu = prim::GetAttr[name="pwl"](%self.545)
                                %se.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6220.SEModule = prim::GetAttr[name="se"](%self.545)
                                %dw.43 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6209.ConvBNRelu = prim::GetAttr[name="dw"](%self.545)
                                %pw.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6207.ConvBNRelu = prim::GetAttr[name="pw"](%self.545)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pw.31, %1)
                                %13 : Tensor = prim::CallMethod[name="forward"](%dw.43, %12)
                                %14 : Tensor = prim::CallMethod[name="forward"](%se.31, %13)
                                %15 : Tensor = prim::CallMethod[name="forward"](%pwl.35, %14)
                                %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.27, %15, %1)
                                return (%16)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6207.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6204.ConvReLU2d object at 0000018BEA3EF260>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6205.Identity object at 0000018BEA3EFA60>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6206.Identity object at 0000018BEA3EE460>
                              }
                              methods {
                                method forward {
                                  graph(%self.547 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6207.ConvBNRelu,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %relu.47 : __torch__.torch.nn.modules.linear.___torch_mangle_6206.Identity = prim::GetAttr[name="relu"](%self.547)
                                    %bn.67 : __torch__.torch.nn.modules.linear.___torch_mangle_6205.Identity = prim::GetAttr[name="bn"](%self.547)
                                    %conv.115 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6204.ConvReLU2d = prim::GetAttr[name="conv"](%self.547)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.115, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.67)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.47)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6204.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 112
                                    out_channels = 336
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3BAF0>
                                    scale = 0.020147399976849556
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6204.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6204.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6204.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6204.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.549 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6204.ConvReLU2d,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %_packed_params.129 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.549)
                                        %15 : float = prim::Constant[value=0.020147399976849556](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.145 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.129, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.145)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6205.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.551 : __torch__.torch.nn.modules.linear.___torch_mangle_6205.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6206.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.553 : __torch__.torch.nn.modules.linear.___torch_mangle_6206.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6209.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6208.Conv2d object at 0000018BEA3F0EE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.555 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6209.ConvBNRelu,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %conv.117 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6208.Conv2d = prim::GetAttr[name="conv"](%self.555)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.117, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6208.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 336
                                    out_channels = 336
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 336
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3BBF0>
                                    scale = 0.0076149627566337585
                                    zero_point = 67
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6208.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6208.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6208.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6208.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.557 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6208.Conv2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %_packed_params.131 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.557)
                                        %15 : float = prim::Constant[value=0.0076149627566337585](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=67](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %x.17 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.131, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%x.17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6220.SEModule {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6210.AdaptiveAvgPool2d object at 0000018BEA3F2860>
                                se = <__torch__.torch.nn.modules.container.___torch_mangle_6216.Sequential object at 0000018BEA0036E0>
                                mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6219.TorchMultiply object at 0000018BEA005560>
                              }
                              methods {
                                method forward {
                                  graph(%self.559 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6220.SEModule,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %mul.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6219.TorchMultiply = prim::GetAttr[name="mul"](%self.559)
                                    %se.29 : __torch__.torch.nn.modules.container.___torch_mangle_6216.Sequential = prim::GetAttr[name="se"](%self.559)
                                    %avg_pool.15 : __torch__.torch.nn.modules.pooling.___torch_mangle_6210.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.559)
                                    %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.15, %1)
                                    %33 : Tensor = prim::CallMethod[name="forward"](%se.29, %32)
                                    %34 : Tensor = prim::CallMethod[name="forward"](%mul.15, %1, %33)
                                    return (%34)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.pooling.___torch_mangle_6210.AdaptiveAvgPool2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.561 : __torch__.torch.nn.modules.pooling.___torch_mangle_6210.AdaptiveAvgPool2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.avg_pool
                                        %input.147 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        return (%input.147)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.container.___torch_mangle_6216.Sequential {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6213.ConvBNRelu object at 0000018BEA004A60>
                                    1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6214.Conv2d object at 0000018BEA004760>
                                    2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6215.Sigmoid object at 0000018BEA004CE0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.563 : __torch__.torch.nn.modules.container.___torch_mangle_6216.Sequential,
                                            %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                        %_2.15 : __torch__.torch.nn.modules.activation.___torch_mangle_6215.Sigmoid = prim::GetAttr[name="2"](%self.563)
                                        %_1.15 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6214.Conv2d = prim::GetAttr[name="1"](%self.563)
                                        %_0.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6213.ConvBNRelu = prim::GetAttr[name="0"](%self.563)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%_0.17, %1)
                                        %9 : Tensor = prim::CallMethod[name="forward"](%_1.15, %8)
                                        %10 : Tensor = prim::CallMethod[name="forward"](%_2.15, %9)
                                        return (%10)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6213.ConvBNRelu {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6211.ConvReLU2d object at 0000018BEA3F3760>
                                        relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6212.Identity object at 0000018BEA004060>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.565 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6213.ConvBNRelu,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %relu.49 : __torch__.torch.nn.modules.linear.___torch_mangle_6212.Identity = prim::GetAttr[name="relu"](%self.565)
                                            %conv.119 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6211.ConvReLU2d = prim::GetAttr[name="conv"](%self.565)
                                            %6 : Tensor = prim::CallMethod[name="forward"](%conv.119, %1)
                                            %7 : NoneType = prim::CallMethod[name="forward"](%relu.49)
                                            return (%6)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6211.ConvReLU2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 336
                                            out_channels = 88
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B370>
                                            scale = 1.1920928955078125e-07
                                            zero_point = 0
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6211.ConvReLU2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6211.ConvReLU2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6211.ConvReLU2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6211.ConvReLU2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.567 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6211.ConvReLU2d,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %_packed_params.133 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.567)
                                                %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.149 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.133, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.149)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6212.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.569 : __torch__.torch.nn.modules.linear.___torch_mangle_6212.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6214.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 88
                                        out_channels = 336
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3BC70>
                                        scale = 0.00040349783375859261
                                        zero_point = 30
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6214.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6214.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6214.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6214.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.571 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6214.Conv2d,
                                                %1 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu)):
                                            %_packed_params.135 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.571)
                                            %15 : float = prim::Constant[value=0.00040349783375859261](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=30](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.151 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.135, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.151)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.activation.___torch_mangle_6215.Sigmoid {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.573 : __torch__.torch.nn.modules.activation.___torch_mangle_6215.Sigmoid,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                            return (%2)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6219.TorchMultiply {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6218.QFunctional object at 0000018BEA006D60>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.575 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6219.TorchMultiply,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                        %mul_func.15 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6218.QFunctional = prim::GetAttr[name="mul_func"](%self.575)
                                        %activation_post_process.41 : __torch__.torch.nn.modules.linear.___torch_mangle_6217.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.15)
                                        %5 : float = prim::Constant[value=0.0036761518567800522](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=69](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.153 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.41)
                                        return (%input.153)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6218.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6217.Identity object at 0000018BEA005760>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6217.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.577 : __torch__.torch.nn.modules.linear.___torch_mangle_6217.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6223.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6221.Conv2d object at 0000018BEA0073E0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6222.Identity object at 0000018BEA0079E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.579 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6223.ConvBNRelu,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %bn.69 : __torch__.torch.nn.modules.linear.___torch_mangle_6222.Identity = prim::GetAttr[name="bn"](%self.579)
                                    %conv.121 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6221.Conv2d = prim::GetAttr[name="conv"](%self.579)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.121, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.69)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6221.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 336
                                    out_channels = 112
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A3F0>
                                    scale = 0.024841530248522758
                                    zero_point = 63
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6221.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6221.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6221.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6221.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.581 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6221.Conv2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %_packed_params.137 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.581)
                                        %15 : float = prim::Constant[value=0.024841530248522758](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.137, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6222.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.583 : __torch__.torch.nn.modules.linear.___torch_mangle_6222.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6226.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6225.QFunctional object at 0000018BEA009BE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.585 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6226.TorchAdd,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %add_func.27 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6225.QFunctional = prim::GetAttr[name="add_func"](%self.585)
                                    %activation_post_process.43 : __torch__.torch.nn.modules.linear.___torch_mangle_6224.Identity = prim::GetAttr[name="activation_post_process"](%add_func.27)
                                    %5 : float = prim::Constant[value=0.052997715771198273](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=58](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.155 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.43)
                                    return (%input.155)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6225.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6224.Identity object at 0000018BEA0087E0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6224.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.587 : __torch__.torch.nn.modules.linear.___torch_mangle_6224.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6251.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6231.ConvBNRelu object at 0000018BEA00C260>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6233.ConvBNRelu object at 0000018BEA00E460>
                            se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6244.SEModule object at 0000018BEA017360>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6247.ConvBNRelu object at 0000018BEA01A960>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6250.TorchAdd object at 0000018BEA019460>
                          }
                          methods {
                            method forward {
                              graph(%self.589 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6251.IRFBlock,
                                    %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                %res_conn.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6250.TorchAdd = prim::GetAttr[name="res_conn"](%self.589)
                                %pwl.37 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6247.ConvBNRelu = prim::GetAttr[name="pwl"](%self.589)
                                %se.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6244.SEModule = prim::GetAttr[name="se"](%self.589)
                                %dw.45 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6233.ConvBNRelu = prim::GetAttr[name="dw"](%self.589)
                                %pw.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6231.ConvBNRelu = prim::GetAttr[name="pw"](%self.589)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pw.33, %1)
                                %13 : Tensor = prim::CallMethod[name="forward"](%dw.45, %12)
                                %14 : Tensor = prim::CallMethod[name="forward"](%se.35, %13)
                                %15 : Tensor = prim::CallMethod[name="forward"](%pwl.37, %14)
                                %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.29, %15, %1)
                                return (%16)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6231.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6228.ConvReLU2d object at 0000018BEA00C2E0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6229.Identity object at 0000018BEA00BDE0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6230.Identity object at 0000018BEA00CEE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.591 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6231.ConvBNRelu,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %relu.51 : __torch__.torch.nn.modules.linear.___torch_mangle_6230.Identity = prim::GetAttr[name="relu"](%self.591)
                                    %bn.71 : __torch__.torch.nn.modules.linear.___torch_mangle_6229.Identity = prim::GetAttr[name="bn"](%self.591)
                                    %conv.123 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6228.ConvReLU2d = prim::GetAttr[name="conv"](%self.591)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.123, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.71)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.51)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6228.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 112
                                    out_channels = 336
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3A470>
                                    scale = 0.022453382611274719
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6228.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6228.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6228.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6228.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.593 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6228.ConvReLU2d,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %_packed_params.139 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.593)
                                        %15 : float = prim::Constant[value=0.022453382611274719](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.157 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.139, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.157)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6229.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.595 : __torch__.torch.nn.modules.linear.___torch_mangle_6229.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6230.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.597 : __torch__.torch.nn.modules.linear.___torch_mangle_6230.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6233.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6232.Conv2d object at 0000018BEA00EFE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.599 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6233.ConvBNRelu,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %conv.125 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6232.Conv2d = prim::GetAttr[name="conv"](%self.599)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.125, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6232.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 336
                                    out_channels = 336
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 336
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B4F0>
                                    scale = 0.0092360768467187881
                                    zero_point = 58
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6232.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6232.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6232.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6232.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.601 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6232.Conv2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %_packed_params.141 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.601)
                                        %15 : float = prim::Constant[value=0.0092360768467187881](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=58](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %x.19 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.141, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%x.19)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6244.SEModule {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6234.AdaptiveAvgPool2d object at 0000018BEA00D3E0>
                                se = <__torch__.torch.nn.modules.container.___torch_mangle_6240.Sequential object at 0000018BEA016CE0>
                                mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6243.TorchMultiply object at 0000018BEA018460>
                              }
                              methods {
                                method forward {
                                  graph(%self.603 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6244.SEModule,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %mul.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6243.TorchMultiply = prim::GetAttr[name="mul"](%self.603)
                                    %se.33 : __torch__.torch.nn.modules.container.___torch_mangle_6240.Sequential = prim::GetAttr[name="se"](%self.603)
                                    %avg_pool.17 : __torch__.torch.nn.modules.pooling.___torch_mangle_6234.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.603)
                                    %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.17, %1)
                                    %33 : Tensor = prim::CallMethod[name="forward"](%se.33, %32)
                                    %34 : Tensor = prim::CallMethod[name="forward"](%mul.17, %1, %33)
                                    return (%34)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.pooling.___torch_mangle_6234.AdaptiveAvgPool2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.605 : __torch__.torch.nn.modules.pooling.___torch_mangle_6234.AdaptiveAvgPool2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.avg_pool
                                        %input.159 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        return (%input.159)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.container.___torch_mangle_6240.Sequential {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6237.ConvBNRelu object at 0000018BEA0137E0>
                                    1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6238.Conv2d object at 0000018BEA013BE0>
                                    2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6239.Sigmoid object at 0000018BEA013EE0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.607 : __torch__.torch.nn.modules.container.___torch_mangle_6240.Sequential,
                                            %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                        %_2.17 : __torch__.torch.nn.modules.activation.___torch_mangle_6239.Sigmoid = prim::GetAttr[name="2"](%self.607)
                                        %_1.17 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6238.Conv2d = prim::GetAttr[name="1"](%self.607)
                                        %_0.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6237.ConvBNRelu = prim::GetAttr[name="0"](%self.607)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%_0.19, %1)
                                        %9 : Tensor = prim::CallMethod[name="forward"](%_1.17, %8)
                                        %10 : Tensor = prim::CallMethod[name="forward"](%_2.17, %9)
                                        return (%10)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6237.ConvBNRelu {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6235.ConvReLU2d object at 0000018BEA010B60>
                                        relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6236.Identity object at 0000018BEA00FDE0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.609 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6237.ConvBNRelu,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %relu.53 : __torch__.torch.nn.modules.linear.___torch_mangle_6236.Identity = prim::GetAttr[name="relu"](%self.609)
                                            %conv.127 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6235.ConvReLU2d = prim::GetAttr[name="conv"](%self.609)
                                            %6 : Tensor = prim::CallMethod[name="forward"](%conv.127, %1)
                                            %7 : NoneType = prim::CallMethod[name="forward"](%relu.53)
                                            return (%6)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6235.ConvReLU2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 336
                                            out_channels = 88
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3B570>
                                            scale = 1.1920928955078125e-07
                                            zero_point = 0
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6235.ConvReLU2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6235.ConvReLU2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6235.ConvReLU2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6235.ConvReLU2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.611 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6235.ConvReLU2d,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %_packed_params.143 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.611)
                                                %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.161 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.143, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.161)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6236.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.613 : __torch__.torch.nn.modules.linear.___torch_mangle_6236.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6238.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 88
                                        out_channels = 336
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3BCF0>
                                        scale = 0.00027793736080639064
                                        zero_point = 51
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6238.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6238.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6238.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6238.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.615 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6238.Conv2d,
                                                %1 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu)):
                                            %_packed_params.145 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.615)
                                            %15 : float = prim::Constant[value=0.00027793736080639064](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=51](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.163 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.145, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.163)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.activation.___torch_mangle_6239.Sigmoid {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.617 : __torch__.torch.nn.modules.activation.___torch_mangle_6239.Sigmoid,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                            return (%2)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6243.TorchMultiply {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6242.QFunctional object at 0000018BEA017BE0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.619 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6243.TorchMultiply,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                        %mul_func.17 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6242.QFunctional = prim::GetAttr[name="mul_func"](%self.619)
                                        %activation_post_process.45 : __torch__.torch.nn.modules.linear.___torch_mangle_6241.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.17)
                                        %5 : float = prim::Constant[value=0.0047452496364712715](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.165 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.45)
                                        return (%input.165)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6242.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6241.Identity object at 0000018BEA0170E0>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6241.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.621 : __torch__.torch.nn.modules.linear.___torch_mangle_6241.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6247.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6245.Conv2d object at 0000018BEA017960>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6246.Identity object at 0000018BEA019860>
                              }
                              methods {
                                method forward {
                                  graph(%self.623 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6247.ConvBNRelu,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %bn.73 : __torch__.torch.nn.modules.linear.___torch_mangle_6246.Identity = prim::GetAttr[name="bn"](%self.623)
                                    %conv.129 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6245.Conv2d = prim::GetAttr[name="conv"](%self.623)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.129, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.73)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6245.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 336
                                    out_channels = 112
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3DEF0>
                                    scale = 0.031656406819820404
                                    zero_point = 60
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6245.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6245.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6245.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6245.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.625 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6245.Conv2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %_packed_params.147 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.625)
                                        %15 : float = prim::Constant[value=0.031656406819820404](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.147, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6246.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.627 : __torch__.torch.nn.modules.linear.___torch_mangle_6246.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6250.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6249.QFunctional object at 0000018BEA019260>
                              }
                              methods {
                                method forward {
                                  graph(%self.629 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6250.TorchAdd,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %add_func.29 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6249.QFunctional = prim::GetAttr[name="add_func"](%self.629)
                                    %activation_post_process.47 : __torch__.torch.nn.modules.linear.___torch_mangle_6248.Identity = prim::GetAttr[name="activation_post_process"](%add_func.29)
                                    %5 : float = prim::Constant[value=0.063239879906177521](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %input.167 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_8/__module.model.model.backbone.body.trunk3.fbnetv2_3_8.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.47)
                                    return (%input.167)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6249.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6248.Identity object at 0000018BEA01A2E0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6248.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.631 : __torch__.torch.nn.modules.linear.___torch_mangle_6248.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6275.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6255.ConvBNRelu object at 0000018BEA01EFE0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6257.ConvBNRelu object at 0000018BEA01DFE0>
                            se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6268.SEModule object at 0000018BEA02AE60>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6271.ConvBNRelu object at 0000018BEA02BA60>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6274.TorchAdd object at 0000018BEA02BAE0>
                          }
                          methods {
                            method forward {
                              graph(%self.633 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6275.IRFBlock,
                                    %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                %res_conn.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6274.TorchAdd = prim::GetAttr[name="res_conn"](%self.633)
                                %pwl.39 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6271.ConvBNRelu = prim::GetAttr[name="pwl"](%self.633)
                                %se.39 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6268.SEModule = prim::GetAttr[name="se"](%self.633)
                                %dw.47 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6257.ConvBNRelu = prim::GetAttr[name="dw"](%self.633)
                                %pw.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6255.ConvBNRelu = prim::GetAttr[name="pw"](%self.633)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pw.35, %1)
                                %13 : Tensor = prim::CallMethod[name="forward"](%dw.47, %12)
                                %14 : Tensor = prim::CallMethod[name="forward"](%se.39, %13)
                                %15 : Tensor = prim::CallMethod[name="forward"](%pwl.39, %14)
                                %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.31, %15, %1)
                                return (%16)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6255.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6252.ConvReLU2d object at 0000018BEA01C4E0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6253.Identity object at 0000018BEA01B1E0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6254.Identity object at 0000018BEA01D660>
                              }
                              methods {
                                method forward {
                                  graph(%self.635 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6255.ConvBNRelu,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %relu.55 : __torch__.torch.nn.modules.linear.___torch_mangle_6254.Identity = prim::GetAttr[name="relu"](%self.635)
                                    %bn.75 : __torch__.torch.nn.modules.linear.___torch_mangle_6253.Identity = prim::GetAttr[name="bn"](%self.635)
                                    %conv.131 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6252.ConvReLU2d = prim::GetAttr[name="conv"](%self.635)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.131, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.75)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.55)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6252.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 112
                                    out_channels = 336
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D2F0>
                                    scale = 0.029554517939686775
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6252.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6252.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6252.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6252.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.637 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6252.ConvReLU2d,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %_packed_params.149 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.637)
                                        %15 : float = prim::Constant[value=0.029554517939686775](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.169 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.149, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%input.169)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6253.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.639 : __torch__.torch.nn.modules.linear.___torch_mangle_6253.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6254.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.641 : __torch__.torch.nn.modules.linear.___torch_mangle_6254.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6257.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6256.Conv2d object at 0000018BEA01DAE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.643 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6257.ConvBNRelu,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %conv.133 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6256.Conv2d = prim::GetAttr[name="conv"](%self.643)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.133, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6256.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 336
                                    out_channels = 336
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 336
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3CBF0>
                                    scale = 0.012390102259814739
                                    zero_point = 72
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6256.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6256.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6256.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6256.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.645 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6256.Conv2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %_packed_params.151 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.645)
                                        %15 : float = prim::Constant[value=0.012390102259814739](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=72](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %x.21 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.151, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%x.21)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6268.SEModule {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6258.AdaptiveAvgPool2d object at 0000018BEA020860>
                                se = <__torch__.torch.nn.modules.container.___torch_mangle_6264.Sequential object at 0000018BEA025760>
                                mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6267.TorchMultiply object at 0000018BEA0289E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.647 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6268.SEModule,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %mul.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6267.TorchMultiply = prim::GetAttr[name="mul"](%self.647)
                                    %se.37 : __torch__.torch.nn.modules.container.___torch_mangle_6264.Sequential = prim::GetAttr[name="se"](%self.647)
                                    %avg_pool.19 : __torch__.torch.nn.modules.pooling.___torch_mangle_6258.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.647)
                                    %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.19, %1)
                                    %33 : Tensor = prim::CallMethod[name="forward"](%se.37, %32)
                                    %34 : Tensor = prim::CallMethod[name="forward"](%mul.19, %1, %33)
                                    return (%34)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.pooling.___torch_mangle_6258.AdaptiveAvgPool2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.649 : __torch__.torch.nn.modules.pooling.___torch_mangle_6258.AdaptiveAvgPool2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.avg_pool
                                        %input.171 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                        return (%input.171)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.container.___torch_mangle_6264.Sequential {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6261.ConvBNRelu object at 0000018BEA024FE0>
                                    1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6262.Conv2d object at 0000018BEA0260E0>
                                    2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6263.Sigmoid object at 0000018BEA0255E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.651 : __torch__.torch.nn.modules.container.___torch_mangle_6264.Sequential,
                                            %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                        %_2.19 : __torch__.torch.nn.modules.activation.___torch_mangle_6263.Sigmoid = prim::GetAttr[name="2"](%self.651)
                                        %_1.19 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6262.Conv2d = prim::GetAttr[name="1"](%self.651)
                                        %_0.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6261.ConvBNRelu = prim::GetAttr[name="0"](%self.651)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%_0.21, %1)
                                        %9 : Tensor = prim::CallMethod[name="forward"](%_1.19, %8)
                                        %10 : Tensor = prim::CallMethod[name="forward"](%_2.19, %9)
                                        return (%10)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6261.ConvBNRelu {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6259.ConvReLU2d object at 0000018BEA022F60>
                                        relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6260.Identity object at 0000018BEA021260>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.653 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6261.ConvBNRelu,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %relu.57 : __torch__.torch.nn.modules.linear.___torch_mangle_6260.Identity = prim::GetAttr[name="relu"](%self.653)
                                            %conv.135 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6259.ConvReLU2d = prim::GetAttr[name="conv"](%self.653)
                                            %6 : Tensor = prim::CallMethod[name="forward"](%conv.135, %1)
                                            %7 : NoneType = prim::CallMethod[name="forward"](%relu.57)
                                            return (%6)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6259.ConvReLU2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 336
                                            out_channels = 88
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D9F0>
                                            scale = 1.1920928955078125e-07
                                            zero_point = 0
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6259.ConvReLU2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6259.ConvReLU2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6259.ConvReLU2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6259.ConvReLU2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.655 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6259.ConvReLU2d,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %_packed_params.153 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.655)
                                                %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.173 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.153, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se.0/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.173)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6260.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.657 : __torch__.torch.nn.modules.linear.___torch_mangle_6260.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6262.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 88
                                        out_channels = 336
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D870>
                                        scale = 0.00030603984487242997
                                        zero_point = 74
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6262.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6262.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6262.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6262.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.659 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6262.Conv2d,
                                                %1 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu)):
                                            %_packed_params.155 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.659)
                                            %15 : float = prim::Constant[value=0.00030603984487242997](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=74](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.175 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.155, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.175)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.activation.___torch_mangle_6263.Sigmoid {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.661 : __torch__.torch.nn.modules.activation.___torch_mangle_6263.Sigmoid,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                            return (%2)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6267.TorchMultiply {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6266.QFunctional object at 0000018BEA0287E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.663 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6267.TorchMultiply,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                        %mul_func.19 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6266.QFunctional = prim::GetAttr[name="mul_func"](%self.663)
                                        %activation_post_process.49 : __torch__.torch.nn.modules.linear.___torch_mangle_6265.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.19)
                                        %5 : float = prim::Constant[value=0.0064642475917935371](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=69](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.177 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.49)
                                        return (%input.177)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6266.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6265.Identity object at 0000018BEA028B60>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6265.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.665 : __torch__.torch.nn.modules.linear.___torch_mangle_6265.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6271.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6269.Conv2d object at 0000018BEA02A2E0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6270.Identity object at 0000018BEA02AEE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.667 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6271.ConvBNRelu,
                                        %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                    %bn.77 : __torch__.torch.nn.modules.linear.___torch_mangle_6270.Identity = prim::GetAttr[name="bn"](%self.667)
                                    %conv.137 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6269.Conv2d = prim::GetAttr[name="conv"](%self.667)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.137, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.77)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6269.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 336
                                    out_channels = 112
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3CEF0>
                                    scale = 0.038257457315921783
                                    zero_point = 66
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6269.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6269.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                        %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                        %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                        %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                        %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                        %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                        %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                        %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                        %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                        %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                        %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                        %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                        %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                        %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                        %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                        %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6269.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6269.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                        %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                         = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.669 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6269.Conv2d,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %_packed_params.157 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.669)
                                        %15 : float = prim::Constant[value=0.038257457315921783](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %17 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.157, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_6270.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.671 : __torch__.torch.nn.modules.linear.___torch_mangle_6270.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6274.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6273.QFunctional object at 0000018BEA02C9E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.673 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6274.TorchAdd,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %add_func.31 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6273.QFunctional = prim::GetAttr[name="add_func"](%self.673)
                                    %activation_post_process.51 : __torch__.torch.nn.modules.linear.___torch_mangle_6272.Identity = prim::GetAttr[name="activation_post_process"](%add_func.31)
                                    %5 : float = prim::Constant[value=0.075057744979858398](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %6 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %Xq.1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_9/__module.model.model.backbone.body.trunk3.fbnetv2_3_9.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.51)
                                    return (%Xq.1)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6273.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6272.Identity object at 0000018BEA02C5E0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6272.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.675 : __torch__.torch.nn.modules.linear.___torch_mangle_6272.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6280.QuantStubNested {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    stubs = <__torch__.torch.nn.modules.container.___torch_mangle_6279.ModuleList object at 0000018BEA02D860>
                  }
                  methods {
                    method forward {
                      graph(%self.7 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6280.QuantStubNested,
                            %X.1 : Float(1, 3, 224, 299, strides=[200928, 66976, 299, 1], requires_grad=0, device=cpu)):
                        %stubs.1 : __torch__.torch.nn.modules.container.___torch_mangle_6279.ModuleList = prim::GetAttr[name="stubs"](%self.7)
                        %_0.1 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6278.Quantize = prim::GetAttr[name="0"](%stubs.1)
                        %5 : Tensor = prim::CallMethod[name="forward"](%_0.1, %X.1)
                        return (%5)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.___torch_mangle_6279.ModuleList {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6278.Quantize object at 0000018BEA02D7E0>
                      }
                      methods {
                      }
                      submodules {
                        module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6278.Quantize {
                          parameters {
                          }
                          attributes {
                            scale = ...
                            zero_point = ...
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.9 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6278.Quantize,
                                    %X.1 : Float(1, 3, 224, 299, strides=[200928, 66976, 299, 1], requires_grad=0, device=cpu)):
                                %2 : float = prim::Constant[value=2.1648626327514648](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.quant_stubs/__module.model.model.backbone.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                %3 : int = prim::Constant[value=57](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.quant_stubs/__module.model.model.backbone.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.quant_stubs/__module.model.model.backbone.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                %input.1 : QUInt8(1, 3, 224, 299, strides=[200928, 66976, 299, 1], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%X.1, %2, %3, %4), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.quant_stubs/__module.model.model.backbone.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                return (%input.1)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6286.QuantStubNested {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    stubs = <__torch__.torch.nn.modules.container.___torch_mangle_6285.ModuleList object at 0000018BEA02E260>
                  }
                  methods {
                    method forward {
                      graph(%self.677 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6286.QuantStubNested,
                            %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu),
                            %2 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu),
                            %3 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu),
                            %4 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                        %stubs.9 : __torch__.torch.nn.modules.container.___torch_mangle_6285.ModuleList = prim::GetAttr[name="stubs"](%self.677)
                        %_3 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6284.DeQuantize = prim::GetAttr[name="3"](%stubs.9)
                        %stubs.7 : __torch__.torch.nn.modules.container.___torch_mangle_6285.ModuleList = prim::GetAttr[name="stubs"](%self.677)
                        %_2.21 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6283.DeQuantize = prim::GetAttr[name="2"](%stubs.7)
                        %stubs.5 : __torch__.torch.nn.modules.container.___torch_mangle_6285.ModuleList = prim::GetAttr[name="stubs"](%self.677)
                        %_1.21 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6282.DeQuantize = prim::GetAttr[name="1"](%stubs.5)
                        %stubs.3 : __torch__.torch.nn.modules.container.___torch_mangle_6285.ModuleList = prim::GetAttr[name="stubs"](%self.677)
                        %_0.23 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6281.DeQuantize = prim::GetAttr[name="0"](%stubs.3)
                        %17 : NoneType = prim::CallMethod[name="forward"](%_0.23, %1)
                        %18 : NoneType = prim::CallMethod[name="forward"](%_1.21, %2)
                        %19 : NoneType = prim::CallMethod[name="forward"](%_2.21, %3)
                        %20 : Tensor = prim::CallMethod[name="forward"](%_3, %4)
                        return (%20)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.___torch_mangle_6285.ModuleList {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6281.DeQuantize object at 0000018BEA02D4E0>
                        1 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6282.DeQuantize object at 0000018BEA02EC60>
                        2 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6283.DeQuantize object at 0000018BEA02ECE0>
                        3 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6284.DeQuantize object at 0000018BEA02E560>
                      }
                      methods {
                      }
                      submodules {
                        module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6281.DeQuantize {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.679 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6281.DeQuantize,
                                    %1 : QUInt8(1, 16, 112, 150, strides=[268800, 1, 2400, 16], requires_grad=0, device=cpu)):
                                %3 : NoneType = prim::Constant()
                                return (%3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                        module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6282.DeQuantize {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.681 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6282.DeQuantize,
                                    %1 : QUInt8(1, 24, 56, 75, strides=[100800, 1, 1800, 24], requires_grad=0, device=cpu)):
                                %3 : NoneType = prim::Constant()
                                return (%3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                        module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6283.DeQuantize {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.683 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6283.DeQuantize,
                                    %1 : QUInt8(1, 32, 28, 38, strides=[34048, 1, 1216, 32], requires_grad=0, device=cpu)):
                                %3 : NoneType = prim::Constant()
                                return (%3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                        module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6284.DeQuantize {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.685 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6284.DeQuantize,
                                    %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                %feature_map : Float(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.dequant_stubs/__module.model.model.backbone.dequant_stubs.stubs.3 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:96:0
                                return (%feature_map)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.proposal_generator.rpn.___torch_mangle_6423.RPN {
              parameters {
              }
              attributes {
                training = False
                _is_full_backward_hook = None
                rpn_head = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6420.QuantWrapSubClass object at 0000018BEACBA1F0>
                anchor_generator = <__torch__.detectron2.modeling.anchor_generator.___torch_mangle_6422.DefaultAnchorGenerator object at 0000018BEACBA670>
              }
              methods {
                method forward {
                  graph(%self.687 : __torch__.detectron2.modeling.proposal_generator.rpn.___torch_mangle_6423.RPN,
                        %1 : Float(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                        %image_size : Long(2, strides=[1], requires_grad=0, device=cpu)):
                    %rpn_head : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6420.QuantWrapSubClass = prim::GetAttr[name="rpn_head"](%self.687)
                    %anchor_generator : __torch__.detectron2.modeling.anchor_generator.___torch_mangle_6422.DefaultAnchorGenerator = prim::GetAttr[name="anchor_generator"](%self.687)
                    %550 : Tensor = prim::CallMethod[name="forward"](%anchor_generator, %1)
                    %551 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%rpn_head, %1)
                    %7 : Float(1, 15, 14, 19, strides=[3990, 1, 285, 15], requires_grad=0, device=cpu), %8 : Float(1, 60, 14, 19, strides=[15960, 1, 1140, 60], requires_grad=0, device=cpu) = prim::TupleUnpack(%551)
                    %9 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %10 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %11 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %12 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %13 : int[] = prim::ListConstruct(%9, %10, %11, %12), scope: __module.model/__module.model.model.proposal_generator
                    %14 : Float(1, 14, 19, 15, strides=[3990, 285, 15, 1], requires_grad=0, device=cpu) = aten::permute(%7, %13), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %16 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %logits_i : Float(1, 3990, strides=[3990, 1], requires_grad=0, device=cpu) = aten::flatten(%14, %15, %16), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %18 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %19 : int = aten::size(%8, %18), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %20 : Long(device=cpu) = prim::NumToTensor(%19), scope: __module.model/__module.model.model.proposal_generator
                    %21 : int = aten::Int(%20), scope: __module.model/__module.model.model.proposal_generator
                    %37 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %38 : int = aten::size(%8, %37), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %39 : Long(device=cpu) = prim::NumToTensor(%38), scope: __module.model/__module.model.model.proposal_generator
                    %40 : int = aten::Int(%39), scope: __module.model/__module.model.model.proposal_generator
                    %53 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %54 : int = aten::size(%8, %53), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %55 : Long(device=cpu) = prim::NumToTensor(%54), scope: __module.model/__module.model.model.proposal_generator
                    %56 : int = aten::Int(%55), scope: __module.model/__module.model.model.proposal_generator
                    %57 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %58 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %59 : int[] = prim::ListConstruct(%21, %57, %58, %40, %56), scope: __module.model/__module.model.model.proposal_generator
                    %60 : Float(1, 15, 4, 14, 19, strides=[60, 4, 1, 1140, 60], requires_grad=0, device=cpu) = aten::view(%8, %59), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %61 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %62 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %63 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %64 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %65 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %66 : int[] = prim::ListConstruct(%61, %62, %63, %64, %65), scope: __module.model/__module.model.model.proposal_generator
                    %67 : Float(1, 14, 19, 15, 4, strides=[60, 1140, 60, 4, 1], requires_grad=0, device=cpu) = aten::permute(%60, %66), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %68 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %69 : int = prim::Constant[value=-2](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %pred_anchor_deltas_i : Float(1, 3990, 4, strides=[15960, 4, 1], requires_grad=0, device=cpu) = aten::flatten(%67, %68, %69), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %71 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:522:0
                    %72 : int = aten::size(%pred_anchor_deltas_i, %71), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:522:0
                    %N : Long(device=cpu) = prim::NumToTensor(%72), scope: __module.model/__module.model.model.proposal_generator
                    %74 : int = aten::Int(%N), scope: __module.model/__module.model.model.proposal_generator
                    %75 : int = aten::Int(%N), scope: __module.model/__module.model.model.proposal_generator
                    %82 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:526:0
                    %83 : int = aten::size(%550, %82), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:526:0
                    %B : Long(device=cpu) = prim::NumToTensor(%83), scope: __module.model/__module.model.model.proposal_generator
                    %85 : int = aten::Int(%B), scope: __module.model/__module.model.model.proposal_generator
                    %86 : int = aten::Int(%B), scope: __module.model/__module.model.model.proposal_generator
                    %87 : int = aten::Int(%B), scope: __module.model/__module.model.model.proposal_generator
                    %88 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:527:0
                    %89 : int[] = prim::ListConstruct(%88, %87), scope: __module.model/__module.model.model.proposal_generator
                    %deltas.1 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%pred_anchor_deltas_i, %89), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:527:0
                    %91 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %92 : Float(1, 3990, 4, strides=[15960, 4, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%550, %91), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %93 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %94 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %95 : int[] = prim::ListConstruct(%75, %93, %94), scope: __module.model/__module.model.model.proposal_generator
                    %96 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %97 : Float(1, 3990, 4, strides=[15960, 4, 1], requires_grad=0, device=cpu) = aten::expand(%92, %95, %96), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %98 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %99 : int[] = prim::ListConstruct(%98, %86), scope: __module.model/__module.model.model.proposal_generator
                    %boxes.1 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%97, %99), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %101 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %102 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %103 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %104 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %deltas.3 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%deltas.1, %101, %102, %103, %104), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %106 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %107 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %108 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %109 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %boxes.3 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%boxes.1, %106, %107, %108, %109), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %111 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %112 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %113 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %114 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %115 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %111, %112, %113, %114), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %116 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %117 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %118 : Float(3990, strides=[4], requires_grad=0, device=cpu) = aten::select(%115, %116, %117), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %119 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %120 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %121 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %122 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %123 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %119, %120, %121, %122), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %124 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %125 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %126 : Float(3990, strides=[4], requires_grad=0, device=cpu) = aten::select(%123, %124, %125), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %127 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %widths.1 : Float(3990, strides=[1], requires_grad=0, device=cpu) = aten::sub(%118, %126, %127), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %129 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %130 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %131 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %132 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %133 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %129, %130, %131, %132), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %134 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %135 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %136 : Float(3990, strides=[4], requires_grad=0, device=cpu) = aten::select(%133, %134, %135), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %137 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %138 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %139 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %140 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %141 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %137, %138, %139, %140), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %142 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %143 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %144 : Float(3990, strides=[4], requires_grad=0, device=cpu) = aten::select(%141, %142, %143), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %145 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %heights.1 : Float(3990, strides=[1], requires_grad=0, device=cpu) = aten::sub(%136, %144, %145), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %147 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %148 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %149 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %150 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %151 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %147, %148, %149, %150), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %152 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %153 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %154 : Float(3990, strides=[4], requires_grad=0, device=cpu) = aten::select(%151, %152, %153), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %155 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %156 : Float(3990, strides=[1], requires_grad=0, device=cpu) = aten::mul(%widths.1, %155), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %157 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %ctr_x.1 : Float(3990, strides=[1], requires_grad=0, device=cpu) = aten::add(%154, %156, %157), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %159 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %160 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %161 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %162 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %163 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %159, %160, %161, %162), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %164 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %165 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %166 : Float(3990, strides=[4], requires_grad=0, device=cpu) = aten::select(%163, %164, %165), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %167 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %168 : Float(3990, strides=[1], requires_grad=0, device=cpu) = aten::mul(%heights.1, %167), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %169 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %ctr_y.1 : Float(3990, strides=[1], requires_grad=0, device=cpu) = aten::add(%166, %168, %169), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %171 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %172 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %173 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %174 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %175 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas.3, %171, %172, %173, %174), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %176 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %177 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %178 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %179 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %180 : Float(3990, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%175, %176, %177, %178, %179), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %181 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %dx.1 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%180, %181), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %183 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %184 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %185 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %186 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %187 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas.3, %183, %184, %185, %186), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %188 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %189 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %190 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %191 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %192 : Float(3990, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%187, %188, %189, %190, %191), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %193 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %dy.1 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%192, %193), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %195 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %196 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %197 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %198 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %199 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas.3, %195, %196, %197, %198), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %200 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %201 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %202 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %203 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %204 : Float(3990, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%199, %200, %201, %202, %203), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %205 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %dw.1 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%204, %205), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %207 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %208 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %209 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %210 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %211 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas.3, %207, %208, %209, %210), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %212 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %213 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %214 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %215 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %216 : Float(3990, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%211, %212, %213, %214, %215), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %217 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %dh.1 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%216, %217), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %219 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %220 : float = prim::Constant[value=4.1351665567423561](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:103:0
                    %dw.3 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::clamp(%dw.1, %219, %220), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:103:0
                    %222 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %223 : float = prim::Constant[value=4.1351665567423561](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:104:0
                    %dh.3 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::clamp(%dh.1, %222, %223), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:104:0
                    %225 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %226 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %227 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %228 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %229 : Float(3990, strides=[1], requires_grad=0, device=cpu) = aten::slice(%widths.1, %225, %226, %227, %228), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %230 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %231 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%229, %230), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %232 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%dx.1, %231), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %233 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %234 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %235 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %236 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %237 : Float(3990, strides=[1], requires_grad=0, device=cpu) = aten::slice(%ctr_x.1, %233, %234, %235, %236), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %238 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %239 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%237, %238), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %240 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %pred_ctr_x.1 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%232, %239, %240), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %242 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %243 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %244 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %245 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %246 : Float(3990, strides=[1], requires_grad=0, device=cpu) = aten::slice(%heights.1, %242, %243, %244, %245), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %247 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %248 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%246, %247), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %249 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%dy.1, %248), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %250 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %251 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %252 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %253 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %254 : Float(3990, strides=[1], requires_grad=0, device=cpu) = aten::slice(%ctr_y.1, %250, %251, %252, %253), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %255 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %256 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%254, %255), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %257 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %pred_ctr_y.1 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%249, %256, %257), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %259 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::exp(%dw.3), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %260 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %261 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %262 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %263 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %264 : Float(3990, strides=[1], requires_grad=0, device=cpu) = aten::slice(%widths.1, %260, %261, %262, %263), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %265 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %266 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%264, %265), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %pred_w.1 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%259, %266), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %268 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::exp(%dh.3), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %269 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %270 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %271 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %272 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %273 : Float(3990, strides=[1], requires_grad=0, device=cpu) = aten::slice(%heights.1, %269, %270, %271, %272), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %274 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %275 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%273, %274), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %pred_h.1 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%268, %275), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %277 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %278 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_w.1, %277), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %279 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %x1.1 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::sub(%pred_ctr_x.1, %278, %279), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %281 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %282 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_h.1, %281), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %283 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %y1.1 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::sub(%pred_ctr_y.1, %282, %283), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %285 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %286 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_w.1, %285), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %287 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %x2.1 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%pred_ctr_x.1, %286, %287), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %289 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %290 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_h.1, %289), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %291 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %y2.1 : Float(3990, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%pred_ctr_y.1, %290, %291), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %293 : Tensor[] = prim::ListConstruct(%x1.1, %y1.1, %x2.1, %y2.1), scope: __module.model/__module.model.model.proposal_generator
                    %294 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:115:0
                    %pred_boxes.1 : Float(3990, 1, 4, strides=[4, 4, 1], requires_grad=0, device=cpu) = aten::stack(%293, %294), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:115:0
                    %296 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %297 : int = aten::size(%deltas.3, %296), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %298 : Long(device=cpu) = prim::NumToTensor(%297), scope: __module.model/__module.model.model.proposal_generator
                    %299 : int = aten::Int(%298), scope: __module.model/__module.model.model.proposal_generator
                    %300 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %301 : int = aten::size(%deltas.3, %300), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %302 : Long(device=cpu) = prim::NumToTensor(%301), scope: __module.model/__module.model.model.proposal_generator
                    %303 : int = aten::Int(%302), scope: __module.model/__module.model.model.proposal_generator
                    %304 : int[] = prim::ListConstruct(%299, %303), scope: __module.model/__module.model.model.proposal_generator
                    %proposals_i.1 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%pred_boxes.1, %304), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %306 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:532:0
                    %307 : int[] = prim::ListConstruct(%74, %306, %85), scope: __module.model/__module.model.model.proposal_generator
                    %proposals_i : Float(1, 3990, 4, strides=[15960, 4, 1], requires_grad=0, device=cpu) = aten::view(%proposals_i.1, %307), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:532:0
                    %309 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %310 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %311 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %312 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %313 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %314 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::arange(%309, %310, %311, %312, %313), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %315 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.proposal_generator
                    %batch_idx : Tensor = prim::CallFunction(%315, %314, %proposals_i), scope: __module.model/__module.model.model.proposal_generator
                    %320 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:73:0
                    %321 : int = aten::size(%logits_i, %320), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:73:0
                    %Hi_Wi_A : Long(device=cpu) = prim::NumToTensor(%321), scope: __module.model/__module.model.model.proposal_generator
                    %323 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %324 : int = prim::Constant[value=1000](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:75:0
                    %num_proposals_i : Long(requires_grad=0, device=cpu) = aten::clamp(%Hi_Wi_A, %323, %324), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:75:0
                    %326 : int = aten::Int(%num_proposals_i), scope: __module.model/__module.model.model.proposal_generator
                    %327 : int = aten::Int(%num_proposals_i), scope: __module.model/__module.model.model.proposal_generator
                    %328 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:79:0
                    %329 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:79:0
                    %330 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:79:0
                    %topk_scores : Float(1, 1000, strides=[1000, 1], requires_grad=0, device=cpu), %topk_idx : Long(1, 1000, strides=[1000, 1], requires_grad=0, device=cpu) = aten::topk(%logits_i, %327, %328, %329, %330), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:79:0
                    %333 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %334 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %335 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %336 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %337 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::slice(%batch_idx, %333, %334, %335, %336), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %338 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %339 : Long(1, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%337, %338), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %340 : Tensor?[] = prim::ListConstruct(%339, %topk_idx), scope: __module.model/__module.model.model.proposal_generator
                    %topk_proposals : Float(1, 1000, 4, strides=[4000, 4, 1], requires_grad=0, device=cpu) = aten::index(%proposals_i, %340), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %342 : int[] = prim::ListConstruct(%326), scope: __module.model/__module.model.model.proposal_generator
                    %343 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %344 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %345 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %346 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %347 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %348 : Long(1000, strides=[1], requires_grad=0, device=cpu) = aten::full(%342, %343, %344, %345, %346, %347), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %349 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.proposal_generator
                    %level_ids : Tensor = prim::CallFunction(%349, %348, %proposals_i), scope: __module.model/__module.model.model.proposal_generator
                    %351 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:101:0
                    %352 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:101:0
                    %tensor.5 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::select(%topk_proposals, %351, %352), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:101:0
                    %354 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %355 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %356 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %357 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.7 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.5, %354, %355, %356, %357), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %368 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:102:0
                    %369 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:102:0
                    %scores_per_img.1 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::select(%topk_scores, %368, %369), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:102:0
                    %380 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_tensor.py:926:0
                    %381 : Tensor[] = aten::unbind(%image_size, %380), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_tensor.py:926:0
                    %h.1 : Long(requires_grad=0, device=cpu), %w.1 : Long(requires_grad=0, device=cpu) = prim::ListUnpack(%381), scope: __module.model/__module.model.model.proposal_generator
                    %384 : Scalar = aten::ScalarImplicit(%h.1), scope: __module.model/__module.model.model.proposal_generator
                    %385 : Scalar = aten::ScalarImplicit(%w.1), scope: __module.model/__module.model.model.proposal_generator
                    %386 : Scalar = aten::ScalarImplicit(%h.1), scope: __module.model/__module.model.model.proposal_generator
                    %387 : Scalar = aten::ScalarImplicit(%w.1), scope: __module.model/__module.model.model.proposal_generator
                    %388 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %389 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %390 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %391 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %392 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %388, %389, %390, %391), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %393 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %394 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %395 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%392, %393, %394), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %396 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %x1.3 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%395, %396, %387), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %398 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %399 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %400 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %401 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %402 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %398, %399, %400, %401), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %403 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %404 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %405 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%402, %403, %404), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %406 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %y1.3 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%405, %406, %386), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %408 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %409 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %410 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %411 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %412 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %408, %409, %410, %411), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %413 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %414 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %415 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%412, %413, %414), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %416 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %x2.3 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%415, %416, %385), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %418 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %419 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %420 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %421 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %422 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %418, %419, %420, %421), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %423 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %424 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %425 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%422, %423, %424), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %426 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %y2.3 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%425, %426, %384), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %428 : Tensor[] = prim::ListConstruct(%x1.3, %y1.3, %x2.3, %y2.3), scope: __module.model/__module.model.model.proposal_generator
                    %429 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:197:0
                    %box : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::stack(%428, %429), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:197:0
                    %431 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %432 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %433 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %434 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %435 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%box, %431, %432, %433, %434), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %436 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %437 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %438 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%435, %436, %437), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %439 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %440 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %441 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %442 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %443 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%box, %439, %440, %441, %442), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %444 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %445 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %446 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%443, %444, %445), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %447 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %widths.3 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::sub(%438, %446, %447), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %449 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %450 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %451 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %452 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %453 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%box, %449, %450, %451, %452), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %454 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %455 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %456 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%453, %454, %455), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %457 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %458 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %459 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %460 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %461 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%box, %457, %458, %459, %460), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %462 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %463 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %464 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%461, %462, %463), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %465 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %heights.3 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::sub(%456, %464, %465), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %467 : float = prim::Constant[value=0.](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %468 : Bool(1000, strides=[1], requires_grad=0, device=cpu) = aten::gt(%widths.3, %467), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %469 : float = prim::Constant[value=0.](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %470 : Bool(1000, strides=[1], requires_grad=0, device=cpu) = aten::gt(%heights.3, %469), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %item.1 : Bool(1000, strides=[1], requires_grad=0, device=cpu) = aten::__and__(%468, %470), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %472 : Tensor?[] = prim::ListConstruct(%item.1), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.9 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::index(%box, %472), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:235:0
                    %474 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %475 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %476 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %477 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.11 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.9, %474, %475, %476, %477), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %488 : Tensor?[] = prim::ListConstruct(%item.1), scope: __module.model/__module.model.model.proposal_generator
                    %scores_per_img : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::index(%scores_per_img.1, %488), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:119:0
                    %490 : Tensor?[] = prim::ListConstruct(%item.1), scope: __module.model/__module.model.model.proposal_generator
                    %491 : Long(1000, strides=[1], requires_grad=0, device=cpu) = aten::index(%level_ids, %490), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:119:0
                    %500 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\nms.py:20:0
                    %501 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\nms.py:20:0
                    %502 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\nms.py:20:0
                    %503 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %boxes.5 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.11, %500, %501, %502, %503), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\nms.py:20:0
                    %509 : float = prim::Constant[value=0.69999999999999996](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\jit\_trace.py:1139:0
                    %510 : Function = prim::Constant[name="_batched_nms_coordinate_trick"](), scope: __module.model/__module.model.model.proposal_generator
                    %keep.1 : Tensor = prim::CallFunction(%510, %boxes.5, %scores_per_img, %491, %509), scope: __module.model/__module.model.model.proposal_generator
                    %512 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %513 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %514 : int = prim::Constant[value=30](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %515 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %item : Long(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%keep.1, %512, %513, %514, %515), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %517 : Tensor?[] = prim::ListConstruct(%item), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.13 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::index(%boxes.5, %517), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:235:0
                    %519 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %520 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %521 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %522 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.15 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.13, %519, %520, %521, %522), scope: __module.model/__module.model.model.proposal_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    return (%tensor.15)
              
                }
              }
              submodules {
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6420.QuantWrapSubClass {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    rpn_feature = <__torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6409.FBNetModule object at 0000018BEACB35F0>
                    rpn_regressor = <__torch__.d2go.modeling.backbone.modules.___torch_mangle_6412.RPNHeadConvRegressor object at 0000018BEACB5570>
                    quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6415.QuantStubNested object at 0000018BEACB7770>
                    dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6419.QuantStubNested object at 0000018BEACBB370>
                  }
                  methods {
                    method forward {
                      graph(%self.691 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6420.QuantWrapSubClass,
                            %1 : Float(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                        %dequant_stubs.3 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6419.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.691)
                        %rpn_regressor : __torch__.d2go.modeling.backbone.modules.___torch_mangle_6412.RPNHeadConvRegressor = prim::GetAttr[name="rpn_regressor"](%self.691)
                        %rpn_feature : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6409.FBNetModule = prim::GetAttr[name="rpn_feature"](%self.691)
                        %quant_stubs.3 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6415.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.691)
                        %15 : Tensor = prim::CallMethod[name="forward"](%quant_stubs.3, %1)
                        %16 : Tensor = prim::CallMethod[name="forward"](%rpn_feature, %15)
                        %17 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%rpn_regressor, %16)
                        %9 : QUInt8(1, 15, 14, 19, strides=[3990, 1, 285, 15], requires_grad=0, device=cpu), %10 : QUInt8(1, 60, 14, 19, strides=[15960, 1, 1140, 60], requires_grad=0, device=cpu) = prim::TupleUnpack(%17)
                        %18 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%dequant_stubs.3, %9, %10)
                        %12 : Float(1, 15, 14, 19, strides=[3990, 1, 285, 15], requires_grad=0, device=cpu), %13 : Float(1, 60, 14, 19, strides=[15960, 1, 1140, 60], requires_grad=0, device=cpu) = prim::TupleUnpack(%18)
                        %14 : (Float(1, 15, 14, 19, strides=[3990, 1, 285, 15], requires_grad=0, device=cpu), Float(1, 60, 14, 19, strides=[15960, 1, 1140, 60], requires_grad=0, device=cpu)) = prim::TupleConstruct(%12, %13)
                        return (%14)
                  
                    }
                  }
                  submodules {
                    module __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6409.FBNetModule {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.nn.modules.container.___torch_mangle_6408.Sequential object at 0000018BEACB3570>
                      }
                      methods {
                        method forward {
                          graph(%self.697 : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6409.FBNetModule,
                                %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                            %_0.39 : __torch__.torch.nn.modules.container.___torch_mangle_6408.Sequential = prim::GetAttr[name="0"](%self.697)
                            %4 : Tensor = prim::CallMethod[name="forward"](%_0.39, %1)
                            return (%4)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_6408.Sequential {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            fbnetv2_0_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6311.IRFBlock object at 0000018BEA03E560>
                            fbnetv2_0_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6335.IRFBlock object at 0000018BEA6591E0>
                            fbnetv2_0_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6359.IRFBlock object at 0000018BEA66B7E0>
                            fbnetv2_0_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6383.IRFBlock object at 0000018BEA67DBE0>
                            fbnetv2_0_4 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6407.IRFBlock object at 0000018BEACB3170>
                          }
                          methods {
                            method forward {
                              graph(%self.699 : __torch__.torch.nn.modules.container.___torch_mangle_6408.Sequential,
                                    %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                %fbnetv2_0_4.1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6407.IRFBlock = prim::GetAttr[name="fbnetv2_0_4"](%self.699)
                                %fbnetv2_0_3.1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6383.IRFBlock = prim::GetAttr[name="fbnetv2_0_3"](%self.699)
                                %fbnetv2_0_2.3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6359.IRFBlock = prim::GetAttr[name="fbnetv2_0_2"](%self.699)
                                %fbnetv2_0_1.3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6335.IRFBlock = prim::GetAttr[name="fbnetv2_0_1"](%self.699)
                                %fbnetv2_0_0.3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6311.IRFBlock = prim::GetAttr[name="fbnetv2_0_0"](%self.699)
                                %12 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_0.3, %1)
                                %13 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_1.3, %12)
                                %14 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_2.3, %13)
                                %15 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_3.1, %14)
                                %16 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_4.1, %15)
                                return (%16)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6311.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6291.ConvBNRelu object at 0000018BEA02F8E0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6293.ConvBNRelu object at 0000018BEA032B60>
                                se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6304.SEModule object at 0000018BEA03C860>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6307.ConvBNRelu object at 0000018BEA03D2E0>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6310.TorchAdd object at 0000018BEA03DEE0>
                              }
                              methods {
                                method forward {
                                  graph(%self.701 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6311.IRFBlock,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %res_conn.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6310.TorchAdd = prim::GetAttr[name="res_conn"](%self.701)
                                    %pwl.41 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6307.ConvBNRelu = prim::GetAttr[name="pwl"](%self.701)
                                    %se.43 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6304.SEModule = prim::GetAttr[name="se"](%self.701)
                                    %dw.49 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6293.ConvBNRelu = prim::GetAttr[name="dw"](%self.701)
                                    %pw.37 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6291.ConvBNRelu = prim::GetAttr[name="pw"](%self.701)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pw.37, %1)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%dw.49, %12)
                                    %14 : Tensor = prim::CallMethod[name="forward"](%se.43, %13)
                                    %15 : Tensor = prim::CallMethod[name="forward"](%pwl.41, %14)
                                    %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.33, %15, %1)
                                    return (%16)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6291.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6288.ConvReLU2d object at 0000018BEA02E2E0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6289.Identity object at 0000018BEA030BE0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6290.Identity object at 0000018BEA030060>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.703 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6291.ConvBNRelu,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %relu.59 : __torch__.torch.nn.modules.linear.___torch_mangle_6290.Identity = prim::GetAttr[name="relu"](%self.703)
                                        %bn.79 : __torch__.torch.nn.modules.linear.___torch_mangle_6289.Identity = prim::GetAttr[name="bn"](%self.703)
                                        %conv.139 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6288.ConvReLU2d = prim::GetAttr[name="conv"](%self.703)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.139, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.79)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.59)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6288.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 112
                                        out_channels = 336
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3DDF0>
                                        scale = 0.035599935799837112
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6288.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6288.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6288.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6288.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.705 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6288.ConvReLU2d,
                                                %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                            %_packed_params.159 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.705)
                                            %15 : float = prim::Constant[value=0.035599935799837112](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.181 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.159, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.181)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6289.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.707 : __torch__.torch.nn.modules.linear.___torch_mangle_6289.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6290.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.709 : __torch__.torch.nn.modules.linear.___torch_mangle_6290.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6293.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6292.Conv2d object at 0000018BEA02FDE0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.711 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6293.ConvBNRelu,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %conv.141 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6292.Conv2d = prim::GetAttr[name="conv"](%self.711)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.141, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6292.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 336
                                        out_channels = 336
                                        kernel_size = (5, 5)
                                        stride = (1, 1)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 336
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D7F0>
                                        scale = 0.0090596023947000504
                                        zero_point = 56
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6292.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6292.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6292.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6292.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.713 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6292.Conv2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %_packed_params.161 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.713)
                                            %15 : float = prim::Constant[value=0.0090596023947000504](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=56](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %x.23 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.161, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%x.23)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6304.SEModule {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6294.AdaptiveAvgPool2d object at 0000018BEA032F60>
                                    se = <__torch__.torch.nn.modules.container.___torch_mangle_6300.Sequential object at 0000018BEA037E60>
                                    mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6303.TorchMultiply object at 0000018BEA03B160>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.715 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6304.SEModule,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %mul.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6303.TorchMultiply = prim::GetAttr[name="mul"](%self.715)
                                        %se.41 : __torch__.torch.nn.modules.container.___torch_mangle_6300.Sequential = prim::GetAttr[name="se"](%self.715)
                                        %avg_pool.21 : __torch__.torch.nn.modules.pooling.___torch_mangle_6294.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.715)
                                        %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.21, %1)
                                        %33 : Tensor = prim::CallMethod[name="forward"](%se.41, %32)
                                        %34 : Tensor = prim::CallMethod[name="forward"](%mul.21, %1, %33)
                                        return (%34)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.pooling.___torch_mangle_6294.AdaptiveAvgPool2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.717 : __torch__.torch.nn.modules.pooling.___torch_mangle_6294.AdaptiveAvgPool2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.avg_pool
                                            %input.183 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            return (%input.183)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.container.___torch_mangle_6300.Sequential {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6297.ConvBNRelu object at 0000018BEA0370E0>
                                        1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6298.Conv2d object at 0000018BEA0384E0>
                                        2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6299.Sigmoid object at 0000018BEA0373E0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.719 : __torch__.torch.nn.modules.container.___torch_mangle_6300.Sequential,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %_2.23 : __torch__.torch.nn.modules.activation.___torch_mangle_6299.Sigmoid = prim::GetAttr[name="2"](%self.719)
                                            %_1.23 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6298.Conv2d = prim::GetAttr[name="1"](%self.719)
                                            %_0.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6297.ConvBNRelu = prim::GetAttr[name="0"](%self.719)
                                            %8 : Tensor = prim::CallMethod[name="forward"](%_0.29, %1)
                                            %9 : Tensor = prim::CallMethod[name="forward"](%_1.23, %8)
                                            %10 : Tensor = prim::CallMethod[name="forward"](%_2.23, %9)
                                            return (%10)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6297.ConvBNRelu {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                            conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6295.ConvReLU2d object at 0000018BEA034160>
                                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6296.Identity object at 0000018BEA0347E0>
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.721 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6297.ConvBNRelu,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %relu.61 : __torch__.torch.nn.modules.linear.___torch_mangle_6296.Identity = prim::GetAttr[name="relu"](%self.721)
                                                %conv.143 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6295.ConvReLU2d = prim::GetAttr[name="conv"](%self.721)
                                                %6 : Tensor = prim::CallMethod[name="forward"](%conv.143, %1)
                                                %7 : NoneType = prim::CallMethod[name="forward"](%relu.61)
                                                return (%6)
                                          
                                            }
                                          }
                                          submodules {
                                            module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6295.ConvReLU2d {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                                in_channels = 336
                                                out_channels = 88
                                                kernel_size = (1, 1)
                                                stride = (1, 1)
                                                padding = (0, 0)
                                                dilation = (1, 1)
                                                transposed = False
                                                output_padding = (0, 0)
                                                groups = 1
                                                padding_mode = zeros
                                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C9F0>
                                                scale = 1.1920928955078125e-07
                                                zero_point = 0
                                              }
                                              methods {
                                                method __getstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6295.ConvReLU2d):
                                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                    %training : bool = prim::GetAttr[name="training"](%self)
                                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                    return (%19)
                                              
                                                }
                                                method __setstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6295.ConvReLU2d,
                                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                    %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                    %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                    %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                    %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                    %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                    %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                    %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                    %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                    %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                    %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                    %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                    %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                    %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                    %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                    %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                    %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                     = prim::SetAttr[name="stride"](%self, %13)
                                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                     = prim::SetAttr[name="padding"](%self, %16)
                                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                     = prim::SetAttr[name="dilation"](%self, %19)
                                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                                     = prim::SetAttr[name="transposed"](%self, %22)
                                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                                     = prim::SetAttr[name="groups"](%self, %28)
                                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                                     = prim::SetAttr[name="scale"](%self, %41)
                                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                                     = prim::SetAttr[name="training"](%self, %47)
                                                    return (%48)
                                              
                                                }
                                                method _weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6295.ConvReLU2d):
                                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                    return (%2)
                                              
                                                }
                                                method set_weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6295.ConvReLU2d,
                                                        %w.1 : Tensor,
                                                        %b.1 : Tensor?):
                                                    %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                    %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                    %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                     = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                      block0():
                                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                                        -> ()
                                                      block1():
                                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                                        -> ()
                                                    return (%37)
                                              
                                                }
                                                method forward {
                                                  graph(%self.723 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6295.ConvReLU2d,
                                                        %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                    %_packed_params.163 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.723)
                                                    %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %input.185 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.163, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    return (%input.185)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6296.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = False
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.725 : __torch__.torch.nn.modules.linear.___torch_mangle_6296.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6298.Conv2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 88
                                            out_channels = 336
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D770>
                                            scale = 0.00018600169278215617
                                            zero_point = 22
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6298.Conv2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6298.Conv2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6298.Conv2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6298.Conv2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.727 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6298.Conv2d,
                                                    %1 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu)):
                                                %_packed_params.165 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.727)
                                                %15 : float = prim::Constant[value=0.00018600169278215617](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=22](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.187 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.165, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.187)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.activation.___torch_mangle_6299.Sigmoid {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.729 : __torch__.torch.nn.modules.activation.___torch_mangle_6299.Sigmoid,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                                return (%2)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6303.TorchMultiply {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6302.QFunctional object at 0000018BEA039360>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.731 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6303.TorchMultiply,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu),
                                                %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %mul_func.21 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6302.QFunctional = prim::GetAttr[name="mul_func"](%self.731)
                                            %activation_post_process.53 : __torch__.torch.nn.modules.linear.___torch_mangle_6301.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.21)
                                            %5 : float = prim::Constant[value=0.0042520989663898945](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %6 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.189 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.53)
                                            return (%input.189)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6302.QFunctional {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6301.Identity object at 0000018BEA03A9E0>
                                          }
                                          methods {
                                          }
                                          submodules {
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6301.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.733 : __torch__.torch.nn.modules.linear.___torch_mangle_6301.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6307.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6305.Conv2d object at 0000018BEA03B2E0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6306.Identity object at 0000018BEA03B360>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.735 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6307.ConvBNRelu,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %bn.81 : __torch__.torch.nn.modules.linear.___torch_mangle_6306.Identity = prim::GetAttr[name="bn"](%self.735)
                                        %conv.145 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6305.Conv2d = prim::GetAttr[name="conv"](%self.735)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.145, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.81)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6305.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 336
                                        out_channels = 112
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3DA70>
                                        scale = 0.043158065527677536
                                        zero_point = 51
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6305.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6305.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6305.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6305.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.737 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6305.Conv2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %_packed_params.167 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.737)
                                            %15 : float = prim::Constant[value=0.043158065527677536](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=51](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %17 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.167, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6306.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.739 : __torch__.torch.nn.modules.linear.___torch_mangle_6306.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6310.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6309.QFunctional object at 0000018BEA03D360>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.741 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6310.TorchAdd,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %add_func.33 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6309.QFunctional = prim::GetAttr[name="add_func"](%self.741)
                                        %activation_post_process.55 : __torch__.torch.nn.modules.linear.___torch_mangle_6308.Identity = prim::GetAttr[name="activation_post_process"](%add_func.33)
                                        %5 : float = prim::Constant[value=0.082980155944824219](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=58](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.191 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.55)
                                        return (%input.191)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6309.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6308.Identity object at 0000018BEA03E460>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6308.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.743 : __torch__.torch.nn.modules.linear.___torch_mangle_6308.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6335.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6315.ConvBNRelu object at 0000018BEA042560>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6317.ConvBNRelu object at 0000018BEA64FA60>
                                se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6328.SEModule object at 0000018BEA657360>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6331.ConvBNRelu object at 0000018BEA656660>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6334.TorchAdd object at 0000018BEA659860>
                              }
                              methods {
                                method forward {
                                  graph(%self.745 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6335.IRFBlock,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %res_conn.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6334.TorchAdd = prim::GetAttr[name="res_conn"](%self.745)
                                    %pwl.43 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6331.ConvBNRelu = prim::GetAttr[name="pwl"](%self.745)
                                    %se.47 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6328.SEModule = prim::GetAttr[name="se"](%self.745)
                                    %dw.51 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6317.ConvBNRelu = prim::GetAttr[name="dw"](%self.745)
                                    %pw.39 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6315.ConvBNRelu = prim::GetAttr[name="pw"](%self.745)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pw.39, %1)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%dw.51, %12)
                                    %14 : Tensor = prim::CallMethod[name="forward"](%se.47, %13)
                                    %15 : Tensor = prim::CallMethod[name="forward"](%pwl.43, %14)
                                    %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.35, %15, %1)
                                    return (%16)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6315.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6312.ConvReLU2d object at 0000018BEA03F8E0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6313.Identity object at 0000018BEA03FBE0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6314.Identity object at 0000018BEA041EE0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.747 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6315.ConvBNRelu,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %relu.63 : __torch__.torch.nn.modules.linear.___torch_mangle_6314.Identity = prim::GetAttr[name="relu"](%self.747)
                                        %bn.83 : __torch__.torch.nn.modules.linear.___torch_mangle_6313.Identity = prim::GetAttr[name="bn"](%self.747)
                                        %conv.147 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6312.ConvReLU2d = prim::GetAttr[name="conv"](%self.747)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.147, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.83)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.63)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6312.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 112
                                        out_channels = 336
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D070>
                                        scale = 0.044427476823329926
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6312.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6312.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6312.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6312.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.749 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6312.ConvReLU2d,
                                                %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                            %_packed_params.169 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.749)
                                            %15 : float = prim::Constant[value=0.044427476823329926](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.193 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.169, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.193)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6313.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.751 : __torch__.torch.nn.modules.linear.___torch_mangle_6313.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6314.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.753 : __torch__.torch.nn.modules.linear.___torch_mangle_6314.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6317.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6316.Conv2d object at 0000018BEA0420E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.755 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6317.ConvBNRelu,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %conv.149 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6316.Conv2d = prim::GetAttr[name="conv"](%self.755)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.149, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6316.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 336
                                        out_channels = 336
                                        kernel_size = (5, 5)
                                        stride = (1, 1)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 336
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D3F0>
                                        scale = 0.010373517870903015
                                        zero_point = 73
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6316.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6316.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6316.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6316.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.757 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6316.Conv2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %_packed_params.171 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.757)
                                            %15 : float = prim::Constant[value=0.010373517870903015](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=73](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %x.25 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.171, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%x.25)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6328.SEModule {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6318.AdaptiveAvgPool2d object at 0000018BEA64E7E0>
                                    se = <__torch__.torch.nn.modules.container.___torch_mangle_6324.Sequential object at 0000018BEA6527E0>
                                    mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6327.TorchMultiply object at 0000018BEA655760>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.759 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6328.SEModule,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %mul.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6327.TorchMultiply = prim::GetAttr[name="mul"](%self.759)
                                        %se.45 : __torch__.torch.nn.modules.container.___torch_mangle_6324.Sequential = prim::GetAttr[name="se"](%self.759)
                                        %avg_pool.23 : __torch__.torch.nn.modules.pooling.___torch_mangle_6318.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.759)
                                        %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.23, %1)
                                        %33 : Tensor = prim::CallMethod[name="forward"](%se.45, %32)
                                        %34 : Tensor = prim::CallMethod[name="forward"](%mul.23, %1, %33)
                                        return (%34)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.pooling.___torch_mangle_6318.AdaptiveAvgPool2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.761 : __torch__.torch.nn.modules.pooling.___torch_mangle_6318.AdaptiveAvgPool2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.avg_pool
                                            %input.195 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            return (%input.195)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.container.___torch_mangle_6324.Sequential {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6321.ConvBNRelu object at 0000018BEA6515E0>
                                        1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6322.Conv2d object at 0000018BEA652660>
                                        2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6323.Sigmoid object at 0000018BEA653560>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.763 : __torch__.torch.nn.modules.container.___torch_mangle_6324.Sequential,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %_2.25 : __torch__.torch.nn.modules.activation.___torch_mangle_6323.Sigmoid = prim::GetAttr[name="2"](%self.763)
                                            %_1.25 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6322.Conv2d = prim::GetAttr[name="1"](%self.763)
                                            %_0.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6321.ConvBNRelu = prim::GetAttr[name="0"](%self.763)
                                            %8 : Tensor = prim::CallMethod[name="forward"](%_0.31, %1)
                                            %9 : Tensor = prim::CallMethod[name="forward"](%_1.25, %8)
                                            %10 : Tensor = prim::CallMethod[name="forward"](%_2.25, %9)
                                            return (%10)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6321.ConvBNRelu {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                            conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6319.ConvReLU2d object at 0000018BEA64E1E0>
                                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6320.Identity object at 0000018BEA64E2E0>
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.765 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6321.ConvBNRelu,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %relu.65 : __torch__.torch.nn.modules.linear.___torch_mangle_6320.Identity = prim::GetAttr[name="relu"](%self.765)
                                                %conv.151 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6319.ConvReLU2d = prim::GetAttr[name="conv"](%self.765)
                                                %6 : Tensor = prim::CallMethod[name="forward"](%conv.151, %1)
                                                %7 : NoneType = prim::CallMethod[name="forward"](%relu.65)
                                                return (%6)
                                          
                                            }
                                          }
                                          submodules {
                                            module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6319.ConvReLU2d {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                                in_channels = 336
                                                out_channels = 88
                                                kernel_size = (1, 1)
                                                stride = (1, 1)
                                                padding = (0, 0)
                                                dilation = (1, 1)
                                                transposed = False
                                                output_padding = (0, 0)
                                                groups = 1
                                                padding_mode = zeros
                                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D6F0>
                                                scale = 1.1920928955078125e-07
                                                zero_point = 0
                                              }
                                              methods {
                                                method __getstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6319.ConvReLU2d):
                                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                    %training : bool = prim::GetAttr[name="training"](%self)
                                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                    return (%19)
                                              
                                                }
                                                method __setstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6319.ConvReLU2d,
                                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                    %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                    %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                    %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                    %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                    %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                    %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                    %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                    %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                    %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                    %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                    %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                    %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                    %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                    %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                    %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                    %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                     = prim::SetAttr[name="stride"](%self, %13)
                                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                     = prim::SetAttr[name="padding"](%self, %16)
                                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                     = prim::SetAttr[name="dilation"](%self, %19)
                                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                                     = prim::SetAttr[name="transposed"](%self, %22)
                                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                                     = prim::SetAttr[name="groups"](%self, %28)
                                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                                     = prim::SetAttr[name="scale"](%self, %41)
                                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                                     = prim::SetAttr[name="training"](%self, %47)
                                                    return (%48)
                                              
                                                }
                                                method _weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6319.ConvReLU2d):
                                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                    return (%2)
                                              
                                                }
                                                method set_weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6319.ConvReLU2d,
                                                        %w.1 : Tensor,
                                                        %b.1 : Tensor?):
                                                    %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                    %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                    %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                     = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                      block0():
                                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                                        -> ()
                                                      block1():
                                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                                        -> ()
                                                    return (%37)
                                              
                                                }
                                                method forward {
                                                  graph(%self.767 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6319.ConvReLU2d,
                                                        %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                    %_packed_params.173 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.767)
                                                    %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %input.197 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.173, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    return (%input.197)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6320.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = False
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.769 : __torch__.torch.nn.modules.linear.___torch_mangle_6320.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6322.Conv2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 88
                                            out_channels = 336
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3CAF0>
                                            scale = 9.525578934699297e-05
                                            zero_point = 32
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6322.Conv2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6322.Conv2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6322.Conv2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6322.Conv2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.771 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6322.Conv2d,
                                                    %1 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu)):
                                                %_packed_params.175 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.771)
                                                %15 : float = prim::Constant[value=9.525578934699297e-05](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=32](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.199 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.175, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.199)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.activation.___torch_mangle_6323.Sigmoid {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.773 : __torch__.torch.nn.modules.activation.___torch_mangle_6323.Sigmoid,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                                return (%2)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6327.TorchMultiply {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6326.QFunctional object at 0000018BEA654FE0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.775 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6327.TorchMultiply,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu),
                                                %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %mul_func.23 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6326.QFunctional = prim::GetAttr[name="mul_func"](%self.775)
                                            %activation_post_process.57 : __torch__.torch.nn.modules.linear.___torch_mangle_6325.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.23)
                                            %5 : float = prim::Constant[value=0.0052361465059220791](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %6 : int = prim::Constant[value=72](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.201 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.57)
                                            return (%input.201)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6326.QFunctional {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6325.Identity object at 0000018BEA6548E0>
                                          }
                                          methods {
                                          }
                                          submodules {
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6325.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.777 : __torch__.torch.nn.modules.linear.___torch_mangle_6325.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6331.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6329.Conv2d object at 0000018BEA6567E0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6330.Identity object at 0000018BEA6563E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.779 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6331.ConvBNRelu,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %bn.85 : __torch__.torch.nn.modules.linear.___torch_mangle_6330.Identity = prim::GetAttr[name="bn"](%self.779)
                                        %conv.153 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6329.Conv2d = prim::GetAttr[name="conv"](%self.779)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.153, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.85)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6329.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 336
                                        out_channels = 112
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3CE70>
                                        scale = 0.051569793373346329
                                        zero_point = 60
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6329.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6329.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6329.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6329.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.781 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6329.Conv2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %_packed_params.177 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.781)
                                            %15 : float = prim::Constant[value=0.051569793373346329](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %17 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.177, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6330.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.783 : __torch__.torch.nn.modules.linear.___torch_mangle_6330.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6334.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6333.QFunctional object at 0000018BEA65A060>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.785 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6334.TorchAdd,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %add_func.35 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6333.QFunctional = prim::GetAttr[name="add_func"](%self.785)
                                        %activation_post_process.59 : __torch__.torch.nn.modules.linear.___torch_mangle_6332.Identity = prim::GetAttr[name="activation_post_process"](%add_func.35)
                                        %5 : float = prim::Constant[value=0.097166500985622406](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.203 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.59)
                                        return (%input.203)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6333.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6332.Identity object at 0000018BEA658D60>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6332.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.787 : __torch__.torch.nn.modules.linear.___torch_mangle_6332.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6359.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6339.ConvBNRelu object at 0000018BEA65CF60>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6341.ConvBNRelu object at 0000018BEA65CFE0>
                                se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6352.SEModule object at 0000018BEA6669E0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6355.ConvBNRelu object at 0000018BEA668260>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6358.TorchAdd object at 0000018BEA66B360>
                              }
                              methods {
                                method forward {
                                  graph(%self.789 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6359.IRFBlock,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %res_conn.37 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6358.TorchAdd = prim::GetAttr[name="res_conn"](%self.789)
                                    %pwl.45 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6355.ConvBNRelu = prim::GetAttr[name="pwl"](%self.789)
                                    %se.51 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6352.SEModule = prim::GetAttr[name="se"](%self.789)
                                    %dw.53 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6341.ConvBNRelu = prim::GetAttr[name="dw"](%self.789)
                                    %pw.41 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6339.ConvBNRelu = prim::GetAttr[name="pw"](%self.789)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pw.41, %1)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%dw.53, %12)
                                    %14 : Tensor = prim::CallMethod[name="forward"](%se.51, %13)
                                    %15 : Tensor = prim::CallMethod[name="forward"](%pwl.45, %14)
                                    %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.37, %15, %1)
                                    return (%16)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6339.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6336.ConvReLU2d object at 0000018BEA65B160>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6337.Identity object at 0000018BEA65ABE0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6338.Identity object at 0000018BEA65CEE0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.791 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6339.ConvBNRelu,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %relu.67 : __torch__.torch.nn.modules.linear.___torch_mangle_6338.Identity = prim::GetAttr[name="relu"](%self.791)
                                        %bn.87 : __torch__.torch.nn.modules.linear.___torch_mangle_6337.Identity = prim::GetAttr[name="bn"](%self.791)
                                        %conv.155 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6336.ConvReLU2d = prim::GetAttr[name="conv"](%self.791)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.155, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.87)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.67)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6336.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 112
                                        out_channels = 336
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3CB70>
                                        scale = 0.050065327435731888
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6336.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6336.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6336.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6336.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.793 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6336.ConvReLU2d,
                                                %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                            %_packed_params.179 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.793)
                                            %15 : float = prim::Constant[value=0.050065327435731888](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.205 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.179, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.205)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6337.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.795 : __torch__.torch.nn.modules.linear.___torch_mangle_6337.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6338.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.797 : __torch__.torch.nn.modules.linear.___torch_mangle_6338.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6341.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6340.Conv2d object at 0000018BEA65DB60>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.799 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6341.ConvBNRelu,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %conv.157 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6340.Conv2d = prim::GetAttr[name="conv"](%self.799)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.157, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6340.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 336
                                        out_channels = 336
                                        kernel_size = (5, 5)
                                        stride = (1, 1)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 336
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C2F0>
                                        scale = 0.011929290369153023
                                        zero_point = 56
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6340.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6340.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6340.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6340.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.801 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6340.Conv2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %_packed_params.181 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.801)
                                            %15 : float = prim::Constant[value=0.011929290369153023](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=56](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %x.27 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.181, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%x.27)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6352.SEModule {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6342.AdaptiveAvgPool2d object at 0000018BEA65F3E0>
                                    se = <__torch__.torch.nn.modules.container.___torch_mangle_6348.Sequential object at 0000018BEA667260>
                                    mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6351.TorchMultiply object at 0000018BEA667B60>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.803 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6352.SEModule,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %mul.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6351.TorchMultiply = prim::GetAttr[name="mul"](%self.803)
                                        %se.49 : __torch__.torch.nn.modules.container.___torch_mangle_6348.Sequential = prim::GetAttr[name="se"](%self.803)
                                        %avg_pool.25 : __torch__.torch.nn.modules.pooling.___torch_mangle_6342.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.803)
                                        %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.25, %1)
                                        %33 : Tensor = prim::CallMethod[name="forward"](%se.49, %32)
                                        %34 : Tensor = prim::CallMethod[name="forward"](%mul.25, %1, %33)
                                        return (%34)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.pooling.___torch_mangle_6342.AdaptiveAvgPool2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.805 : __torch__.torch.nn.modules.pooling.___torch_mangle_6342.AdaptiveAvgPool2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.avg_pool
                                            %input.207 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            return (%input.207)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.container.___torch_mangle_6348.Sequential {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6345.ConvBNRelu object at 0000018BEA662F60>
                                        1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6346.Conv2d object at 0000018BEA663960>
                                        2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6347.Sigmoid object at 0000018BEA663D60>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.807 : __torch__.torch.nn.modules.container.___torch_mangle_6348.Sequential,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %_2.27 : __torch__.torch.nn.modules.activation.___torch_mangle_6347.Sigmoid = prim::GetAttr[name="2"](%self.807)
                                            %_1.27 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6346.Conv2d = prim::GetAttr[name="1"](%self.807)
                                            %_0.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6345.ConvBNRelu = prim::GetAttr[name="0"](%self.807)
                                            %8 : Tensor = prim::CallMethod[name="forward"](%_0.33, %1)
                                            %9 : Tensor = prim::CallMethod[name="forward"](%_1.27, %8)
                                            %10 : Tensor = prim::CallMethod[name="forward"](%_2.27, %9)
                                            return (%10)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6345.ConvBNRelu {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                            conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6343.ConvReLU2d object at 0000018BEA6604E0>
                                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6344.Identity object at 0000018BEA6610E0>
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.809 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6345.ConvBNRelu,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %relu.69 : __torch__.torch.nn.modules.linear.___torch_mangle_6344.Identity = prim::GetAttr[name="relu"](%self.809)
                                                %conv.159 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6343.ConvReLU2d = prim::GetAttr[name="conv"](%self.809)
                                                %6 : Tensor = prim::CallMethod[name="forward"](%conv.159, %1)
                                                %7 : NoneType = prim::CallMethod[name="forward"](%relu.69)
                                                return (%6)
                                          
                                            }
                                          }
                                          submodules {
                                            module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6343.ConvReLU2d {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                                in_channels = 336
                                                out_channels = 88
                                                kernel_size = (1, 1)
                                                stride = (1, 1)
                                                padding = (0, 0)
                                                dilation = (1, 1)
                                                transposed = False
                                                output_padding = (0, 0)
                                                groups = 1
                                                padding_mode = zeros
                                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3CDF0>
                                                scale = 1.1920928955078125e-07
                                                zero_point = 0
                                              }
                                              methods {
                                                method __getstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6343.ConvReLU2d):
                                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                    %training : bool = prim::GetAttr[name="training"](%self)
                                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                    return (%19)
                                              
                                                }
                                                method __setstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6343.ConvReLU2d,
                                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                    %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                    %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                    %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                    %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                    %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                    %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                    %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                    %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                    %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                    %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                    %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                    %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                    %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                    %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                    %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                    %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                     = prim::SetAttr[name="stride"](%self, %13)
                                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                     = prim::SetAttr[name="padding"](%self, %16)
                                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                     = prim::SetAttr[name="dilation"](%self, %19)
                                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                                     = prim::SetAttr[name="transposed"](%self, %22)
                                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                                     = prim::SetAttr[name="groups"](%self, %28)
                                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                                     = prim::SetAttr[name="scale"](%self, %41)
                                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                                     = prim::SetAttr[name="training"](%self, %47)
                                                    return (%48)
                                              
                                                }
                                                method _weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6343.ConvReLU2d):
                                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                    return (%2)
                                              
                                                }
                                                method set_weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6343.ConvReLU2d,
                                                        %w.1 : Tensor,
                                                        %b.1 : Tensor?):
                                                    %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                    %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                    %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                     = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                      block0():
                                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                                        -> ()
                                                      block1():
                                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                                        -> ()
                                                    return (%37)
                                              
                                                }
                                                method forward {
                                                  graph(%self.811 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6343.ConvReLU2d,
                                                        %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                    %_packed_params.183 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.811)
                                                    %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %input.209 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.183, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    return (%input.209)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6344.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = False
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.813 : __torch__.torch.nn.modules.linear.___torch_mangle_6344.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6346.Conv2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 88
                                            out_channels = 336
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C3F0>
                                            scale = 0.00011300288315396756
                                            zero_point = 37
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6346.Conv2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6346.Conv2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6346.Conv2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6346.Conv2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.815 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6346.Conv2d,
                                                    %1 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu)):
                                                %_packed_params.185 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.815)
                                                %15 : float = prim::Constant[value=0.00011300288315396756](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=37](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.211 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.185, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.211)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.activation.___torch_mangle_6347.Sigmoid {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.817 : __torch__.torch.nn.modules.activation.___torch_mangle_6347.Sigmoid,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                                return (%2)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6351.TorchMultiply {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6350.QFunctional object at 0000018BEA666460>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.819 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6351.TorchMultiply,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu),
                                                %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %mul_func.25 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6350.QFunctional = prim::GetAttr[name="mul_func"](%self.819)
                                            %activation_post_process.61 : __torch__.torch.nn.modules.linear.___torch_mangle_6349.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.25)
                                            %5 : float = prim::Constant[value=0.0057127703912556171](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %6 : int = prim::Constant[value=56](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.213 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.61)
                                            return (%input.213)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6350.QFunctional {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6349.Identity object at 0000018BEA666960>
                                          }
                                          methods {
                                          }
                                          submodules {
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6349.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.821 : __torch__.torch.nn.modules.linear.___torch_mangle_6349.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6355.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6353.Conv2d object at 0000018BEA6686E0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6354.Identity object at 0000018BEA6697E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.823 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6355.ConvBNRelu,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %bn.89 : __torch__.torch.nn.modules.linear.___torch_mangle_6354.Identity = prim::GetAttr[name="bn"](%self.823)
                                        %conv.161 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6353.Conv2d = prim::GetAttr[name="conv"](%self.823)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.161, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.89)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6353.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 336
                                        out_channels = 112
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C1F0>
                                        scale = 0.069201745092868805
                                        zero_point = 61
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6353.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6353.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6353.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6353.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.825 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6353.Conv2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %_packed_params.187 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.825)
                                            %15 : float = prim::Constant[value=0.069201745092868805](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %17 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.187, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6354.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.827 : __torch__.torch.nn.modules.linear.___torch_mangle_6354.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6358.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6357.QFunctional object at 0000018BEA66B8E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.829 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6358.TorchAdd,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %add_func.37 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6357.QFunctional = prim::GetAttr[name="add_func"](%self.829)
                                        %activation_post_process.63 : __torch__.torch.nn.modules.linear.___torch_mangle_6356.Identity = prim::GetAttr[name="activation_post_process"](%add_func.37)
                                        %5 : float = prim::Constant[value=0.10592420399188995](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.215 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.63)
                                        return (%input.215)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6357.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6356.Identity object at 0000018BEA66BB60>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6356.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.831 : __torch__.torch.nn.modules.linear.___torch_mangle_6356.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6383.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6363.ConvBNRelu object at 0000018BEA66FE60>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6365.ConvBNRelu object at 0000018BEA66E360>
                                se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6376.SEModule object at 0000018BEA6787E0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6379.ConvBNRelu object at 0000018BEA67B060>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6382.TorchAdd object at 0000018BEA67C960>
                              }
                              methods {
                                method forward {
                                  graph(%self.833 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6383.IRFBlock,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %res_conn.39 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6382.TorchAdd = prim::GetAttr[name="res_conn"](%self.833)
                                    %pwl.47 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6379.ConvBNRelu = prim::GetAttr[name="pwl"](%self.833)
                                    %se.55 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6376.SEModule = prim::GetAttr[name="se"](%self.833)
                                    %dw.55 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6365.ConvBNRelu = prim::GetAttr[name="dw"](%self.833)
                                    %pw.43 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6363.ConvBNRelu = prim::GetAttr[name="pw"](%self.833)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pw.43, %1)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%dw.55, %12)
                                    %14 : Tensor = prim::CallMethod[name="forward"](%se.55, %13)
                                    %15 : Tensor = prim::CallMethod[name="forward"](%pwl.47, %14)
                                    %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.39, %15, %1)
                                    return (%16)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6363.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6360.ConvReLU2d object at 0000018BEA66DCE0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6361.Identity object at 0000018BEA66E0E0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6362.Identity object at 0000018BEA66D2E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.835 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6363.ConvBNRelu,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %relu.71 : __torch__.torch.nn.modules.linear.___torch_mangle_6362.Identity = prim::GetAttr[name="relu"](%self.835)
                                        %bn.91 : __torch__.torch.nn.modules.linear.___torch_mangle_6361.Identity = prim::GetAttr[name="bn"](%self.835)
                                        %conv.163 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6360.ConvReLU2d = prim::GetAttr[name="conv"](%self.835)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.163, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.91)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.71)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6360.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 112
                                        out_channels = 336
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D8F0>
                                        scale = 0.050053708255290985
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6360.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6360.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6360.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6360.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.837 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6360.ConvReLU2d,
                                                %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                            %_packed_params.189 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.837)
                                            %15 : float = prim::Constant[value=0.050053708255290985](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.217 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.189, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.217)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6361.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.839 : __torch__.torch.nn.modules.linear.___torch_mangle_6361.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6362.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.841 : __torch__.torch.nn.modules.linear.___torch_mangle_6362.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6365.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6364.Conv2d object at 0000018BEA66E9E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.843 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6365.ConvBNRelu,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %conv.165 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6364.Conv2d = prim::GetAttr[name="conv"](%self.843)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.165, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6364.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 336
                                        out_channels = 336
                                        kernel_size = (5, 5)
                                        stride = (1, 1)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 336
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3DF70>
                                        scale = 0.012063684873282909
                                        zero_point = 76
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6364.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6364.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6364.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6364.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.845 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6364.Conv2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %_packed_params.191 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.845)
                                            %15 : float = prim::Constant[value=0.012063684873282909](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=76](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %x.29 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.191, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%x.29)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6376.SEModule {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6366.AdaptiveAvgPool2d object at 0000018BEA66F1E0>
                                    se = <__torch__.torch.nn.modules.container.___torch_mangle_6372.Sequential object at 0000018BEA677260>
                                    mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6375.TorchMultiply object at 0000018BEA678760>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.847 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6376.SEModule,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %mul.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6375.TorchMultiply = prim::GetAttr[name="mul"](%self.847)
                                        %se.53 : __torch__.torch.nn.modules.container.___torch_mangle_6372.Sequential = prim::GetAttr[name="se"](%self.847)
                                        %avg_pool.27 : __torch__.torch.nn.modules.pooling.___torch_mangle_6366.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.847)
                                        %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.27, %1)
                                        %33 : Tensor = prim::CallMethod[name="forward"](%se.53, %32)
                                        %34 : Tensor = prim::CallMethod[name="forward"](%mul.27, %1, %33)
                                        return (%34)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.pooling.___torch_mangle_6366.AdaptiveAvgPool2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.849 : __torch__.torch.nn.modules.pooling.___torch_mangle_6366.AdaptiveAvgPool2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.avg_pool
                                            %input.219 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            return (%input.219)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.container.___torch_mangle_6372.Sequential {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6369.ConvBNRelu object at 0000018BEA6742E0>
                                        1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6370.Conv2d object at 0000018BEA6749E0>
                                        2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6371.Sigmoid object at 0000018BEA674B60>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.851 : __torch__.torch.nn.modules.container.___torch_mangle_6372.Sequential,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %_2.29 : __torch__.torch.nn.modules.activation.___torch_mangle_6371.Sigmoid = prim::GetAttr[name="2"](%self.851)
                                            %_1.29 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6370.Conv2d = prim::GetAttr[name="1"](%self.851)
                                            %_0.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6369.ConvBNRelu = prim::GetAttr[name="0"](%self.851)
                                            %8 : Tensor = prim::CallMethod[name="forward"](%_0.35, %1)
                                            %9 : Tensor = prim::CallMethod[name="forward"](%_1.29, %8)
                                            %10 : Tensor = prim::CallMethod[name="forward"](%_2.29, %9)
                                            return (%10)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6369.ConvBNRelu {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                            conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6367.ConvReLU2d object at 0000018BEA6716E0>
                                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6368.Identity object at 0000018BEA6708E0>
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.853 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6369.ConvBNRelu,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %relu.73 : __torch__.torch.nn.modules.linear.___torch_mangle_6368.Identity = prim::GetAttr[name="relu"](%self.853)
                                                %conv.167 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6367.ConvReLU2d = prim::GetAttr[name="conv"](%self.853)
                                                %6 : Tensor = prim::CallMethod[name="forward"](%conv.167, %1)
                                                %7 : NoneType = prim::CallMethod[name="forward"](%relu.73)
                                                return (%6)
                                          
                                            }
                                          }
                                          submodules {
                                            module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6367.ConvReLU2d {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                                in_channels = 336
                                                out_channels = 88
                                                kernel_size = (1, 1)
                                                stride = (1, 1)
                                                padding = (0, 0)
                                                dilation = (1, 1)
                                                transposed = False
                                                output_padding = (0, 0)
                                                groups = 1
                                                padding_mode = zeros
                                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C270>
                                                scale = 1.1920928955078125e-07
                                                zero_point = 0
                                              }
                                              methods {
                                                method __getstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6367.ConvReLU2d):
                                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                    %training : bool = prim::GetAttr[name="training"](%self)
                                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                    return (%19)
                                              
                                                }
                                                method __setstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6367.ConvReLU2d,
                                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                    %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                    %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                    %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                    %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                    %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                    %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                    %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                    %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                    %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                    %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                    %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                    %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                    %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                    %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                    %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                    %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                     = prim::SetAttr[name="stride"](%self, %13)
                                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                     = prim::SetAttr[name="padding"](%self, %16)
                                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                     = prim::SetAttr[name="dilation"](%self, %19)
                                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                                     = prim::SetAttr[name="transposed"](%self, %22)
                                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                                     = prim::SetAttr[name="groups"](%self, %28)
                                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                                     = prim::SetAttr[name="scale"](%self, %41)
                                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                                     = prim::SetAttr[name="training"](%self, %47)
                                                    return (%48)
                                              
                                                }
                                                method _weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6367.ConvReLU2d):
                                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                    return (%2)
                                              
                                                }
                                                method set_weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6367.ConvReLU2d,
                                                        %w.1 : Tensor,
                                                        %b.1 : Tensor?):
                                                    %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                    %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                    %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                     = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                      block0():
                                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                                        -> ()
                                                      block1():
                                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                                        -> ()
                                                    return (%37)
                                              
                                                }
                                                method forward {
                                                  graph(%self.855 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6367.ConvReLU2d,
                                                        %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                    %_packed_params.193 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.855)
                                                    %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %input.221 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.193, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    return (%input.221)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6368.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = False
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.857 : __torch__.torch.nn.modules.linear.___torch_mangle_6368.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6370.Conv2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 88
                                            out_channels = 336
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3CFF0>
                                            scale = 0.00013504094386007637
                                            zero_point = 31
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6370.Conv2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6370.Conv2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6370.Conv2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6370.Conv2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.859 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6370.Conv2d,
                                                    %1 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu)):
                                                %_packed_params.195 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.859)
                                                %15 : float = prim::Constant[value=0.00013504094386007637](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=31](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.223 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.195, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.223)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.activation.___torch_mangle_6371.Sigmoid {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.861 : __torch__.torch.nn.modules.activation.___torch_mangle_6371.Sigmoid,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                                return (%2)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6375.TorchMultiply {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6374.QFunctional object at 0000018BEA679DE0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.863 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6375.TorchMultiply,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu),
                                                %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %mul_func.27 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6374.QFunctional = prim::GetAttr[name="mul_func"](%self.863)
                                            %activation_post_process.65 : __torch__.torch.nn.modules.linear.___torch_mangle_6373.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.27)
                                            %5 : float = prim::Constant[value=0.0063616079278290272](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %6 : int = prim::Constant[value=72](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.225 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.65)
                                            return (%input.225)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6374.QFunctional {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6373.Identity object at 0000018BEA6790E0>
                                          }
                                          methods {
                                          }
                                          submodules {
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6373.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.865 : __torch__.torch.nn.modules.linear.___torch_mangle_6373.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6379.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6377.Conv2d object at 0000018BEA67B9E0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6378.Identity object at 0000018BEA67A1E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.867 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6379.ConvBNRelu,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %bn.93 : __torch__.torch.nn.modules.linear.___torch_mangle_6378.Identity = prim::GetAttr[name="bn"](%self.867)
                                        %conv.169 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6377.Conv2d = prim::GetAttr[name="conv"](%self.867)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.169, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.93)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6377.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 336
                                        out_channels = 112
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3DE70>
                                        scale = 0.068887114524841309
                                        zero_point = 61
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6377.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6377.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6377.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6377.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.869 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6377.Conv2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %_packed_params.197 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.869)
                                            %15 : float = prim::Constant[value=0.068887114524841309](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %17 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.197, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6378.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.871 : __torch__.torch.nn.modules.linear.___torch_mangle_6378.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6382.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6381.QFunctional object at 0000018BEA67CDE0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.873 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6382.TorchAdd,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %add_func.39 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6381.QFunctional = prim::GetAttr[name="add_func"](%self.873)
                                        %activation_post_process.67 : __torch__.torch.nn.modules.linear.___torch_mangle_6380.Identity = prim::GetAttr[name="activation_post_process"](%add_func.39)
                                        %5 : float = prim::Constant[value=0.12308783084154129](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=57](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.227 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.67)
                                        return (%input.227)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6381.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6380.Identity object at 0000018BEA67B160>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6380.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.875 : __torch__.torch.nn.modules.linear.___torch_mangle_6380.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6407.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6387.ConvBNRelu object at 0000018BEA67FC60>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6389.ConvBNRelu object at 0000018BEA681DE0>
                                se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6400.SEModule object at 0000018BEA68ACE0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6403.ConvBNRelu object at 0000018BEACB2BF0>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6406.TorchAdd object at 0000018BEACB3B70>
                              }
                              methods {
                                method forward {
                                  graph(%self.877 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6407.IRFBlock,
                                        %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %res_conn.41 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6406.TorchAdd = prim::GetAttr[name="res_conn"](%self.877)
                                    %pwl.49 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6403.ConvBNRelu = prim::GetAttr[name="pwl"](%self.877)
                                    %se.59 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6400.SEModule = prim::GetAttr[name="se"](%self.877)
                                    %dw.57 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6389.ConvBNRelu = prim::GetAttr[name="dw"](%self.877)
                                    %pw.45 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6387.ConvBNRelu = prim::GetAttr[name="pw"](%self.877)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pw.45, %1)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%dw.57, %12)
                                    %14 : Tensor = prim::CallMethod[name="forward"](%se.59, %13)
                                    %15 : Tensor = prim::CallMethod[name="forward"](%pwl.49, %14)
                                    %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.41, %15, %1)
                                    return (%16)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6387.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6384.ConvReLU2d object at 0000018BEA67CE60>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6385.Identity object at 0000018BEA67F260>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6386.Identity object at 0000018BEA67E4E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.879 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6387.ConvBNRelu,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %relu.75 : __torch__.torch.nn.modules.linear.___torch_mangle_6386.Identity = prim::GetAttr[name="relu"](%self.879)
                                        %bn.95 : __torch__.torch.nn.modules.linear.___torch_mangle_6385.Identity = prim::GetAttr[name="bn"](%self.879)
                                        %conv.171 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6384.ConvReLU2d = prim::GetAttr[name="conv"](%self.879)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.171, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.95)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.75)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6384.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 112
                                        out_channels = 336
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D970>
                                        scale = 0.054365098476409912
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6384.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6384.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6384.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6384.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.881 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6384.ConvReLU2d,
                                                %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                            %_packed_params.199 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.881)
                                            %15 : float = prim::Constant[value=0.054365098476409912](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.229 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.199, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.229)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6385.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.883 : __torch__.torch.nn.modules.linear.___torch_mangle_6385.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6386.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.885 : __torch__.torch.nn.modules.linear.___torch_mangle_6386.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6389.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6388.Conv2d object at 0000018BEA67FE60>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.887 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6389.ConvBNRelu,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %conv.173 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6388.Conv2d = prim::GetAttr[name="conv"](%self.887)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.173, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6388.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 336
                                        out_channels = 336
                                        kernel_size = (5, 5)
                                        stride = (1, 1)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 336
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C970>
                                        scale = 0.011963602155447006
                                        zero_point = 65
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6388.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6388.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6388.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6388.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.889 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6388.Conv2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %_packed_params.201 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.889)
                                            %15 : float = prim::Constant[value=0.011963602155447006](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %x.31 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.201, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%x.31)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6400.SEModule {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6390.AdaptiveAvgPool2d object at 0000018BEA680560>
                                    se = <__torch__.torch.nn.modules.container.___torch_mangle_6396.Sequential object at 0000018BEA687CE0>
                                    mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6399.TorchMultiply object at 0000018BEA68B360>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.891 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6400.SEModule,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %mul.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6399.TorchMultiply = prim::GetAttr[name="mul"](%self.891)
                                        %se.57 : __torch__.torch.nn.modules.container.___torch_mangle_6396.Sequential = prim::GetAttr[name="se"](%self.891)
                                        %avg_pool.29 : __torch__.torch.nn.modules.pooling.___torch_mangle_6390.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.891)
                                        %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.29, %1)
                                        %33 : Tensor = prim::CallMethod[name="forward"](%se.57, %32)
                                        %34 : Tensor = prim::CallMethod[name="forward"](%mul.29, %1, %33)
                                        return (%34)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.pooling.___torch_mangle_6390.AdaptiveAvgPool2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.893 : __torch__.torch.nn.modules.pooling.___torch_mangle_6390.AdaptiveAvgPool2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.avg_pool
                                            %input.231 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            return (%input.231)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.container.___torch_mangle_6396.Sequential {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6393.ConvBNRelu object at 0000018BEA685F60>
                                        1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6394.Conv2d object at 0000018BEA686260>
                                        2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6395.Sigmoid object at 0000018BEA6873E0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.895 : __torch__.torch.nn.modules.container.___torch_mangle_6396.Sequential,
                                                %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %_2.31 : __torch__.torch.nn.modules.activation.___torch_mangle_6395.Sigmoid = prim::GetAttr[name="2"](%self.895)
                                            %_1.31 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6394.Conv2d = prim::GetAttr[name="1"](%self.895)
                                            %_0.37 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6393.ConvBNRelu = prim::GetAttr[name="0"](%self.895)
                                            %8 : Tensor = prim::CallMethod[name="forward"](%_0.37, %1)
                                            %9 : Tensor = prim::CallMethod[name="forward"](%_1.31, %8)
                                            %10 : Tensor = prim::CallMethod[name="forward"](%_2.31, %9)
                                            return (%10)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6393.ConvBNRelu {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                            conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6391.ConvReLU2d object at 0000018BEA682CE0>
                                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6392.Identity object at 0000018BEA683F60>
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.897 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6393.ConvBNRelu,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %relu.77 : __torch__.torch.nn.modules.linear.___torch_mangle_6392.Identity = prim::GetAttr[name="relu"](%self.897)
                                                %conv.175 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6391.ConvReLU2d = prim::GetAttr[name="conv"](%self.897)
                                                %6 : Tensor = prim::CallMethod[name="forward"](%conv.175, %1)
                                                %7 : NoneType = prim::CallMethod[name="forward"](%relu.77)
                                                return (%6)
                                          
                                            }
                                          }
                                          submodules {
                                            module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6391.ConvReLU2d {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                                in_channels = 336
                                                out_channels = 88
                                                kernel_size = (1, 1)
                                                stride = (1, 1)
                                                padding = (0, 0)
                                                dilation = (1, 1)
                                                transposed = False
                                                output_padding = (0, 0)
                                                groups = 1
                                                padding_mode = zeros
                                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C170>
                                                scale = 1.1920928955078125e-07
                                                zero_point = 0
                                              }
                                              methods {
                                                method __getstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6391.ConvReLU2d):
                                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                    %training : bool = prim::GetAttr[name="training"](%self)
                                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                    return (%19)
                                              
                                                }
                                                method __setstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6391.ConvReLU2d,
                                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                    %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                    %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                    %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                    %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                    %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                    %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                    %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                    %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                    %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                    %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                    %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                    %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                    %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                    %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                    %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                    %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                     = prim::SetAttr[name="stride"](%self, %13)
                                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                     = prim::SetAttr[name="padding"](%self, %16)
                                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                     = prim::SetAttr[name="dilation"](%self, %19)
                                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                                     = prim::SetAttr[name="transposed"](%self, %22)
                                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                                     = prim::SetAttr[name="groups"](%self, %28)
                                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                                     = prim::SetAttr[name="scale"](%self, %41)
                                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                                     = prim::SetAttr[name="training"](%self, %47)
                                                    return (%48)
                                              
                                                }
                                                method _weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6391.ConvReLU2d):
                                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                    return (%2)
                                              
                                                }
                                                method set_weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6391.ConvReLU2d,
                                                        %w.1 : Tensor,
                                                        %b.1 : Tensor?):
                                                    %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                    %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                    %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                     = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                      block0():
                                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                                        -> ()
                                                      block1():
                                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                                        -> ()
                                                    return (%37)
                                              
                                                }
                                                method forward {
                                                  graph(%self.899 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6391.ConvReLU2d,
                                                        %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                    %_packed_params.203 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.899)
                                                    %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %input.233 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.203, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    return (%input.233)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6392.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = False
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.901 : __torch__.torch.nn.modules.linear.___torch_mangle_6392.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6394.Conv2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 88
                                            out_channels = 336
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D1F0>
                                            scale = 0.00012768710439559072
                                            zero_point = 39
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6394.Conv2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6394.Conv2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6394.Conv2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6394.Conv2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.903 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6394.Conv2d,
                                                    %1 : QUInt8(1, 88, 1, 1, strides=[88, 1, 88, 88], requires_grad=0, device=cpu)):
                                                %_packed_params.205 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.903)
                                                %15 : float = prim::Constant[value=0.00012768710439559072](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=39](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.235 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.205, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.235)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.activation.___torch_mangle_6395.Sigmoid {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.905 : __torch__.torch.nn.modules.activation.___torch_mangle_6395.Sigmoid,
                                                    %1 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                                %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                                return (%2)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6399.TorchMultiply {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6398.QFunctional object at 0000018BEA68A160>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.907 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6399.TorchMultiply,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu),
                                                %2 : QUInt8(1, 336, 1, 1, strides=[336, 1, 336, 336], requires_grad=0, device=cpu)):
                                            %mul_func.29 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6398.QFunctional = prim::GetAttr[name="mul_func"](%self.907)
                                            %activation_post_process.69 : __torch__.torch.nn.modules.linear.___torch_mangle_6397.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.29)
                                            %5 : float = prim::Constant[value=0.0079161925241351128](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %6 : int = prim::Constant[value=43](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.237 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.69)
                                            return (%input.237)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6398.QFunctional {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6397.Identity object at 0000018BEA6884E0>
                                          }
                                          methods {
                                          }
                                          submodules {
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6397.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.909 : __torch__.torch.nn.modules.linear.___torch_mangle_6397.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6403.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6401.Conv2d object at 0000018BEA68A760>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6402.Identity object at 0000018BEACB3D70>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.911 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6403.ConvBNRelu,
                                            %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                        %bn.97 : __torch__.torch.nn.modules.linear.___torch_mangle_6402.Identity = prim::GetAttr[name="bn"](%self.911)
                                        %conv.177 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6401.Conv2d = prim::GetAttr[name="conv"](%self.911)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.177, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.97)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6401.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 336
                                        out_channels = 112
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3DFF0>
                                        scale = 0.099086955189704895
                                        zero_point = 64
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6401.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6401.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6401.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6401.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.913 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6401.Conv2d,
                                                %1 : QUInt8(1, 336, 14, 19, strides=[89376, 1, 6384, 336], requires_grad=0, device=cpu)):
                                            %_packed_params.207 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.913)
                                            %15 : float = prim::Constant[value=0.099086955189704895](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %17 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.207, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6402.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.915 : __torch__.torch.nn.modules.linear.___torch_mangle_6402.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6406.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6405.QFunctional object at 0000018BEACB3AF0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.917 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6406.TorchAdd,
                                            %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                        %add_func.41 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6405.QFunctional = prim::GetAttr[name="add_func"](%self.917)
                                        %activation_post_process.71 : __torch__.torch.nn.modules.linear.___torch_mangle_6404.Identity = prim::GetAttr[name="activation_post_process"](%add_func.41)
                                        %5 : float = prim::Constant[value=0.16053634881973267](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=58](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.239 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_4.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.71)
                                        return (%input.239)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6405.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6404.Identity object at 0000018BEACB3BF0>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6404.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.919 : __torch__.torch.nn.modules.linear.___torch_mangle_6404.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.d2go.modeling.backbone.modules.___torch_mangle_6412.RPNHeadConvRegressor {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        cls_logits = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6410.Conv2d object at 0000018BEACB40F0>
                        bbox_pred = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6411.Conv2d object at 0000018BEACB3670>
                      }
                      methods {
                        method forward {
                          graph(%self.921 : __torch__.d2go.modeling.backbone.modules.___torch_mangle_6412.RPNHeadConvRegressor,
                                %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                            %bbox_pred.1 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6411.Conv2d = prim::GetAttr[name="bbox_pred"](%self.921)
                            %cls_logits : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6410.Conv2d = prim::GetAttr[name="cls_logits"](%self.921)
                            %7 : Tensor = prim::CallMethod[name="forward"](%cls_logits, %1)
                            %8 : Tensor = prim::CallMethod[name="forward"](%bbox_pred.1, %1)
                            %6 : (QUInt8(1, 15, 14, 19, strides=[3990, 1, 285, 15], requires_grad=0, device=cpu), QUInt8(1, 60, 14, 19, strides=[15960, 1, 1140, 60], requires_grad=0, device=cpu)) = prim::TupleConstruct(%7, %8)
                            return (%6)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6410.Conv2d {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            in_channels = 112
                            out_channels = 15
                            kernel_size = (1, 1)
                            stride = (1, 1)
                            padding = (0, 0)
                            dilation = (1, 1)
                            transposed = False
                            output_padding = (0, 0)
                            groups = 1
                            padding_mode = zeros
                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C370>
                            scale = 0.22892257571220398
                            zero_point = 88
                          }
                          methods {
                            method __getstate__ {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6410.Conv2d):
                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                %groups : int = prim::GetAttr[name="groups"](%self)
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %scale : float = prim::GetAttr[name="scale"](%self)
                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                %training : bool = prim::GetAttr[name="training"](%self)
                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                return (%19)
                          
                            }
                            method __setstate__ {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6410.Conv2d,
                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                %4 : int = prim::TupleIndex(%state.1, %3)
                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                %7 : int = prim::TupleIndex(%state.1, %6)
                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                 = prim::SetAttr[name="stride"](%self, %13)
                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                 = prim::SetAttr[name="padding"](%self, %16)
                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                 = prim::SetAttr[name="dilation"](%self, %19)
                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                 = prim::SetAttr[name="transposed"](%self, %22)
                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                %28 : int = prim::TupleIndex(%state.1, %27)
                                 = prim::SetAttr[name="groups"](%self, %28)
                                %31 : str = prim::TupleIndex(%state.1, %30)
                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                %41 : float = prim::TupleIndex(%state.1, %40)
                                 = prim::SetAttr[name="scale"](%self, %41)
                                %44 : int = prim::TupleIndex(%state.1, %43)
                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                 = prim::SetAttr[name="training"](%self, %47)
                                return (%48)
                          
                            }
                            method _weight_bias {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6410.Conv2d):
                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                return (%2)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6410.Conv2d,
                                    %w.1 : Tensor,
                                    %b.1 : Tensor?):
                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                  block0():
                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                    -> ()
                                  block1():
                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                    -> ()
                                return (%37)
                          
                            }
                            method forward {
                              graph(%self.923 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6410.Conv2d,
                                    %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                %_packed_params.209 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.923)
                                %15 : float = prim::Constant[value=0.22892257571220398](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.cls_logits # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %16 : int = prim::Constant[value=88](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.cls_logits # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %Xq.3 : QUInt8(1, 15, 14, 19, strides=[3990, 1, 285, 15], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.209, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.cls_logits # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                return (%Xq.3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6411.Conv2d {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            in_channels = 112
                            out_channels = 60
                            kernel_size = (1, 1)
                            stride = (1, 1)
                            padding = (0, 0)
                            dilation = (1, 1)
                            transposed = False
                            output_padding = (0, 0)
                            groups = 1
                            padding_mode = zeros
                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3CA70>
                            scale = 0.040997181087732315
                            zero_point = 92
                          }
                          methods {
                            method __getstate__ {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6411.Conv2d):
                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                %groups : int = prim::GetAttr[name="groups"](%self)
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %scale : float = prim::GetAttr[name="scale"](%self)
                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                %training : bool = prim::GetAttr[name="training"](%self)
                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                return (%19)
                          
                            }
                            method __setstate__ {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6411.Conv2d,
                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                %4 : int = prim::TupleIndex(%state.1, %3)
                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                %7 : int = prim::TupleIndex(%state.1, %6)
                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                 = prim::SetAttr[name="stride"](%self, %13)
                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                 = prim::SetAttr[name="padding"](%self, %16)
                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                 = prim::SetAttr[name="dilation"](%self, %19)
                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                 = prim::SetAttr[name="transposed"](%self, %22)
                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                %28 : int = prim::TupleIndex(%state.1, %27)
                                 = prim::SetAttr[name="groups"](%self, %28)
                                %31 : str = prim::TupleIndex(%state.1, %30)
                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                %41 : float = prim::TupleIndex(%state.1, %40)
                                 = prim::SetAttr[name="scale"](%self, %41)
                                %44 : int = prim::TupleIndex(%state.1, %43)
                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                 = prim::SetAttr[name="training"](%self, %47)
                                return (%48)
                          
                            }
                            method _weight_bias {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6411.Conv2d):
                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                return (%2)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6411.Conv2d,
                                    %w.1 : Tensor,
                                    %b.1 : Tensor?):
                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                  block0():
                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                    -> ()
                                  block1():
                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                    -> ()
                                return (%37)
                          
                            }
                            method forward {
                              graph(%self.925 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6411.Conv2d,
                                    %1 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                %_packed_params.211 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.925)
                                %15 : float = prim::Constant[value=0.040997181087732315](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.bbox_pred # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %16 : int = prim::Constant[value=92](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.bbox_pred # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %Xq.5 : QUInt8(1, 60, 14, 19, strides=[15960, 1, 1140, 60], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.211, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.bbox_pred # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                return (%Xq.5)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6415.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_6414.ModuleList object at 0000018BEACB7D70>
                      }
                      methods {
                        method forward {
                          graph(%self.693 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6415.QuantStubNested,
                                %1 : Float(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                            %stubs.11 : __torch__.torch.nn.modules.container.___torch_mangle_6414.ModuleList = prim::GetAttr[name="stubs"](%self.693)
                            %_0.27 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6413.Quantize = prim::GetAttr[name="0"](%stubs.11)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.27, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_6414.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6413.Quantize object at 0000018BEACB4870>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6413.Quantize {
                              parameters {
                              }
                              attributes {
                                scale = ...
                                zero_point = ...
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.695 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6413.Quantize,
                                        %1 : Float(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                    %2 : float = prim::Constant[value=0.075057744979858398](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.quant_stubs/__module.model.model.proposal_generator.rpn_head.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    %3 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.quant_stubs/__module.model.model.proposal_generator.rpn_head.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.quant_stubs/__module.model.model.proposal_generator.rpn_head.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    %input.179 : QUInt8(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%1, %2, %3, %4), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.quant_stubs/__module.model.model.proposal_generator.rpn_head.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    return (%input.179)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6419.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_6418.ModuleList object at 0000018BEACB81F0>
                      }
                      methods {
                        method forward {
                          graph(%self.927 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6419.QuantStubNested,
                                %1 : QUInt8(1, 15, 14, 19, strides=[3990, 1, 285, 15], requires_grad=0, device=cpu),
                                %2 : QUInt8(1, 60, 14, 19, strides=[15960, 1, 1140, 60], requires_grad=0, device=cpu)):
                            %stubs.15 : __torch__.torch.nn.modules.container.___torch_mangle_6418.ModuleList = prim::GetAttr[name="stubs"](%self.927)
                            %_1.33 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6417.DeQuantize = prim::GetAttr[name="1"](%stubs.15)
                            %stubs.13 : __torch__.torch.nn.modules.container.___torch_mangle_6418.ModuleList = prim::GetAttr[name="stubs"](%self.927)
                            %_0.41 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6416.DeQuantize = prim::GetAttr[name="0"](%stubs.13)
                            %10 : Tensor = prim::CallMethod[name="forward"](%_0.41, %1)
                            %11 : Tensor = prim::CallMethod[name="forward"](%_1.33, %2)
                            %9 : (Float(1, 15, 14, 19, strides=[3990, 1, 285, 15], requires_grad=0, device=cpu), Float(1, 60, 14, 19, strides=[15960, 1, 1140, 60], requires_grad=0, device=cpu)) = prim::TupleConstruct(%10, %11)
                            return (%9)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_6418.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6416.DeQuantize object at 0000018BEACB96F0>
                            1 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6417.DeQuantize object at 0000018BEACB9DF0>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6416.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.929 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6416.DeQuantize,
                                        %1 : QUInt8(1, 15, 14, 19, strides=[3990, 1, 285, 15], requires_grad=0, device=cpu)):
                                    %score : Float(1, 15, 14, 19, strides=[3990, 1, 285, 15], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.dequant_stubs/__module.model.model.proposal_generator.rpn_head.dequant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:96:0
                                    return (%score)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6417.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.931 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6417.DeQuantize,
                                        %1 : QUInt8(1, 60, 14, 19, strides=[15960, 1, 1140, 60], requires_grad=0, device=cpu)):
                                    %x.33 : Float(1, 60, 14, 19, strides=[15960, 1, 1140, 60], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.dequant_stubs/__module.model.model.proposal_generator.rpn_head.dequant_stubs.stubs.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:96:0
                                    return (%x.33)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.detectron2.modeling.anchor_generator.___torch_mangle_6422.DefaultAnchorGenerator {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    cell_anchors = <__torch__.detectron2.modeling.anchor_generator.___torch_mangle_6421.BufferList object at 0000018BEACBB870>
                  }
                  methods {
                    method forward {
                      graph(%self.689 : __torch__.detectron2.modeling.anchor_generator.___torch_mangle_6422.DefaultAnchorGenerator,
                            %1 : Float(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                        %cell_anchors : __torch__.detectron2.modeling.anchor_generator.___torch_mangle_6421.BufferList = prim::GetAttr[name="cell_anchors"](%self.689)
                        %_0.25 : Tensor = prim::GetAttr[name="0"](%cell_anchors)
                        %10 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:229:0
                        %11 : int = aten::size(%1, %10), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:229:0
                        %grid_height : Long(device=cpu) = prim::NumToTensor(%11), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %13 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:229:0
                        %14 : int = aten::size(%1, %13), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:229:0
                        %grid_width : Long(device=cpu) = prim::NumToTensor(%14), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %16 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %17 : Long(requires_grad=0, device=cpu) = aten::mul(%grid_width, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %18 : Scalar = aten::ScalarImplicit(%17), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %19 : float = prim::Constant[value=0.](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %20 : int = prim::Constant[value=16](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %21 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %22 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %23 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %24 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %25 : Float(19, strides=[1], requires_grad=0, device=cpu) = aten::arange(%19, %18, %20, %21, %22, %23, %24), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %26 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %27 : Tensor = prim::CallFunction(%26, %25, %_0.25), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %28 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %29 : Long(requires_grad=0, device=cpu) = aten::mul(%grid_height, %28), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %30 : Scalar = aten::ScalarImplicit(%29), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %31 : float = prim::Constant[value=0.](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %32 : int = prim::Constant[value=16](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %33 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %34 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %35 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %36 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %37 : Float(14, strides=[1], requires_grad=0, device=cpu) = aten::arange(%31, %30, %32, %33, %34, %35, %36), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %38 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %39 : Tensor = prim::CallFunction(%38, %37, %_0.25), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %40 : Tensor[] = prim::ListConstruct(%39, %27), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %41 : Tensor[] = aten::meshgrid(%40), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\functional.py:504:0
                        %shift_y.1 : Float(14, 19, strides=[1, 0], requires_grad=0, device=cpu), %shift_x.1 : Float(14, 19, strides=[0, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%41), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %44 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:53:0
                        %45 : int[] = prim::ListConstruct(%44), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %shift_x : Float(266, strides=[1], requires_grad=0, device=cpu) = aten::reshape(%shift_x.1, %45), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:53:0
                        %47 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:54:0
                        %48 : int[] = prim::ListConstruct(%47), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %shift_y : Float(266, strides=[1], requires_grad=0, device=cpu) = aten::reshape(%shift_y.1, %48), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:54:0
                        %50 : Tensor[] = prim::ListConstruct(%shift_x, %shift_y, %shift_x, %shift_y), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %51 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:175:0
                        %shifts : Float(266, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::stack(%50, %51), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:175:0
                        %53 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %54 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %55 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %56 : int[] = prim::ListConstruct(%53, %54, %55), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %57 : Float(266, 1, 4, strides=[4, 4, 1], requires_grad=0, device=cpu) = aten::view(%shifts, %56), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %58 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %59 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %60 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %61 : int[] = prim::ListConstruct(%58, %59, %60), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %62 : Float(1, 15, 4, strides=[60, 4, 1], requires_grad=0, device=cpu) = aten::view(%_0.25, %61), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %63 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %64 : Float(266, 15, 4, strides=[60, 4, 1], requires_grad=0, device=cpu) = aten::add(%57, %62, %63), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %65 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %66 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %67 : int[] = prim::ListConstruct(%65, %66), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %tensor.1 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%64, %67), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %69 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                        %70 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                        %71 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                        %72 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %tensor.3 : Float(3990, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.1, %69, %70, %71, %72), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                        return (%tensor.3)
                  
                    }
                  }
                  submodules {
                    module __torch__.detectron2.modeling.anchor_generator.___torch_mangle_6421.BufferList {
                      parameters {
                      }
                      attributes {
                        0 = ...
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                      }
                      submodules {
                      }
                    }
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.roi_heads.roi_heads.___torch_mangle_6659.StandardROIHeads {
              parameters {
              }
              attributes {
                training = False
                _is_full_backward_hook = None
                box_pooler = <__torch__.detectron2.modeling.poolers.___torch_mangle_6426.ROIPooler object at 0000018BEACBA8F0>
                box_head = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6574.QuantWrapSubClass object at 0000018BEA8C6960>
                box_predictor = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6586.QuantWrapSubClass object at 0000018BEA8C98E0>
                mask_pooler = <__torch__.detectron2.modeling.poolers.___torch_mangle_6589.ROIPooler object at 0000018BEA8C8760>
                mask_head = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6658.QuantWrapSubClass object at 0000018BE9FEA470>
              }
              methods {
                method forward {
                  graph(%self.933 : __torch__.detectron2.modeling.roi_heads.roi_heads.___torch_mangle_6659.StandardROIHeads,
                        %1 : Float(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                        %2 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu),
                        %image_size : Long(2, strides=[1], requires_grad=0, device=cpu)):
                    %mask_head : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6658.QuantWrapSubClass = prim::GetAttr[name="mask_head"](%self.933)
                    %mask_pooler : __torch__.detectron2.modeling.poolers.___torch_mangle_6589.ROIPooler = prim::GetAttr[name="mask_pooler"](%self.933)
                    %box_predictor : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6586.QuantWrapSubClass = prim::GetAttr[name="box_predictor"](%self.933)
                    %box_head : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6574.QuantWrapSubClass = prim::GetAttr[name="box_head"](%self.933)
                    %box_pooler : __torch__.detectron2.modeling.poolers.___torch_mangle_6426.ROIPooler = prim::GetAttr[name="box_pooler"](%self.933)
                    %453 : Tensor = prim::CallMethod[name="forward"](%box_pooler, %1, %2)
                    %454 : Tensor = prim::CallMethod[name="forward"](%box_head, %453)
                    %455 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%box_predictor, %454)
                    %12 : Float(30, 72, strides=[72, 1], requires_grad=0, device=cpu), %13 : Float(30, 19, strides=[19, 1], requires_grad=0, device=cpu) = prim::TupleUnpack(%455)
                    %14 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:240:0
                    %15 : int = aten::size(%2, %14), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:240:0
                    %16 : Long(device=cpu) = prim::NumToTensor(%15), scope: __module.model/__module.model.model.roi_heads
                    %17 : int = aten::Int(%16), scope: __module.model/__module.model.model.roi_heads
                    %21 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %22 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %23 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %24 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %deltas : Float(30, 72, strides=[72, 1], requires_grad=0, device=cpu) = aten::to(%12, %21, %22, %23, %24), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %26 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %27 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %28 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %29 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %boxes.9 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%2, %26, %27, %28, %29), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %31 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %32 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %33 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %34 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %35 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.9, %31, %32, %33, %34), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %36 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %37 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %38 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%35, %36, %37), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %39 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %40 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %41 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %42 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %43 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.9, %39, %40, %41, %42), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %44 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %45 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %46 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%43, %44, %45), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %47 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %widths : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::sub(%38, %46, %47), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %49 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %50 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %51 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %52 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %53 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.9, %49, %50, %51, %52), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %54 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %55 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %56 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%53, %54, %55), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %57 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %58 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %59 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %60 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %61 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.9, %57, %58, %59, %60), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %62 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %63 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %64 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%61, %62, %63), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %65 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %heights : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::sub(%56, %64, %65), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %67 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %68 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %69 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %70 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %71 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.9, %67, %68, %69, %70), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %72 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %73 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %74 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%71, %72, %73), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %75 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %76 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::mul(%widths, %75), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %77 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %ctr_x : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::add(%74, %76, %77), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %79 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %80 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %81 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %82 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %83 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.9, %79, %80, %81, %82), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %84 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %85 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %86 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%83, %84, %85), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %87 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %88 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::mul(%heights, %87), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %89 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %ctr_y : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::add(%86, %88, %89), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %91 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %92 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %93 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %94 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %95 : Float(30, 72, strides=[72, 1], requires_grad=0, device=cpu) = aten::slice(%deltas, %91, %92, %93, %94), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %96 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %97 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %98 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %99 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %100 : Float(30, 18, strides=[72, 4], requires_grad=0, device=cpu) = aten::slice(%95, %96, %97, %98, %99), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %101 : Double(requires_grad=0, device=cpu) = prim::Constant[value={10}](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %dx : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::div(%100, %101), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %103 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %104 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %105 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %106 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %107 : Float(30, 72, strides=[72, 1], requires_grad=0, device=cpu) = aten::slice(%deltas, %103, %104, %105, %106), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %108 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %109 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %110 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %111 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %112 : Float(30, 18, strides=[72, 4], requires_grad=0, device=cpu) = aten::slice(%107, %108, %109, %110, %111), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %113 : Double(requires_grad=0, device=cpu) = prim::Constant[value={10}](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %dy : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::div(%112, %113), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %115 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %116 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %117 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %118 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %119 : Float(30, 72, strides=[72, 1], requires_grad=0, device=cpu) = aten::slice(%deltas, %115, %116, %117, %118), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %120 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %121 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %122 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %123 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %124 : Float(30, 18, strides=[72, 4], requires_grad=0, device=cpu) = aten::slice(%119, %120, %121, %122, %123), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %125 : Double(requires_grad=0, device=cpu) = prim::Constant[value={5}](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %dw.5 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::div(%124, %125), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %127 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %128 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %129 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %130 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %131 : Float(30, 72, strides=[72, 1], requires_grad=0, device=cpu) = aten::slice(%deltas, %127, %128, %129, %130), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %132 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %133 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %134 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %135 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %136 : Float(30, 18, strides=[72, 4], requires_grad=0, device=cpu) = aten::slice(%131, %132, %133, %134, %135), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %137 : Double(requires_grad=0, device=cpu) = prim::Constant[value={5}](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %dh.5 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::div(%136, %137), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %139 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %140 : float = prim::Constant[value=4.1351665567423561](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:103:0
                    %dw.7 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::clamp(%dw.5, %139, %140), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:103:0
                    %142 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %143 : float = prim::Constant[value=4.1351665567423561](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:104:0
                    %dh : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::clamp(%dh.5, %142, %143), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:104:0
                    %145 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %146 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %147 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %148 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %149 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%widths, %145, %146, %147, %148), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %150 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %151 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%149, %150), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %152 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::mul(%dx, %151), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %153 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %154 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %155 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %156 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %157 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%ctr_x, %153, %154, %155, %156), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %158 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %159 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%157, %158), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %160 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %pred_ctr_x : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::add(%152, %159, %160), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %162 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %163 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %164 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %165 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %166 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%heights, %162, %163, %164, %165), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %167 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %168 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%166, %167), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %169 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::mul(%dy, %168), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %170 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %171 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %172 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %173 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %174 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%ctr_y, %170, %171, %172, %173), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %175 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %176 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%174, %175), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %177 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %pred_ctr_y : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::add(%169, %176, %177), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %179 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::exp(%dw.7), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %180 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %181 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %182 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %183 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %184 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%widths, %180, %181, %182, %183), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %185 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %186 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%184, %185), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %pred_w : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::mul(%179, %186), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %188 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::exp(%dh), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %189 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %190 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %191 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %192 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %193 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%heights, %189, %190, %191, %192), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %194 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %195 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%193, %194), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %pred_h : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::mul(%188, %195), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %197 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %198 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::mul(%pred_w, %197), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %199 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %x1.5 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::sub(%pred_ctr_x, %198, %199), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %201 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %202 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::mul(%pred_h, %201), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %203 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %y1.5 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::sub(%pred_ctr_y, %202, %203), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %205 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %206 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::mul(%pred_w, %205), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %207 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %x2.5 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::add(%pred_ctr_x, %206, %207), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %209 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %210 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::mul(%pred_h, %209), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %211 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %y2.5 : Float(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::add(%pred_ctr_y, %210, %211), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %213 : Tensor[] = prim::ListConstruct(%x1.5, %y1.5, %x2.5, %y2.5), scope: __module.model/__module.model.model.roi_heads
                    %214 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:115:0
                    %pred_boxes : Float(30, 18, 4, strides=[72, 4, 1], requires_grad=0, device=cpu) = aten::stack(%213, %214), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:115:0
                    %216 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %217 : int = aten::size(%deltas, %216), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %218 : Long(device=cpu) = prim::NumToTensor(%217), scope: __module.model/__module.model.model.roi_heads
                    %219 : int = aten::Int(%218), scope: __module.model/__module.model.model.roi_heads
                    %220 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %221 : int = aten::size(%deltas, %220), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %222 : Long(device=cpu) = prim::NumToTensor(%221), scope: __module.model/__module.model.model.roi_heads
                    %223 : int = aten::Int(%222), scope: __module.model/__module.model.model.roi_heads
                    %224 : int[] = prim::ListConstruct(%219, %223), scope: __module.model/__module.model.model.roi_heads
                    %225 : Float(30, 72, strides=[72, 1], requires_grad=0, device=cpu) = aten::reshape(%pred_boxes, %224), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %226 : int[] = prim::ListConstruct(%17), scope: __module.model/__module.model.model.roi_heads
                    %227 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_tensor.py:789:0
                    %228 : Tensor[] = aten::split_with_sizes(%225, %226, %227), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_tensor.py:789:0
                    %boxes.11 : Float(30, 72, strides=[72, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%228), scope: __module.model/__module.model.model.roi_heads
                    %230 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:240:0
                    %231 : int = aten::size(%boxes.9, %230), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:240:0
                    %232 : Long(device=cpu) = prim::NumToTensor(%231), scope: __module.model/__module.model.model.roi_heads
                    %233 : int = aten::Int(%232), scope: __module.model/__module.model.model.roi_heads
                    %237 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1841:0
                    %238 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %239 : Float(30, 19, strides=[19, 1], requires_grad=0, device=cpu) = aten::softmax(%13, %237, %238), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1841:0
                    %240 : int[] = prim::ListConstruct(%233), scope: __module.model/__module.model.model.roi_heads
                    %241 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_tensor.py:789:0
                    %242 : Tensor[] = aten::split_with_sizes(%239, %240, %241), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_tensor.py:789:0
                    %scores.1 : Float(30, 19, strides=[19, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%242), scope: __module.model/__module.model.model.roi_heads
                    %254 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %255 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %256 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %257 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %258 : Float(30, 19, strides=[19, 1], requires_grad=0, device=cpu) = aten::slice(%scores.1, %254, %255, %256, %257), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %259 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %260 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %261 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %262 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %scores.3 : Float(30, 18, strides=[19, 1], requires_grad=0, device=cpu) = aten::slice(%258, %259, %260, %261, %262), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %267 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:143:0
                    %268 : int = aten::size(%boxes.11, %267), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:143:0
                    %269 : Long(device=cpu) = prim::NumToTensor(%268), scope: __module.model/__module.model.model.roi_heads
                    %270 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_tensor.py:868:0
                    %num_bbox_reg_classes : Long(requires_grad=0, device=cpu) = aten::floor_divide(%269, %270), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_tensor.py:868:0
                    %272 : int = aten::Int(%num_bbox_reg_classes), scope: __module.model/__module.model.model.roi_heads
                    %273 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:145:0
                    %274 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:145:0
                    %275 : int[] = prim::ListConstruct(%273, %274), scope: __module.model/__module.model.model.roi_heads
                    %tensor.17 : Float(540, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%boxes.11, %275), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:145:0
                    %277 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %278 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %279 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %280 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %tensor.19 : Float(540, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.17, %277, %278, %279, %280), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %293 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_tensor.py:926:0
                    %294 : Tensor[] = aten::unbind(%image_size, %293), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_tensor.py:926:0
                    %h : Long(requires_grad=0, device=cpu), %w : Long(requires_grad=0, device=cpu) = prim::ListUnpack(%294), scope: __module.model/__module.model.model.roi_heads
                    %297 : Scalar = aten::ScalarImplicit(%h), scope: __module.model/__module.model.model.roi_heads
                    %298 : Scalar = aten::ScalarImplicit(%w), scope: __module.model/__module.model.model.roi_heads
                    %299 : Scalar = aten::ScalarImplicit(%h), scope: __module.model/__module.model.model.roi_heads
                    %300 : Scalar = aten::ScalarImplicit(%w), scope: __module.model/__module.model.model.roi_heads
                    %301 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %302 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %303 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %304 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %305 : Float(540, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.19, %301, %302, %303, %304), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %306 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %307 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %308 : Float(540, strides=[4], requires_grad=0, device=cpu) = aten::select(%305, %306, %307), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %309 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %x1 : Float(540, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%308, %309, %300), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %311 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %312 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %313 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %314 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %315 : Float(540, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.19, %311, %312, %313, %314), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %316 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %317 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %318 : Float(540, strides=[4], requires_grad=0, device=cpu) = aten::select(%315, %316, %317), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %319 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %y1 : Float(540, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%318, %319, %299), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %321 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %322 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %323 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %324 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %325 : Float(540, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.19, %321, %322, %323, %324), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %326 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %327 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %328 : Float(540, strides=[4], requires_grad=0, device=cpu) = aten::select(%325, %326, %327), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %329 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %x2 : Float(540, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%328, %329, %298), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %331 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %332 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %333 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %334 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %335 : Float(540, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.19, %331, %332, %333, %334), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %336 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %337 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %338 : Float(540, strides=[4], requires_grad=0, device=cpu) = aten::select(%335, %336, %337), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %339 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %y2 : Float(540, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%338, %339, %297), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %341 : Tensor[] = prim::ListConstruct(%x1, %y1, %x2, %y2), scope: __module.model/__module.model.model.roi_heads
                    %342 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:197:0
                    %343 : Float(540, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::stack(%341, %342), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:197:0
                    %344 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:147:0
                    %345 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:147:0
                    %346 : int[] = prim::ListConstruct(%344, %272, %345), scope: __module.model/__module.model.model.roi_heads
                    %boxes.13 : Float(30, 18, 4, strides=[72, 4, 1], requires_grad=0, device=cpu) = aten::view(%343, %346), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:147:0
                    %348 : float = prim::Constant[value=0.20000000000000001](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:151:0
                    %filter_mask : Bool(30, 18, strides=[18, 1], requires_grad=0, device=cpu) = aten::gt(%scores.3, %348), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:151:0
                    %filter_inds.1 : Long(3, 2, strides=[1, 3], requires_grad=0, device=cpu) = aten::nonzero(%filter_mask), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:154:0
                    %353 : Tensor?[] = prim::ListConstruct(%filter_mask), scope: __module.model/__module.model.model.roi_heads
                    %boxes.15 : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::index(%boxes.13, %353), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:158:0
                    %355 : Tensor?[] = prim::ListConstruct(%filter_mask), scope: __module.model/__module.model.model.roi_heads
                    %scores : Float(3, strides=[1], requires_grad=0, device=cpu) = aten::index(%scores.3, %355), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:159:0
                    %357 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %358 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %359 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %360 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %361 : Long(3, 2, strides=[1, 3], requires_grad=0, device=cpu) = aten::slice(%filter_inds.1, %357, %358, %359, %360), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %362 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %363 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %364 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::select(%361, %362, %363), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %373 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\nms.py:20:0
                    %374 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\nms.py:20:0
                    %375 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\nms.py:20:0
                    %376 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %boxes.17 : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%boxes.15, %373, %374, %375, %376), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\nms.py:20:0
                    %382 : float = prim::Constant[value=0.5](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\jit\_trace.py:1139:0
                    %383 : Function = prim::Constant[name="_batched_nms_coordinate_trick"](), scope: __module.model/__module.model.model.roi_heads
                    %keep.3 : Tensor = prim::CallFunction(%383, %boxes.17, %scores, %364, %382), scope: __module.model/__module.model.model.roi_heads
                    %385 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %386 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %387 : int = prim::Constant[value=100](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %388 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %keep : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::slice(%keep.3, %385, %386, %387, %388), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %390 : Tensor?[] = prim::ListConstruct(%keep), scope: __module.model/__module.model.model.roi_heads
                    %tensor.21 : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::index(%boxes.17, %390), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:165:0
                    %392 : Tensor?[] = prim::ListConstruct(%keep), scope: __module.model/__module.model.model.roi_heads
                    %393 : Float(1, strides=[1], requires_grad=0, device=cpu) = aten::index(%scores, %392), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:165:0
                    %394 : Tensor?[] = prim::ListConstruct(%keep), scope: __module.model/__module.model.model.roi_heads
                    %filter_inds : Long(1, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::index(%filter_inds.1, %394), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:165:0
                    %396 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %397 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %398 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %399 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %tensor : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.21, %396, %397, %398, %399), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %425 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %426 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %427 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %428 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %429 : Long(1, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::slice(%filter_inds, %425, %426, %427, %428), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %430 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %431 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %class_pred : Long(1, strides=[2], requires_grad=0, device=cpu) = aten::select(%429, %430, %431), scope: __module.model/__module.model.model.roi_heads # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %456 : Tensor = prim::CallMethod[name="forward"](%mask_pooler, %1, %tensor)
                    %457 : Tensor = prim::CallMethod[name="forward"](%mask_head, %456, %class_pred, %tensor)
                    %452 : (Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu), Long(1, strides=[2], requires_grad=0, device=cpu), Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu), Float(1, strides=[1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%tensor, %class_pred, %457, %393)
                    return (%452)
              
                }
              }
              submodules {
                module __torch__.detectron2.modeling.poolers.___torch_mangle_6426.ROIPooler {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    level_poolers = <__torch__.torch.nn.modules.container.___torch_mangle_6425.ModuleList object at 0000018BEACBB7F0>
                  }
                  methods {
                    method forward {
                      graph(%self.935 : __torch__.detectron2.modeling.poolers.___torch_mangle_6426.ROIPooler,
                            %1 : Float(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                            %2 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu)):
                        %level_poolers.1 : __torch__.torch.nn.modules.container.___torch_mangle_6425.ModuleList = prim::GetAttr[name="level_poolers"](%self.935)
                        %_0.43 : __torch__.detectron2.layers.roi_align.___torch_mangle_6424.ROIAlign = prim::GetAttr[name="0"](%level_poolers.1)
                        %27 : Tensor[] = prim::ListConstruct(%2), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %28 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\poolers.py:95:0
                        %29 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::cat(%27, %28), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\poolers.py:95:0
                        %30 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %31 : int = aten::size(%2, %30), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %32 : Long(device=cpu) = prim::NumToTensor(%31), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %36 : Tensor[] = prim::ListConstruct(%32), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %37 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\wrappers.py:32:0
                        %38 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::stack(%36, %37), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\wrappers.py:32:0
                        %39 : Function = prim::Constant[name="_convert_boxes_to_pooler_format"](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %rois.1 : Tensor = prim::CallFunction(%39, %29, %38), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %42 : Tensor = prim::CallMethod[name="forward"](%_0.43, %rois.1, %1)
                        return (%42)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.___torch_mangle_6425.ModuleList {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.layers.roi_align.___torch_mangle_6424.ROIAlign object at 0000018BEACBABF0>
                      }
                      methods {
                      }
                      submodules {
                        module __torch__.detectron2.layers.roi_align.___torch_mangle_6424.ROIAlign {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.937 : __torch__.detectron2.layers.roi_align.___torch_mangle_6424.ROIAlign,
                                    %rois.1 : Tensor,
                                    %2 : Float(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                %8 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %9 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %10 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %11 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0
                                %boxes.7 : Float(30, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::to(%rois.1, %8, %9, %10, %11), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %18 : float = prim::Constant[value=0.0625](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %19 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %20 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %21 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %22 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %X.3 : Float(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu) = torchvision::roi_align(%2, %boxes.7, %18, %19, %20, %21, %22), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                return (%X.3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6574.QuantWrapSubClass {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    roi_box_conv = <__torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6566.FBNetModule object at 0000018BEA8C52E0>
                    avgpool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6567.AdaptiveAvgPool2d object at 0000018BEA8C4BE0>
                    quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6570.QuantStubNested object at 0000018BEA8C5B60>
                    dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6573.QuantStubNested object at 0000018BEA8C7D60>
                  }
                  methods {
                    method forward {
                      graph(%self.939 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6574.QuantWrapSubClass,
                            %1 : Float(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                        %dequant_stubs.5 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6573.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.939)
                        %avgpool : __torch__.torch.nn.modules.pooling.___torch_mangle_6567.AdaptiveAvgPool2d = prim::GetAttr[name="avgpool"](%self.939)
                        %roi_box_conv : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6566.FBNetModule = prim::GetAttr[name="roi_box_conv"](%self.939)
                        %quant_stubs.5 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6570.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.939)
                        %36 : Tensor = prim::CallMethod[name="forward"](%quant_stubs.5, %1)
                        %37 : Tensor = prim::CallMethod[name="forward"](%roi_box_conv, %36)
                        %38 : Tensor = prim::CallMethod[name="forward"](%avgpool, %37)
                        %39 : Tensor = prim::CallMethod[name="forward"](%dequant_stubs.5, %38)
                        return (%39)
                  
                    }
                  }
                  submodules {
                    module __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6566.FBNetModule {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.nn.modules.container.___torch_mangle_6565.Sequential object at 0000018BEA8C37E0>
                      }
                      methods {
                        method forward {
                          graph(%self.945 : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6566.FBNetModule,
                                %1 : QUInt8(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                            %_0.59 : __torch__.torch.nn.modules.container.___torch_mangle_6565.Sequential = prim::GetAttr[name="0"](%self.945)
                            %4 : Tensor = prim::CallMethod[name="forward"](%_0.59, %1)
                            return (%4)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_6565.Sequential {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            fbnetv2_0_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6447.IRFBlock object at 0000018BEACC84F0>
                            fbnetv2_0_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6471.IRFBlock object at 0000018BEACDACF0>
                            fbnetv2_0_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6495.IRFBlock object at 0000018BEACED170>
                            fbnetv2_0_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6519.IRFBlock object at 0000018BEA8A1DE0>
                            fbnetv2_0_4 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6543.IRFBlock object at 0000018BEA8B21E0>
                            fbnetv2_0_5 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6564.IRFBlock object at 0000018BEA8C36E0>
                          }
                          methods {
                            method forward {
                              graph(%self.947 : __torch__.torch.nn.modules.container.___torch_mangle_6565.Sequential,
                                    %1 : QUInt8(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                                %fbnetv2_0_5 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6564.IRFBlock = prim::GetAttr[name="fbnetv2_0_5"](%self.947)
                                %fbnetv2_0_4.3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6543.IRFBlock = prim::GetAttr[name="fbnetv2_0_4"](%self.947)
                                %fbnetv2_0_3.3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6519.IRFBlock = prim::GetAttr[name="fbnetv2_0_3"](%self.947)
                                %fbnetv2_0_2.5 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6495.IRFBlock = prim::GetAttr[name="fbnetv2_0_2"](%self.947)
                                %fbnetv2_0_1.5 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6471.IRFBlock = prim::GetAttr[name="fbnetv2_0_1"](%self.947)
                                %fbnetv2_0_0.5 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6447.IRFBlock = prim::GetAttr[name="fbnetv2_0_0"](%self.947)
                                %14 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_0.5, %1)
                                %15 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_1.5, %14)
                                %16 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_2.5, %15)
                                %17 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_3.3, %16)
                                %18 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_4.3, %17)
                                %19 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_5, %18)
                                return (%19)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6447.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6430.ConvBNRelu object at 0000018BEACBC5F0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6432.ConvBNRelu object at 0000018BEACBC970>
                                se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6443.SEModule object at 0000018BEACC72F0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6446.ConvBNRelu object at 0000018BEACC8370>
                              }
                              methods {
                                method forward {
                                  graph(%self.949 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6447.IRFBlock,
                                        %1 : QUInt8(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                                    %pwl.51 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6446.ConvBNRelu = prim::GetAttr[name="pwl"](%self.949)
                                    %se.63 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6443.SEModule = prim::GetAttr[name="se"](%self.949)
                                    %dw.59 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6432.ConvBNRelu = prim::GetAttr[name="dw"](%self.949)
                                    %pw.47 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6430.ConvBNRelu = prim::GetAttr[name="pw"](%self.949)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.47, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.59, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%se.63, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%pwl.51, %12)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6430.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6427.ConvReLU2d object at 0000018BEACBBDF0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6428.Identity object at 0000018BEACBBD70>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6429.Identity object at 0000018BEACBBF70>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.951 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6430.ConvBNRelu,
                                            %1 : QUInt8(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                                        %relu.79 : __torch__.torch.nn.modules.linear.___torch_mangle_6429.Identity = prim::GetAttr[name="relu"](%self.951)
                                        %bn.99 : __torch__.torch.nn.modules.linear.___torch_mangle_6428.Identity = prim::GetAttr[name="bn"](%self.951)
                                        %conv.179 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6427.ConvReLU2d = prim::GetAttr[name="conv"](%self.951)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.179, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.99)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.79)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6427.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 112
                                        out_channels = 448
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3DAF0>
                                        scale = 0.062738522887229919
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6427.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6427.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6427.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6427.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.953 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6427.ConvReLU2d,
                                                %1 : QUInt8(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                                            %_packed_params.213 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.953)
                                            %15 : float = prim::Constant[value=0.062738522887229919](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.243 : QUInt8(30, 448, 6, 6, strides=[16128, 1, 2688, 448], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.213, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.243)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6428.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.955 : __torch__.torch.nn.modules.linear.___torch_mangle_6428.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6429.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.957 : __torch__.torch.nn.modules.linear.___torch_mangle_6429.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6432.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6431.Conv2d object at 0000018BEACBC8F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.959 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6432.ConvBNRelu,
                                            %1 : QUInt8(30, 448, 6, 6, strides=[16128, 1, 2688, 448], requires_grad=0, device=cpu)):
                                        %conv.181 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6431.Conv2d = prim::GetAttr[name="conv"](%self.959)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.181, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6431.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 448
                                        out_channels = 448
                                        kernel_size = (5, 5)
                                        stride = (2, 2)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 448
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3E070>
                                        scale = 0.026383798569440842
                                        zero_point = 73
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6431.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6431.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6431.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6431.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.961 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6431.Conv2d,
                                                %1 : QUInt8(30, 448, 6, 6, strides=[16128, 1, 2688, 448], requires_grad=0, device=cpu)):
                                            %_packed_params.215 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.961)
                                            %15 : float = prim::Constant[value=0.026383798569440842](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=73](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %x.35 : QUInt8(30, 448, 3, 3, strides=[4032, 1, 1344, 448], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.215, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%x.35)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6443.SEModule {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6433.AdaptiveAvgPool2d object at 0000018BEACBCEF0>
                                    se = <__torch__.torch.nn.modules.container.___torch_mangle_6439.Sequential object at 0000018BEACC43F0>
                                    mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6442.TorchMultiply object at 0000018BEACC7F70>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.963 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6443.SEModule,
                                            %1 : QUInt8(30, 448, 3, 3, strides=[4032, 1, 1344, 448], requires_grad=0, device=cpu)):
                                        %mul.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6442.TorchMultiply = prim::GetAttr[name="mul"](%self.963)
                                        %se.61 : __torch__.torch.nn.modules.container.___torch_mangle_6439.Sequential = prim::GetAttr[name="se"](%self.963)
                                        %avg_pool.31 : __torch__.torch.nn.modules.pooling.___torch_mangle_6433.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.963)
                                        %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.31, %1)
                                        %33 : Tensor = prim::CallMethod[name="forward"](%se.61, %32)
                                        %34 : Tensor = prim::CallMethod[name="forward"](%mul.31, %1, %33)
                                        return (%34)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.pooling.___torch_mangle_6433.AdaptiveAvgPool2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.965 : __torch__.torch.nn.modules.pooling.___torch_mangle_6433.AdaptiveAvgPool2d,
                                                %1 : QUInt8(30, 448, 3, 3, strides=[4032, 1, 1344, 448], requires_grad=0, device=cpu)):
                                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.avg_pool
                                            %input.245 : QUInt8(30, 448, 1, 1, strides=[448, 1, 448, 448], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            return (%input.245)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.container.___torch_mangle_6439.Sequential {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6436.ConvBNRelu object at 0000018BEACC3B70>
                                        1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6437.Conv2d object at 0000018BEACC3870>
                                        2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6438.Sigmoid object at 0000018BEACC25F0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.967 : __torch__.torch.nn.modules.container.___torch_mangle_6439.Sequential,
                                                %1 : QUInt8(30, 448, 1, 1, strides=[448, 1, 448, 448], requires_grad=0, device=cpu)):
                                            %_2.33 : __torch__.torch.nn.modules.activation.___torch_mangle_6438.Sigmoid = prim::GetAttr[name="2"](%self.967)
                                            %_1.35 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6437.Conv2d = prim::GetAttr[name="1"](%self.967)
                                            %_0.47 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6436.ConvBNRelu = prim::GetAttr[name="0"](%self.967)
                                            %8 : Tensor = prim::CallMethod[name="forward"](%_0.47, %1)
                                            %9 : Tensor = prim::CallMethod[name="forward"](%_1.35, %8)
                                            %10 : Tensor = prim::CallMethod[name="forward"](%_2.33, %9)
                                            return (%10)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6436.ConvBNRelu {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                            conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6434.ConvReLU2d object at 0000018BEACBFE70>
                                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6435.Identity object at 0000018BEACBF2F0>
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.969 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6436.ConvBNRelu,
                                                    %1 : QUInt8(30, 448, 1, 1, strides=[448, 1, 448, 448], requires_grad=0, device=cpu)):
                                                %relu.81 : __torch__.torch.nn.modules.linear.___torch_mangle_6435.Identity = prim::GetAttr[name="relu"](%self.969)
                                                %conv.183 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6434.ConvReLU2d = prim::GetAttr[name="conv"](%self.969)
                                                %6 : Tensor = prim::CallMethod[name="forward"](%conv.183, %1)
                                                %7 : NoneType = prim::CallMethod[name="forward"](%relu.81)
                                                return (%6)
                                          
                                            }
                                          }
                                          submodules {
                                            module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6434.ConvReLU2d {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                                in_channels = 448
                                                out_channels = 112
                                                kernel_size = (1, 1)
                                                stride = (1, 1)
                                                padding = (0, 0)
                                                dilation = (1, 1)
                                                transposed = False
                                                output_padding = (0, 0)
                                                groups = 1
                                                padding_mode = zeros
                                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D370>
                                                scale = 1.1920928955078125e-07
                                                zero_point = 0
                                              }
                                              methods {
                                                method __getstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6434.ConvReLU2d):
                                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                    %training : bool = prim::GetAttr[name="training"](%self)
                                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                    return (%19)
                                              
                                                }
                                                method __setstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6434.ConvReLU2d,
                                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                    %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                    %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                    %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                    %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                    %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                    %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                    %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                    %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                    %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                    %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                    %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                    %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                    %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                    %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                    %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                    %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                     = prim::SetAttr[name="stride"](%self, %13)
                                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                     = prim::SetAttr[name="padding"](%self, %16)
                                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                     = prim::SetAttr[name="dilation"](%self, %19)
                                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                                     = prim::SetAttr[name="transposed"](%self, %22)
                                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                                     = prim::SetAttr[name="groups"](%self, %28)
                                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                                     = prim::SetAttr[name="scale"](%self, %41)
                                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                                     = prim::SetAttr[name="training"](%self, %47)
                                                    return (%48)
                                              
                                                }
                                                method _weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6434.ConvReLU2d):
                                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                    return (%2)
                                              
                                                }
                                                method set_weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6434.ConvReLU2d,
                                                        %w.1 : Tensor,
                                                        %b.1 : Tensor?):
                                                    %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                    %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                    %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                     = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                      block0():
                                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                                        -> ()
                                                      block1():
                                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                                        -> ()
                                                    return (%37)
                                              
                                                }
                                                method forward {
                                                  graph(%self.971 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6434.ConvReLU2d,
                                                        %1 : QUInt8(30, 448, 1, 1, strides=[448, 1, 448, 448], requires_grad=0, device=cpu)):
                                                    %_packed_params.217 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.971)
                                                    %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %input.247 : QUInt8(30, 112, 1, 1, strides=[112, 1, 112, 112], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.217, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    return (%input.247)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6435.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = False
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.973 : __torch__.torch.nn.modules.linear.___torch_mangle_6435.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6437.Conv2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 112
                                            out_channels = 448
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D470>
                                            scale = 0.00038170075276866555
                                            zero_point = 14
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6437.Conv2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6437.Conv2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6437.Conv2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6437.Conv2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.975 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6437.Conv2d,
                                                    %1 : QUInt8(30, 112, 1, 1, strides=[112, 1, 112, 112], requires_grad=0, device=cpu)):
                                                %_packed_params.219 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.975)
                                                %15 : float = prim::Constant[value=0.00038170075276866555](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=14](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.249 : QUInt8(30, 448, 1, 1, strides=[448, 1, 448, 448], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.219, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.249)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.activation.___torch_mangle_6438.Sigmoid {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.977 : __torch__.torch.nn.modules.activation.___torch_mangle_6438.Sigmoid,
                                                    %1 : QUInt8(30, 448, 1, 1, strides=[448, 1, 448, 448], requires_grad=0, device=cpu)):
                                                %2 : QUInt8(30, 448, 1, 1, strides=[448, 1, 448, 448], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                                return (%2)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6442.TorchMultiply {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6441.QFunctional object at 0000018BEACC6CF0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.979 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6442.TorchMultiply,
                                                %1 : QUInt8(30, 448, 3, 3, strides=[4032, 1, 1344, 448], requires_grad=0, device=cpu),
                                                %2 : QUInt8(30, 448, 1, 1, strides=[448, 1, 448, 448], requires_grad=0, device=cpu)):
                                            %mul_func.31 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6441.QFunctional = prim::GetAttr[name="mul_func"](%self.979)
                                            %activation_post_process.73 : __torch__.torch.nn.modules.linear.___torch_mangle_6440.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.31)
                                            %5 : float = prim::Constant[value=0.013206256553530693](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %6 : int = prim::Constant[value=73](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.251 : QUInt8(30, 448, 3, 3, strides=[4032, 1, 1344, 448], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.73)
                                            return (%input.251)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6441.QFunctional {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6440.Identity object at 0000018BEACC6AF0>
                                          }
                                          methods {
                                          }
                                          submodules {
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6440.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.981 : __torch__.torch.nn.modules.linear.___torch_mangle_6440.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6446.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6444.Conv2d object at 0000018BEACC8CF0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6445.Identity object at 0000018BEACC97F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.983 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6446.ConvBNRelu,
                                            %1 : QUInt8(30, 448, 3, 3, strides=[4032, 1, 1344, 448], requires_grad=0, device=cpu)):
                                        %bn.101 : __torch__.torch.nn.modules.linear.___torch_mangle_6445.Identity = prim::GetAttr[name="bn"](%self.983)
                                        %conv.185 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6444.Conv2d = prim::GetAttr[name="conv"](%self.983)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.185, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.101)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6444.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 448
                                        out_channels = 184
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3E0F0>
                                        scale = 0.11668611317873001
                                        zero_point = 66
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6444.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6444.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6444.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6444.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.985 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6444.Conv2d,
                                                %1 : QUInt8(30, 448, 3, 3, strides=[4032, 1, 1344, 448], requires_grad=0, device=cpu)):
                                            %_packed_params.221 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.985)
                                            %15 : float = prim::Constant[value=0.11668611317873001](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.253 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.221, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.253)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6445.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.987 : __torch__.torch.nn.modules.linear.___torch_mangle_6445.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6471.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6451.ConvBNRelu object at 0000018BEACCC1F0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6453.ConvBNRelu object at 0000018BEACCD170>
                                se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6464.SEModule object at 0000018BEACD9A70>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6467.ConvBNRelu object at 0000018BEACD93F0>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6470.TorchAdd object at 0000018BEACDB570>
                              }
                              methods {
                                method forward {
                                  graph(%self.989 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6471.IRFBlock,
                                        %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                    %res_conn.43 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6470.TorchAdd = prim::GetAttr[name="res_conn"](%self.989)
                                    %pwl.53 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6467.ConvBNRelu = prim::GetAttr[name="pwl"](%self.989)
                                    %se.67 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6464.SEModule = prim::GetAttr[name="se"](%self.989)
                                    %dw.61 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6453.ConvBNRelu = prim::GetAttr[name="dw"](%self.989)
                                    %pw.49 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6451.ConvBNRelu = prim::GetAttr[name="pw"](%self.989)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pw.49, %1)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%dw.61, %12)
                                    %14 : Tensor = prim::CallMethod[name="forward"](%se.67, %13)
                                    %15 : Tensor = prim::CallMethod[name="forward"](%pwl.53, %14)
                                    %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.43, %15, %1)
                                    return (%16)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6451.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6448.ConvReLU2d object at 0000018BEACCA6F0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6449.Identity object at 0000018BEACCBF70>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6450.Identity object at 0000018BEACCD5F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.991 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6451.ConvBNRelu,
                                            %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                        %relu.83 : __torch__.torch.nn.modules.linear.___torch_mangle_6450.Identity = prim::GetAttr[name="relu"](%self.991)
                                        %bn.103 : __torch__.torch.nn.modules.linear.___torch_mangle_6449.Identity = prim::GetAttr[name="bn"](%self.991)
                                        %conv.187 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6448.ConvReLU2d = prim::GetAttr[name="conv"](%self.991)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.187, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.103)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.83)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6448.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 184
                                        out_channels = 736
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3CCF0>
                                        scale = 0.052424553781747818
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6448.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6448.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6448.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6448.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.993 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6448.ConvReLU2d,
                                                %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                            %_packed_params.223 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.993)
                                            %15 : float = prim::Constant[value=0.052424553781747818](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.255 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.223, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.255)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6449.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.995 : __torch__.torch.nn.modules.linear.___torch_mangle_6449.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6450.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.997 : __torch__.torch.nn.modules.linear.___torch_mangle_6450.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6453.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6452.Conv2d object at 0000018BEACCCBF0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.999 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6453.ConvBNRelu,
                                            %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                        %conv.189 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6452.Conv2d = prim::GetAttr[name="conv"](%self.999)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.189, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6452.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 736
                                        out_channels = 736
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 736
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3DC70>
                                        scale = 0.0063442853279411793
                                        zero_point = 64
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6452.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6452.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6452.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6452.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1001 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6452.Conv2d,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                            %_packed_params.225 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1001)
                                            %15 : float = prim::Constant[value=0.0063442853279411793](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %x.37 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.225, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%x.37)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6464.SEModule {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6454.AdaptiveAvgPool2d object at 0000018BEACCECF0>
                                    se = <__torch__.torch.nn.modules.container.___torch_mangle_6460.Sequential object at 0000018BEACD44F0>
                                    mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6463.TorchMultiply object at 0000018BEACD77F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1003 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6464.SEModule,
                                            %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                        %mul.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6463.TorchMultiply = prim::GetAttr[name="mul"](%self.1003)
                                        %se.65 : __torch__.torch.nn.modules.container.___torch_mangle_6460.Sequential = prim::GetAttr[name="se"](%self.1003)
                                        %avg_pool.33 : __torch__.torch.nn.modules.pooling.___torch_mangle_6454.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.1003)
                                        %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.33, %1)
                                        %33 : Tensor = prim::CallMethod[name="forward"](%se.65, %32)
                                        %34 : Tensor = prim::CallMethod[name="forward"](%mul.33, %1, %33)
                                        return (%34)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.pooling.___torch_mangle_6454.AdaptiveAvgPool2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1005 : __torch__.torch.nn.modules.pooling.___torch_mangle_6454.AdaptiveAvgPool2d,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.avg_pool
                                            %input.257 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            return (%input.257)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.container.___torch_mangle_6460.Sequential {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6457.ConvBNRelu object at 0000018BEACD2F70>
                                        1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6458.Conv2d object at 0000018BEACD58F0>
                                        2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6459.Sigmoid object at 0000018BEACD4170>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1007 : __torch__.torch.nn.modules.container.___torch_mangle_6460.Sequential,
                                                %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                            %_2.35 : __torch__.torch.nn.modules.activation.___torch_mangle_6459.Sigmoid = prim::GetAttr[name="2"](%self.1007)
                                            %_1.37 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6458.Conv2d = prim::GetAttr[name="1"](%self.1007)
                                            %_0.49 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6457.ConvBNRelu = prim::GetAttr[name="0"](%self.1007)
                                            %8 : Tensor = prim::CallMethod[name="forward"](%_0.49, %1)
                                            %9 : Tensor = prim::CallMethod[name="forward"](%_1.37, %8)
                                            %10 : Tensor = prim::CallMethod[name="forward"](%_2.35, %9)
                                            return (%10)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6457.ConvBNRelu {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                            conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6455.ConvReLU2d object at 0000018BEACD1270>
                                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6456.Identity object at 0000018BEACD1970>
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1009 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6457.ConvBNRelu,
                                                    %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                                %relu.85 : __torch__.torch.nn.modules.linear.___torch_mangle_6456.Identity = prim::GetAttr[name="relu"](%self.1009)
                                                %conv.191 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6455.ConvReLU2d = prim::GetAttr[name="conv"](%self.1009)
                                                %6 : Tensor = prim::CallMethod[name="forward"](%conv.191, %1)
                                                %7 : NoneType = prim::CallMethod[name="forward"](%relu.85)
                                                return (%6)
                                          
                                            }
                                          }
                                          submodules {
                                            module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6455.ConvReLU2d {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                                in_channels = 736
                                                out_channels = 184
                                                kernel_size = (1, 1)
                                                stride = (1, 1)
                                                padding = (0, 0)
                                                dilation = (1, 1)
                                                transposed = False
                                                output_padding = (0, 0)
                                                groups = 1
                                                padding_mode = zeros
                                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3DB70>
                                                scale = 1.1920928955078125e-07
                                                zero_point = 0
                                              }
                                              methods {
                                                method __getstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6455.ConvReLU2d):
                                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                    %training : bool = prim::GetAttr[name="training"](%self)
                                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                    return (%19)
                                              
                                                }
                                                method __setstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6455.ConvReLU2d,
                                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                    %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                    %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                    %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                    %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                    %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                    %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                    %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                    %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                    %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                    %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                    %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                    %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                    %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                    %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                    %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                    %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                     = prim::SetAttr[name="stride"](%self, %13)
                                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                     = prim::SetAttr[name="padding"](%self, %16)
                                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                     = prim::SetAttr[name="dilation"](%self, %19)
                                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                                     = prim::SetAttr[name="transposed"](%self, %22)
                                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                                     = prim::SetAttr[name="groups"](%self, %28)
                                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                                     = prim::SetAttr[name="scale"](%self, %41)
                                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                                     = prim::SetAttr[name="training"](%self, %47)
                                                    return (%48)
                                              
                                                }
                                                method _weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6455.ConvReLU2d):
                                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                    return (%2)
                                              
                                                }
                                                method set_weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6455.ConvReLU2d,
                                                        %w.1 : Tensor,
                                                        %b.1 : Tensor?):
                                                    %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                    %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                    %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                     = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                      block0():
                                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                                        -> ()
                                                      block1():
                                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                                        -> ()
                                                    return (%37)
                                              
                                                }
                                                method forward {
                                                  graph(%self.1011 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6455.ConvReLU2d,
                                                        %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                                    %_packed_params.227 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1011)
                                                    %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %input.259 : QUInt8(30, 184, 1, 1, strides=[184, 1, 184, 184], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.227, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    return (%input.259)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6456.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = False
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.1013 : __torch__.torch.nn.modules.linear.___torch_mangle_6456.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6458.Conv2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 184
                                            out_channels = 736
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D270>
                                            scale = 0.00010648079478414729
                                            zero_point = 71
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6458.Conv2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6458.Conv2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6458.Conv2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6458.Conv2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.1015 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6458.Conv2d,
                                                    %1 : QUInt8(30, 184, 1, 1, strides=[184, 1, 184, 184], requires_grad=0, device=cpu)):
                                                %_packed_params.229 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1015)
                                                %15 : float = prim::Constant[value=0.00010648079478414729](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=71](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.261 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.229, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.261)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.activation.___torch_mangle_6459.Sigmoid {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1017 : __torch__.torch.nn.modules.activation.___torch_mangle_6459.Sigmoid,
                                                    %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                                %2 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                                return (%2)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6463.TorchMultiply {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6462.QFunctional object at 0000018BEACD75F0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1019 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6463.TorchMultiply,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu),
                                                %2 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                            %mul_func.33 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6462.QFunctional = prim::GetAttr[name="mul_func"](%self.1019)
                                            %activation_post_process.75 : __torch__.torch.nn.modules.linear.___torch_mangle_6461.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.33)
                                            %5 : float = prim::Constant[value=0.0030735672917217016](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %6 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.263 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.75)
                                            return (%input.263)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6462.QFunctional {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6461.Identity object at 0000018BEACD6DF0>
                                          }
                                          methods {
                                          }
                                          submodules {
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6461.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.1021 : __torch__.torch.nn.modules.linear.___torch_mangle_6461.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6467.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6465.Conv2d object at 0000018BEACD9C70>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6466.Identity object at 0000018BEACD8F70>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1023 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6467.ConvBNRelu,
                                            %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                        %bn.105 : __torch__.torch.nn.modules.linear.___torch_mangle_6466.Identity = prim::GetAttr[name="bn"](%self.1023)
                                        %conv.193 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6465.Conv2d = prim::GetAttr[name="conv"](%self.1023)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.193, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.105)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6465.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 736
                                        out_channels = 184
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C470>
                                        scale = 0.093607373535633087
                                        zero_point = 59
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6465.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6465.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6465.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6465.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1025 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6465.Conv2d,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                            %_packed_params.231 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1025)
                                            %15 : float = prim::Constant[value=0.093607373535633087](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=59](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %17 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.231, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6466.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1027 : __torch__.torch.nn.modules.linear.___torch_mangle_6466.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6470.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6469.QFunctional object at 0000018BEACDA1F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1029 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6470.TorchAdd,
                                            %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu),
                                            %2 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                        %add_func.43 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6469.QFunctional = prim::GetAttr[name="add_func"](%self.1029)
                                        %activation_post_process.77 : __torch__.torch.nn.modules.linear.___torch_mangle_6468.Identity = prim::GetAttr[name="activation_post_process"](%add_func.43)
                                        %5 : float = prim::Constant[value=0.11917215585708618](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.265 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.77)
                                        return (%input.265)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6469.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6468.Identity object at 0000018BEACDAB70>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6468.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1031 : __torch__.torch.nn.modules.linear.___torch_mangle_6468.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6495.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6475.ConvBNRelu object at 0000018BEACDFF70>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6477.ConvBNRelu object at 0000018BEACDE270>
                                se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6488.SEModule object at 0000018BEACE9570>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6491.ConvBNRelu object at 0000018BEACEA6F0>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6494.TorchAdd object at 0000018BEACECCF0>
                              }
                              methods {
                                method forward {
                                  graph(%self.1033 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6495.IRFBlock,
                                        %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                    %res_conn.45 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6494.TorchAdd = prim::GetAttr[name="res_conn"](%self.1033)
                                    %pwl.55 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6491.ConvBNRelu = prim::GetAttr[name="pwl"](%self.1033)
                                    %se.71 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6488.SEModule = prim::GetAttr[name="se"](%self.1033)
                                    %dw.63 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6477.ConvBNRelu = prim::GetAttr[name="dw"](%self.1033)
                                    %pw.51 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6475.ConvBNRelu = prim::GetAttr[name="pw"](%self.1033)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pw.51, %1)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%dw.63, %12)
                                    %14 : Tensor = prim::CallMethod[name="forward"](%se.71, %13)
                                    %15 : Tensor = prim::CallMethod[name="forward"](%pwl.55, %14)
                                    %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.45, %15, %1)
                                    return (%16)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6475.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6472.ConvReLU2d object at 0000018BEACDDCF0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6473.Identity object at 0000018BEACDC970>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6474.Identity object at 0000018BEACDF2F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1035 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6475.ConvBNRelu,
                                            %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                        %relu.87 : __torch__.torch.nn.modules.linear.___torch_mangle_6474.Identity = prim::GetAttr[name="relu"](%self.1035)
                                        %bn.107 : __torch__.torch.nn.modules.linear.___torch_mangle_6473.Identity = prim::GetAttr[name="bn"](%self.1035)
                                        %conv.195 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6472.ConvReLU2d = prim::GetAttr[name="conv"](%self.1035)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.195, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.107)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.87)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6472.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 184
                                        out_channels = 736
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C4F0>
                                        scale = 0.042814776301383972
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6472.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6472.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6472.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6472.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1037 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6472.ConvReLU2d,
                                                %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                            %_packed_params.233 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1037)
                                            %15 : float = prim::Constant[value=0.042814776301383972](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.267 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.233, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.267)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6473.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1039 : __torch__.torch.nn.modules.linear.___torch_mangle_6473.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6474.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1041 : __torch__.torch.nn.modules.linear.___torch_mangle_6474.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6477.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6476.Conv2d object at 0000018BEACDEBF0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1043 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6477.ConvBNRelu,
                                            %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                        %conv.197 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6476.Conv2d = prim::GetAttr[name="conv"](%self.1043)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.197, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6476.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 736
                                        out_channels = 736
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 736
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C570>
                                        scale = 0.0075231813825666904
                                        zero_point = 80
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6476.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6476.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6476.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6476.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1045 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6476.Conv2d,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                            %_packed_params.235 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1045)
                                            %15 : float = prim::Constant[value=0.0075231813825666904](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=80](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %x.39 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.235, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%x.39)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6488.SEModule {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6478.AdaptiveAvgPool2d object at 0000018BEACE10F0>
                                    se = <__torch__.torch.nn.modules.container.___torch_mangle_6484.Sequential object at 0000018BEACE7FF0>
                                    mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6487.TorchMultiply object at 0000018BEACE9270>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1047 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6488.SEModule,
                                            %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                        %mul.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6487.TorchMultiply = prim::GetAttr[name="mul"](%self.1047)
                                        %se.69 : __torch__.torch.nn.modules.container.___torch_mangle_6484.Sequential = prim::GetAttr[name="se"](%self.1047)
                                        %avg_pool.35 : __torch__.torch.nn.modules.pooling.___torch_mangle_6478.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.1047)
                                        %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.35, %1)
                                        %33 : Tensor = prim::CallMethod[name="forward"](%se.69, %32)
                                        %34 : Tensor = prim::CallMethod[name="forward"](%mul.35, %1, %33)
                                        return (%34)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.pooling.___torch_mangle_6478.AdaptiveAvgPool2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1049 : __torch__.torch.nn.modules.pooling.___torch_mangle_6478.AdaptiveAvgPool2d,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.avg_pool
                                            %input.269 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            return (%input.269)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.container.___torch_mangle_6484.Sequential {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6481.ConvBNRelu object at 0000018BEACE49F0>
                                        1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6482.Conv2d object at 0000018BEACE5B70>
                                        2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6483.Sigmoid object at 0000018BEACE4D70>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1051 : __torch__.torch.nn.modules.container.___torch_mangle_6484.Sequential,
                                                %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                            %_2.37 : __torch__.torch.nn.modules.activation.___torch_mangle_6483.Sigmoid = prim::GetAttr[name="2"](%self.1051)
                                            %_1.39 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6482.Conv2d = prim::GetAttr[name="1"](%self.1051)
                                            %_0.51 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6481.ConvBNRelu = prim::GetAttr[name="0"](%self.1051)
                                            %8 : Tensor = prim::CallMethod[name="forward"](%_0.51, %1)
                                            %9 : Tensor = prim::CallMethod[name="forward"](%_1.39, %8)
                                            %10 : Tensor = prim::CallMethod[name="forward"](%_2.37, %9)
                                            return (%10)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6481.ConvBNRelu {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                            conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6479.ConvReLU2d object at 0000018BEACE3BF0>
                                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6480.Identity object at 0000018BEACE40F0>
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1053 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6481.ConvBNRelu,
                                                    %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                                %relu.89 : __torch__.torch.nn.modules.linear.___torch_mangle_6480.Identity = prim::GetAttr[name="relu"](%self.1053)
                                                %conv.199 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6479.ConvReLU2d = prim::GetAttr[name="conv"](%self.1053)
                                                %6 : Tensor = prim::CallMethod[name="forward"](%conv.199, %1)
                                                %7 : NoneType = prim::CallMethod[name="forward"](%relu.89)
                                                return (%6)
                                          
                                            }
                                          }
                                          submodules {
                                            module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6479.ConvReLU2d {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                                in_channels = 736
                                                out_channels = 184
                                                kernel_size = (1, 1)
                                                stride = (1, 1)
                                                padding = (0, 0)
                                                dilation = (1, 1)
                                                transposed = False
                                                output_padding = (0, 0)
                                                groups = 1
                                                padding_mode = zeros
                                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C5F0>
                                                scale = 1.1920928955078125e-07
                                                zero_point = 0
                                              }
                                              methods {
                                                method __getstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6479.ConvReLU2d):
                                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                    %training : bool = prim::GetAttr[name="training"](%self)
                                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                    return (%19)
                                              
                                                }
                                                method __setstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6479.ConvReLU2d,
                                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                    %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                    %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                    %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                    %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                    %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                    %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                    %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                    %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                    %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                    %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                    %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                    %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                    %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                    %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                    %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                    %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                     = prim::SetAttr[name="stride"](%self, %13)
                                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                     = prim::SetAttr[name="padding"](%self, %16)
                                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                     = prim::SetAttr[name="dilation"](%self, %19)
                                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                                     = prim::SetAttr[name="transposed"](%self, %22)
                                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                                     = prim::SetAttr[name="groups"](%self, %28)
                                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                                     = prim::SetAttr[name="scale"](%self, %41)
                                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                                     = prim::SetAttr[name="training"](%self, %47)
                                                    return (%48)
                                              
                                                }
                                                method _weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6479.ConvReLU2d):
                                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                    return (%2)
                                              
                                                }
                                                method set_weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6479.ConvReLU2d,
                                                        %w.1 : Tensor,
                                                        %b.1 : Tensor?):
                                                    %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                    %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                    %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                     = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                      block0():
                                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                                        -> ()
                                                      block1():
                                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                                        -> ()
                                                    return (%37)
                                              
                                                }
                                                method forward {
                                                  graph(%self.1055 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6479.ConvReLU2d,
                                                        %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                                    %_packed_params.237 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1055)
                                                    %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %input.271 : QUInt8(30, 184, 1, 1, strides=[184, 1, 184, 184], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.237, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    return (%input.271)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6480.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = False
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.1057 : __torch__.torch.nn.modules.linear.___torch_mangle_6480.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6482.Conv2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 184
                                            out_channels = 736
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C7F0>
                                            scale = 0.00010738168202806264
                                            zero_point = 39
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6482.Conv2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6482.Conv2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6482.Conv2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6482.Conv2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.1059 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6482.Conv2d,
                                                    %1 : QUInt8(30, 184, 1, 1, strides=[184, 1, 184, 184], requires_grad=0, device=cpu)):
                                                %_packed_params.239 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1059)
                                                %15 : float = prim::Constant[value=0.00010738168202806264](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=39](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.273 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.239, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.273)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.activation.___torch_mangle_6483.Sigmoid {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1061 : __torch__.torch.nn.modules.activation.___torch_mangle_6483.Sigmoid,
                                                    %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                                %2 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                                return (%2)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6487.TorchMultiply {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6486.QFunctional object at 0000018BEACE8270>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1063 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6487.TorchMultiply,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu),
                                                %2 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                            %mul_func.35 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6486.QFunctional = prim::GetAttr[name="mul_func"](%self.1063)
                                            %activation_post_process.79 : __torch__.torch.nn.modules.linear.___torch_mangle_6485.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.35)
                                            %5 : float = prim::Constant[value=0.0037761512212455273](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %6 : int = prim::Constant[value=80](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.275 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.79)
                                            return (%input.275)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6486.QFunctional {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6485.Identity object at 0000018BEACE85F0>
                                          }
                                          methods {
                                          }
                                          submodules {
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6485.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.1065 : __torch__.torch.nn.modules.linear.___torch_mangle_6485.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6491.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6489.Conv2d object at 0000018BEACEB770>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6490.Identity object at 0000018BEACEBCF0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1067 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6491.ConvBNRelu,
                                            %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                        %bn.109 : __torch__.torch.nn.modules.linear.___torch_mangle_6490.Identity = prim::GetAttr[name="bn"](%self.1067)
                                        %conv.201 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6489.Conv2d = prim::GetAttr[name="conv"](%self.1067)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.201, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.109)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6489.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 736
                                        out_channels = 184
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C670>
                                        scale = 0.094367966055870056
                                        zero_point = 61
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6489.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6489.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6489.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6489.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1069 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6489.Conv2d,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                            %_packed_params.241 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1069)
                                            %15 : float = prim::Constant[value=0.094367966055870056](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %17 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.241, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6490.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1071 : __torch__.torch.nn.modules.linear.___torch_mangle_6490.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6494.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6493.QFunctional object at 0000018BEACECA70>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1073 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6494.TorchAdd,
                                            %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu),
                                            %2 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                        %add_func.45 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6493.QFunctional = prim::GetAttr[name="add_func"](%self.1073)
                                        %activation_post_process.81 : __torch__.torch.nn.modules.linear.___torch_mangle_6492.Identity = prim::GetAttr[name="activation_post_process"](%add_func.45)
                                        %5 : float = prim::Constant[value=0.13020206987857819](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.277 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.81)
                                        return (%input.277)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6493.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6492.Identity object at 0000018BEACEC9F0>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6492.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1075 : __torch__.torch.nn.modules.linear.___torch_mangle_6492.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6519.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6499.ConvBNRelu object at 0000018BEACF0DF0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6501.ConvBNRelu object at 0000018BEA898B60>
                                se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6512.SEModule object at 0000018BEA89C460>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6515.ConvBNRelu object at 0000018BEA8A0FE0>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6518.TorchAdd object at 0000018BEA8A16E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.1077 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6519.IRFBlock,
                                        %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                    %res_conn.47 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6518.TorchAdd = prim::GetAttr[name="res_conn"](%self.1077)
                                    %pwl.57 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6515.ConvBNRelu = prim::GetAttr[name="pwl"](%self.1077)
                                    %se.75 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6512.SEModule = prim::GetAttr[name="se"](%self.1077)
                                    %dw.65 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6501.ConvBNRelu = prim::GetAttr[name="dw"](%self.1077)
                                    %pw.53 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6499.ConvBNRelu = prim::GetAttr[name="pw"](%self.1077)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pw.53, %1)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%dw.65, %12)
                                    %14 : Tensor = prim::CallMethod[name="forward"](%se.75, %13)
                                    %15 : Tensor = prim::CallMethod[name="forward"](%pwl.57, %14)
                                    %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.47, %15, %1)
                                    return (%16)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6499.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6496.ConvReLU2d object at 0000018BEACEF7F0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6497.Identity object at 0000018BEACEF570>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6498.Identity object at 0000018BEACEE3F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1079 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6499.ConvBNRelu,
                                            %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                        %relu.91 : __torch__.torch.nn.modules.linear.___torch_mangle_6498.Identity = prim::GetAttr[name="relu"](%self.1079)
                                        %bn.111 : __torch__.torch.nn.modules.linear.___torch_mangle_6497.Identity = prim::GetAttr[name="bn"](%self.1079)
                                        %conv.203 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6496.ConvReLU2d = prim::GetAttr[name="conv"](%self.1079)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.203, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.111)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.91)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6496.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 184
                                        out_channels = 736
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D4F0>
                                        scale = 0.032224860042333603
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6496.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6496.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6496.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6496.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1081 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6496.ConvReLU2d,
                                                %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                            %_packed_params.243 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1081)
                                            %15 : float = prim::Constant[value=0.032224860042333603](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.279 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.243, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.279)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6497.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1083 : __torch__.torch.nn.modules.linear.___torch_mangle_6497.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6498.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1085 : __torch__.torch.nn.modules.linear.___torch_mangle_6498.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6501.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6500.Conv2d object at 0000018BEACF03F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1087 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6501.ConvBNRelu,
                                            %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                        %conv.205 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6500.Conv2d = prim::GetAttr[name="conv"](%self.1087)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.205, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6500.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 736
                                        out_channels = 736
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 736
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D5F0>
                                        scale = 0.0066443523392081261
                                        zero_point = 79
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6500.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6500.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6500.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6500.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1089 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6500.Conv2d,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                            %_packed_params.245 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1089)
                                            %15 : float = prim::Constant[value=0.0066443523392081261](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=79](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %x.41 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.245, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%x.41)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6512.SEModule {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6502.AdaptiveAvgPool2d object at 0000018BEA898160>
                                    se = <__torch__.torch.nn.modules.container.___torch_mangle_6508.Sequential object at 0000018BEA89B7E0>
                                    mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6511.TorchMultiply object at 0000018BEA89D660>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1091 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6512.SEModule,
                                            %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                        %mul.37 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6511.TorchMultiply = prim::GetAttr[name="mul"](%self.1091)
                                        %se.73 : __torch__.torch.nn.modules.container.___torch_mangle_6508.Sequential = prim::GetAttr[name="se"](%self.1091)
                                        %avg_pool.37 : __torch__.torch.nn.modules.pooling.___torch_mangle_6502.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.1091)
                                        %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.37, %1)
                                        %33 : Tensor = prim::CallMethod[name="forward"](%se.73, %32)
                                        %34 : Tensor = prim::CallMethod[name="forward"](%mul.37, %1, %33)
                                        return (%34)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.pooling.___torch_mangle_6502.AdaptiveAvgPool2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1093 : __torch__.torch.nn.modules.pooling.___torch_mangle_6502.AdaptiveAvgPool2d,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.avg_pool
                                            %input.281 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            return (%input.281)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.container.___torch_mangle_6508.Sequential {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6505.ConvBNRelu object at 0000018BEA8990E0>
                                        1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6506.Conv2d object at 0000018BEA899860>
                                        2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6507.Sigmoid object at 0000018BEA89A760>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1095 : __torch__.torch.nn.modules.container.___torch_mangle_6508.Sequential,
                                                %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                            %_2.39 : __torch__.torch.nn.modules.activation.___torch_mangle_6507.Sigmoid = prim::GetAttr[name="2"](%self.1095)
                                            %_1.41 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6506.Conv2d = prim::GetAttr[name="1"](%self.1095)
                                            %_0.53 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6505.ConvBNRelu = prim::GetAttr[name="0"](%self.1095)
                                            %8 : Tensor = prim::CallMethod[name="forward"](%_0.53, %1)
                                            %9 : Tensor = prim::CallMethod[name="forward"](%_1.41, %8)
                                            %10 : Tensor = prim::CallMethod[name="forward"](%_2.39, %9)
                                            return (%10)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6505.ConvBNRelu {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                            conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6503.ConvReLU2d object at 0000018BEA8993E0>
                                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6504.Identity object at 0000018BEA8996E0>
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1097 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6505.ConvBNRelu,
                                                    %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                                %relu.93 : __torch__.torch.nn.modules.linear.___torch_mangle_6504.Identity = prim::GetAttr[name="relu"](%self.1097)
                                                %conv.207 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6503.ConvReLU2d = prim::GetAttr[name="conv"](%self.1097)
                                                %6 : Tensor = prim::CallMethod[name="forward"](%conv.207, %1)
                                                %7 : NoneType = prim::CallMethod[name="forward"](%relu.93)
                                                return (%6)
                                          
                                            }
                                          }
                                          submodules {
                                            module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6503.ConvReLU2d {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                                in_channels = 736
                                                out_channels = 184
                                                kernel_size = (1, 1)
                                                stride = (1, 1)
                                                padding = (0, 0)
                                                dilation = (1, 1)
                                                transposed = False
                                                output_padding = (0, 0)
                                                groups = 1
                                                padding_mode = zeros
                                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C6F0>
                                                scale = 1.1920928955078125e-07
                                                zero_point = 0
                                              }
                                              methods {
                                                method __getstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6503.ConvReLU2d):
                                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                    %training : bool = prim::GetAttr[name="training"](%self)
                                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                    return (%19)
                                              
                                                }
                                                method __setstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6503.ConvReLU2d,
                                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                    %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                    %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                    %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                    %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                    %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                    %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                    %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                    %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                    %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                    %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                    %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                    %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                    %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                    %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                    %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                    %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                     = prim::SetAttr[name="stride"](%self, %13)
                                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                     = prim::SetAttr[name="padding"](%self, %16)
                                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                     = prim::SetAttr[name="dilation"](%self, %19)
                                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                                     = prim::SetAttr[name="transposed"](%self, %22)
                                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                                     = prim::SetAttr[name="groups"](%self, %28)
                                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                                     = prim::SetAttr[name="scale"](%self, %41)
                                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                                     = prim::SetAttr[name="training"](%self, %47)
                                                    return (%48)
                                              
                                                }
                                                method _weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6503.ConvReLU2d):
                                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                    return (%2)
                                              
                                                }
                                                method set_weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6503.ConvReLU2d,
                                                        %w.1 : Tensor,
                                                        %b.1 : Tensor?):
                                                    %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                    %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                    %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                     = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                      block0():
                                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                                        -> ()
                                                      block1():
                                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                                        -> ()
                                                    return (%37)
                                              
                                                }
                                                method forward {
                                                  graph(%self.1099 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6503.ConvReLU2d,
                                                        %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                                    %_packed_params.247 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1099)
                                                    %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %input.283 : QUInt8(30, 184, 1, 1, strides=[184, 1, 184, 184], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.247, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    return (%input.283)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6504.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = False
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.1101 : __torch__.torch.nn.modules.linear.___torch_mangle_6504.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6506.Conv2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 184
                                            out_channels = 736
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C770>
                                            scale = 0.00014222526806406677
                                            zero_point = 34
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6506.Conv2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6506.Conv2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6506.Conv2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6506.Conv2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.1103 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6506.Conv2d,
                                                    %1 : QUInt8(30, 184, 1, 1, strides=[184, 1, 184, 184], requires_grad=0, device=cpu)):
                                                %_packed_params.249 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1103)
                                                %15 : float = prim::Constant[value=0.00014222526806406677](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=34](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.285 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.249, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.285)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.activation.___torch_mangle_6507.Sigmoid {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1105 : __torch__.torch.nn.modules.activation.___torch_mangle_6507.Sigmoid,
                                                    %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                                %2 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                                return (%2)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6511.TorchMultiply {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6510.QFunctional object at 0000018BEA89E060>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1107 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6511.TorchMultiply,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu),
                                                %2 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                            %mul_func.37 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6510.QFunctional = prim::GetAttr[name="mul_func"](%self.1107)
                                            %activation_post_process.83 : __torch__.torch.nn.modules.linear.___torch_mangle_6509.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.37)
                                            %5 : float = prim::Constant[value=0.0031204482074826956](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %6 : int = prim::Constant[value=75](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.287 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.83)
                                            return (%input.287)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6510.QFunctional {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6509.Identity object at 0000018BEA89C7E0>
                                          }
                                          methods {
                                          }
                                          submodules {
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6509.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.1109 : __torch__.torch.nn.modules.linear.___torch_mangle_6509.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6515.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6513.Conv2d object at 0000018BEA89E960>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6514.Identity object at 0000018BEA89F960>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1111 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6515.ConvBNRelu,
                                            %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                        %bn.113 : __torch__.torch.nn.modules.linear.___torch_mangle_6514.Identity = prim::GetAttr[name="bn"](%self.1111)
                                        %conv.209 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6513.Conv2d = prim::GetAttr[name="conv"](%self.1111)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.209, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.113)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6513.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 736
                                        out_channels = 184
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3DBF0>
                                        scale = 0.1437276154756546
                                        zero_point = 49
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6513.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6513.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6513.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6513.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1113 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6513.Conv2d,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                            %_packed_params.251 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1113)
                                            %15 : float = prim::Constant[value=0.1437276154756546](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=49](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %17 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.251, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6514.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1115 : __torch__.torch.nn.modules.linear.___torch_mangle_6514.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6518.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6517.QFunctional object at 0000018BEA8A0160>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1117 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6518.TorchAdd,
                                            %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu),
                                            %2 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                        %add_func.47 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6517.QFunctional = prim::GetAttr[name="add_func"](%self.1117)
                                        %activation_post_process.85 : __torch__.torch.nn.modules.linear.___torch_mangle_6516.Identity = prim::GetAttr[name="activation_post_process"](%add_func.47)
                                        %5 : float = prim::Constant[value=0.15744976699352264](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.289 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.85)
                                        return (%input.289)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6517.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6516.Identity object at 0000018BEA8A06E0>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6516.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1119 : __torch__.torch.nn.modules.linear.___torch_mangle_6516.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6543.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6523.ConvBNRelu object at 0000018BEA8A4B60>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6525.ConvBNRelu object at 0000018BEA8A4460>
                                se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6536.SEModule object at 0000018BEA8AF5E0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6539.ConvBNRelu object at 0000018BEA8B0AE0>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6542.TorchAdd object at 0000018BEA8B2160>
                              }
                              methods {
                                method forward {
                                  graph(%self.1121 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6543.IRFBlock,
                                        %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                    %res_conn.49 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6542.TorchAdd = prim::GetAttr[name="res_conn"](%self.1121)
                                    %pwl.59 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6539.ConvBNRelu = prim::GetAttr[name="pwl"](%self.1121)
                                    %se.79 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6536.SEModule = prim::GetAttr[name="se"](%self.1121)
                                    %dw.67 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6525.ConvBNRelu = prim::GetAttr[name="dw"](%self.1121)
                                    %pw.55 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6523.ConvBNRelu = prim::GetAttr[name="pw"](%self.1121)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pw.55, %1)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%dw.67, %12)
                                    %14 : Tensor = prim::CallMethod[name="forward"](%se.79, %13)
                                    %15 : Tensor = prim::CallMethod[name="forward"](%pwl.59, %14)
                                    %16 : Tensor = prim::CallMethod[name="forward"](%res_conn.49, %15, %1)
                                    return (%16)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6523.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6520.ConvReLU2d object at 0000018BEA8A27E0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6521.Identity object at 0000018BEA8A2EE0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6522.Identity object at 0000018BEA8A4960>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1123 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6523.ConvBNRelu,
                                            %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                        %relu.95 : __torch__.torch.nn.modules.linear.___torch_mangle_6522.Identity = prim::GetAttr[name="relu"](%self.1123)
                                        %bn.115 : __torch__.torch.nn.modules.linear.___torch_mangle_6521.Identity = prim::GetAttr[name="bn"](%self.1123)
                                        %conv.211 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6520.ConvReLU2d = prim::GetAttr[name="conv"](%self.1123)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.211, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.115)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.95)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6520.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 184
                                        out_channels = 736
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C870>
                                        scale = 0.034690015017986298
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6520.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6520.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6520.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6520.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1125 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6520.ConvReLU2d,
                                                %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                            %_packed_params.253 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1125)
                                            %15 : float = prim::Constant[value=0.034690015017986298](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.291 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.253, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.291)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6521.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1127 : __torch__.torch.nn.modules.linear.___torch_mangle_6521.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6522.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1129 : __torch__.torch.nn.modules.linear.___torch_mangle_6522.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6525.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6524.Conv2d object at 0000018BEA8A4360>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1131 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6525.ConvBNRelu,
                                            %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                        %conv.213 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6524.Conv2d = prim::GetAttr[name="conv"](%self.1131)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.213, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6524.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 736
                                        out_channels = 736
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 736
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3C8F0>
                                        scale = 0.0066893543116748333
                                        zero_point = 69
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6524.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6524.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6524.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6524.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1133 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6524.Conv2d,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                            %_packed_params.255 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1133)
                                            %15 : float = prim::Constant[value=0.0066893543116748333](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=69](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %x.43 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.255, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%x.43)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6536.SEModule {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6526.AdaptiveAvgPool2d object at 0000018BEA8A7B60>
                                    se = <__torch__.torch.nn.modules.container.___torch_mangle_6532.Sequential object at 0000018BEA8AEA60>
                                    mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6535.TorchMultiply object at 0000018BEA8AEEE0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1135 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6536.SEModule,
                                            %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                        %mul.39 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6535.TorchMultiply = prim::GetAttr[name="mul"](%self.1135)
                                        %se.77 : __torch__.torch.nn.modules.container.___torch_mangle_6532.Sequential = prim::GetAttr[name="se"](%self.1135)
                                        %avg_pool.39 : __torch__.torch.nn.modules.pooling.___torch_mangle_6526.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.1135)
                                        %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool.39, %1)
                                        %33 : Tensor = prim::CallMethod[name="forward"](%se.77, %32)
                                        %34 : Tensor = prim::CallMethod[name="forward"](%mul.39, %1, %33)
                                        return (%34)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.pooling.___torch_mangle_6526.AdaptiveAvgPool2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1137 : __torch__.torch.nn.modules.pooling.___torch_mangle_6526.AdaptiveAvgPool2d,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.avg_pool
                                            %input.293 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            return (%input.293)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.container.___torch_mangle_6532.Sequential {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6529.ConvBNRelu object at 0000018BEA8AAF60>
                                        1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6530.Conv2d object at 0000018BEA8AB9E0>
                                        2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6531.Sigmoid object at 0000018BEA8AA2E0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1139 : __torch__.torch.nn.modules.container.___torch_mangle_6532.Sequential,
                                                %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                            %_2.41 : __torch__.torch.nn.modules.activation.___torch_mangle_6531.Sigmoid = prim::GetAttr[name="2"](%self.1139)
                                            %_1.43 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6530.Conv2d = prim::GetAttr[name="1"](%self.1139)
                                            %_0.55 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6529.ConvBNRelu = prim::GetAttr[name="0"](%self.1139)
                                            %8 : Tensor = prim::CallMethod[name="forward"](%_0.55, %1)
                                            %9 : Tensor = prim::CallMethod[name="forward"](%_1.43, %8)
                                            %10 : Tensor = prim::CallMethod[name="forward"](%_2.41, %9)
                                            return (%10)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6529.ConvBNRelu {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                            conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6527.ConvReLU2d object at 0000018BEA8A7DE0>
                                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6528.Identity object at 0000018BEA8A96E0>
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1141 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6529.ConvBNRelu,
                                                    %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                                %relu.97 : __torch__.torch.nn.modules.linear.___torch_mangle_6528.Identity = prim::GetAttr[name="relu"](%self.1141)
                                                %conv.215 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6527.ConvReLU2d = prim::GetAttr[name="conv"](%self.1141)
                                                %6 : Tensor = prim::CallMethod[name="forward"](%conv.215, %1)
                                                %7 : NoneType = prim::CallMethod[name="forward"](%relu.97)
                                                return (%6)
                                          
                                            }
                                          }
                                          submodules {
                                            module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6527.ConvReLU2d {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                                in_channels = 736
                                                out_channels = 184
                                                kernel_size = (1, 1)
                                                stride = (1, 1)
                                                padding = (0, 0)
                                                dilation = (1, 1)
                                                transposed = False
                                                output_padding = (0, 0)
                                                groups = 1
                                                padding_mode = zeros
                                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D570>
                                                scale = 1.1920928955078125e-07
                                                zero_point = 0
                                              }
                                              methods {
                                                method __getstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6527.ConvReLU2d):
                                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                    %training : bool = prim::GetAttr[name="training"](%self)
                                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                    return (%19)
                                              
                                                }
                                                method __setstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6527.ConvReLU2d,
                                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                    %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                    %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                    %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                    %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                    %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                    %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                    %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                    %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                    %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                    %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                    %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                    %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                    %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                    %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                    %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                    %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                     = prim::SetAttr[name="stride"](%self, %13)
                                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                     = prim::SetAttr[name="padding"](%self, %16)
                                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                     = prim::SetAttr[name="dilation"](%self, %19)
                                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                                     = prim::SetAttr[name="transposed"](%self, %22)
                                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                                     = prim::SetAttr[name="groups"](%self, %28)
                                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                                     = prim::SetAttr[name="scale"](%self, %41)
                                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                                     = prim::SetAttr[name="training"](%self, %47)
                                                    return (%48)
                                              
                                                }
                                                method _weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6527.ConvReLU2d):
                                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                    return (%2)
                                              
                                                }
                                                method set_weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6527.ConvReLU2d,
                                                        %w.1 : Tensor,
                                                        %b.1 : Tensor?):
                                                    %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                    %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                    %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                     = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                      block0():
                                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                                        -> ()
                                                      block1():
                                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                                        -> ()
                                                    return (%37)
                                              
                                                }
                                                method forward {
                                                  graph(%self.1143 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6527.ConvReLU2d,
                                                        %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                                    %_packed_params.257 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1143)
                                                    %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %input.295 : QUInt8(30, 184, 1, 1, strides=[184, 1, 184, 184], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.257, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    return (%input.295)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6528.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = False
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.1145 : __torch__.torch.nn.modules.linear.___torch_mangle_6528.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6530.Conv2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 184
                                            out_channels = 736
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3CC70>
                                            scale = 0.0003341123228892684
                                            zero_point = 20
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6530.Conv2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6530.Conv2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6530.Conv2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6530.Conv2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.1147 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6530.Conv2d,
                                                    %1 : QUInt8(30, 184, 1, 1, strides=[184, 1, 184, 184], requires_grad=0, device=cpu)):
                                                %_packed_params.259 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1147)
                                                %15 : float = prim::Constant[value=0.0003341123228892684](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=20](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.297 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.259, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.297)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.activation.___torch_mangle_6531.Sigmoid {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1149 : __torch__.torch.nn.modules.activation.___torch_mangle_6531.Sigmoid,
                                                    %1 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                                %2 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                                return (%2)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6535.TorchMultiply {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6534.QFunctional object at 0000018BEA8AF3E0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1151 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6535.TorchMultiply,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu),
                                                %2 : QUInt8(30, 736, 1, 1, strides=[736, 1, 736, 736], requires_grad=0, device=cpu)):
                                            %mul_func.39 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6534.QFunctional = prim::GetAttr[name="mul_func"](%self.1151)
                                            %activation_post_process.87 : __torch__.torch.nn.modules.linear.___torch_mangle_6533.Identity = prim::GetAttr[name="activation_post_process"](%mul_func.39)
                                            %5 : float = prim::Constant[value=0.0033518190030008554](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %6 : int = prim::Constant[value=69](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.299 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.87)
                                            return (%input.299)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6534.QFunctional {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6533.Identity object at 0000018BEA8AE860>
                                          }
                                          methods {
                                          }
                                          submodules {
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6533.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.1153 : __torch__.torch.nn.modules.linear.___torch_mangle_6533.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6539.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6537.Conv2d object at 0000018BEA8B08E0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6538.Identity object at 0000018BEA8B20E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1155 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6539.ConvBNRelu,
                                            %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                        %bn.117 : __torch__.torch.nn.modules.linear.___torch_mangle_6538.Identity = prim::GetAttr[name="bn"](%self.1155)
                                        %conv.217 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6537.Conv2d = prim::GetAttr[name="conv"](%self.1155)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.217, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.117)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6537.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 736
                                        out_channels = 184
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D670>
                                        scale = 0.14299988746643066
                                        zero_point = 52
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6537.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6537.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6537.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6537.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1157 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6537.Conv2d,
                                                %1 : QUInt8(30, 736, 3, 3, strides=[6624, 1, 2208, 736], requires_grad=0, device=cpu)):
                                            %_packed_params.261 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1157)
                                            %15 : float = prim::Constant[value=0.14299988746643066](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=52](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %17 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.261, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6538.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1159 : __torch__.torch.nn.modules.linear.___torch_mangle_6538.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6542.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6541.QFunctional object at 0000018BEA8B37E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1161 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6542.TorchAdd,
                                            %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu),
                                            %2 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                        %add_func.49 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6541.QFunctional = prim::GetAttr[name="add_func"](%self.1161)
                                        %activation_post_process.89 : __torch__.torch.nn.modules.linear.___torch_mangle_6540.Identity = prim::GetAttr[name="activation_post_process"](%add_func.49)
                                        %5 : float = prim::Constant[value=0.17322206497192383](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.301 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_4.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.89)
                                        return (%input.301)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6541.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6540.Identity object at 0000018BEA8B31E0>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6540.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1163 : __torch__.torch.nn.modules.linear.___torch_mangle_6540.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6564.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6547.ConvBNRelu object at 0000018BEA8B77E0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6549.ConvBNRelu object at 0000018BEA8B63E0>
                                se = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6560.SEModule object at 0000018BEA8C0DE0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6563.ConvBNRelu object at 0000018BEA8C3360>
                              }
                              methods {
                                method forward {
                                  graph(%self.1165 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6564.IRFBlock,
                                        %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                    %pwl.61 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6563.ConvBNRelu = prim::GetAttr[name="pwl"](%self.1165)
                                    %se : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6560.SEModule = prim::GetAttr[name="se"](%self.1165)
                                    %dw.69 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6549.ConvBNRelu = prim::GetAttr[name="dw"](%self.1165)
                                    %pw.57 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6547.ConvBNRelu = prim::GetAttr[name="pw"](%self.1165)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.57, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.69, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%se, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%pwl.61, %12)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6547.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6544.ConvReLU2d object at 0000018BEA8B5360>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6545.Identity object at 0000018BEA8B56E0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6546.Identity object at 0000018BEA8B4F60>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1167 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6547.ConvBNRelu,
                                            %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                        %relu.99 : __torch__.torch.nn.modules.linear.___torch_mangle_6546.Identity = prim::GetAttr[name="relu"](%self.1167)
                                        %bn.119 : __torch__.torch.nn.modules.linear.___torch_mangle_6545.Identity = prim::GetAttr[name="bn"](%self.1167)
                                        %conv.219 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6544.ConvReLU2d = prim::GetAttr[name="conv"](%self.1167)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.219, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.119)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.99)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6544.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 184
                                        out_channels = 1104
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3DCF0>
                                        scale = 0.033178608864545822
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6544.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6544.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6544.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6544.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1169 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6544.ConvReLU2d,
                                                %1 : QUInt8(30, 184, 3, 3, strides=[1656, 1, 552, 184], requires_grad=0, device=cpu)):
                                            %_packed_params.263 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1169)
                                            %15 : float = prim::Constant[value=0.033178608864545822](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.303 : QUInt8(30, 1104, 3, 3, strides=[9936, 1, 3312, 1104], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.263, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.303)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6545.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1171 : __torch__.torch.nn.modules.linear.___torch_mangle_6545.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6546.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1173 : __torch__.torch.nn.modules.linear.___torch_mangle_6546.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6549.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6548.Conv2d object at 0000018BEA8B6C60>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1175 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6549.ConvBNRelu,
                                            %1 : QUInt8(30, 1104, 3, 3, strides=[9936, 1, 3312, 1104], requires_grad=0, device=cpu)):
                                        %conv.221 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6548.Conv2d = prim::GetAttr[name="conv"](%self.1175)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.221, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6548.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 1104
                                        out_channels = 1104
                                        kernel_size = (5, 5)
                                        stride = (1, 1)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1104
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3CD70>
                                        scale = 0.0093186870217323303
                                        zero_point = 66
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6548.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6548.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6548.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6548.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1177 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6548.Conv2d,
                                                %1 : QUInt8(30, 1104, 3, 3, strides=[9936, 1, 3312, 1104], requires_grad=0, device=cpu)):
                                            %_packed_params.265 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1177)
                                            %15 : float = prim::Constant[value=0.0093186870217323303](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %x.45 : QUInt8(30, 1104, 3, 3, strides=[9936, 1, 3312, 1104], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.265, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%x.45)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6560.SEModule {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    avg_pool = <__torch__.torch.nn.modules.pooling.___torch_mangle_6550.AdaptiveAvgPool2d object at 0000018BEA8B7460>
                                    se = <__torch__.torch.nn.modules.container.___torch_mangle_6556.Sequential object at 0000018BEA8BEBE0>
                                    mul = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6559.TorchMultiply object at 0000018BEA8C0BE0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1179 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6560.SEModule,
                                            %1 : QUInt8(30, 1104, 3, 3, strides=[9936, 1, 3312, 1104], requires_grad=0, device=cpu)):
                                        %mul : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6559.TorchMultiply = prim::GetAttr[name="mul"](%self.1179)
                                        %se.81 : __torch__.torch.nn.modules.container.___torch_mangle_6556.Sequential = prim::GetAttr[name="se"](%self.1179)
                                        %avg_pool : __torch__.torch.nn.modules.pooling.___torch_mangle_6550.AdaptiveAvgPool2d = prim::GetAttr[name="avg_pool"](%self.1179)
                                        %32 : Tensor = prim::CallMethod[name="forward"](%avg_pool, %1)
                                        %33 : Tensor = prim::CallMethod[name="forward"](%se.81, %32)
                                        %34 : Tensor = prim::CallMethod[name="forward"](%mul, %1, %33)
                                        return (%34)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.pooling.___torch_mangle_6550.AdaptiveAvgPool2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1181 : __torch__.torch.nn.modules.pooling.___torch_mangle_6550.AdaptiveAvgPool2d,
                                                %1 : QUInt8(30, 1104, 3, 3, strides=[9936, 1, 3312, 1104], requires_grad=0, device=cpu)):
                                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.avg_pool
                                            %input.305 : QUInt8(30, 1104, 1, 1, strides=[1104, 1, 1104, 1104], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.avg_pool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                                            return (%input.305)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.container.___torch_mangle_6556.Sequential {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6553.ConvBNRelu object at 0000018BEA8BC560>
                                        1 = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6554.Conv2d object at 0000018BEA8BD060>
                                        2 = <__torch__.torch.nn.modules.activation.___torch_mangle_6555.Sigmoid object at 0000018BEA8BD260>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1183 : __torch__.torch.nn.modules.container.___torch_mangle_6556.Sequential,
                                                %1 : QUInt8(30, 1104, 1, 1, strides=[1104, 1, 1104, 1104], requires_grad=0, device=cpu)):
                                            %_2 : __torch__.torch.nn.modules.activation.___torch_mangle_6555.Sigmoid = prim::GetAttr[name="2"](%self.1183)
                                            %_1.45 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6554.Conv2d = prim::GetAttr[name="1"](%self.1183)
                                            %_0.57 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6553.ConvBNRelu = prim::GetAttr[name="0"](%self.1183)
                                            %8 : Tensor = prim::CallMethod[name="forward"](%_0.57, %1)
                                            %9 : Tensor = prim::CallMethod[name="forward"](%_1.45, %8)
                                            %10 : Tensor = prim::CallMethod[name="forward"](%_2, %9)
                                            return (%10)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6553.ConvBNRelu {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                            conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6551.ConvReLU2d object at 0000018BEA8B89E0>
                                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6552.Identity object at 0000018BEA8B9C60>
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1185 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6553.ConvBNRelu,
                                                    %1 : QUInt8(30, 1104, 1, 1, strides=[1104, 1, 1104, 1104], requires_grad=0, device=cpu)):
                                                %relu.101 : __torch__.torch.nn.modules.linear.___torch_mangle_6552.Identity = prim::GetAttr[name="relu"](%self.1185)
                                                %conv.223 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6551.ConvReLU2d = prim::GetAttr[name="conv"](%self.1185)
                                                %6 : Tensor = prim::CallMethod[name="forward"](%conv.223, %1)
                                                %7 : NoneType = prim::CallMethod[name="forward"](%relu.101)
                                                return (%6)
                                          
                                            }
                                          }
                                          submodules {
                                            module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6551.ConvReLU2d {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                                in_channels = 1104
                                                out_channels = 280
                                                kernel_size = (1, 1)
                                                stride = (1, 1)
                                                padding = (0, 0)
                                                dilation = (1, 1)
                                                transposed = False
                                                output_padding = (0, 0)
                                                groups = 1
                                                padding_mode = zeros
                                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3DD70>
                                                scale = 1.1920928955078125e-07
                                                zero_point = 0
                                              }
                                              methods {
                                                method __getstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6551.ConvReLU2d):
                                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                    %training : bool = prim::GetAttr[name="training"](%self)
                                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                    return (%19)
                                              
                                                }
                                                method __setstate__ {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6551.ConvReLU2d,
                                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                    %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                    %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                    %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                    %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                    %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                    %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                    %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                    %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                    %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                    %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                    %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                    %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                    %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                    %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                    %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                    %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                     = prim::SetAttr[name="stride"](%self, %13)
                                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                     = prim::SetAttr[name="padding"](%self, %16)
                                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                     = prim::SetAttr[name="dilation"](%self, %19)
                                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                                     = prim::SetAttr[name="transposed"](%self, %22)
                                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                                     = prim::SetAttr[name="groups"](%self, %28)
                                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                                     = prim::SetAttr[name="scale"](%self, %41)
                                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                                     = prim::SetAttr[name="training"](%self, %47)
                                                    return (%48)
                                              
                                                }
                                                method _weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6551.ConvReLU2d):
                                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                    return (%2)
                                              
                                                }
                                                method set_weight_bias {
                                                  graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6551.ConvReLU2d,
                                                        %w.1 : Tensor,
                                                        %b.1 : Tensor?):
                                                    %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                    %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                    %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                     = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                      block0():
                                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                                        -> ()
                                                      block1():
                                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                                        -> ()
                                                    return (%37)
                                              
                                                }
                                                method forward {
                                                  graph(%self.1187 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6551.ConvReLU2d,
                                                        %1 : QUInt8(30, 1104, 1, 1, strides=[1104, 1, 1104, 1104], requires_grad=0, device=cpu)):
                                                    %_packed_params.267 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1187)
                                                    %15 : float = prim::Constant[value=1.1920928955078125e-07](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    %input.307 : QUInt8(30, 280, 1, 1, strides=[280, 1, 280, 280], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.267, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se.0.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                    return (%input.307)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6552.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = False
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.1189 : __torch__.torch.nn.modules.linear.___torch_mangle_6552.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6554.Conv2d {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            in_channels = 280
                                            out_channels = 1104
                                            kernel_size = (1, 1)
                                            stride = (1, 1)
                                            padding = (0, 0)
                                            dilation = (1, 1)
                                            transposed = False
                                            output_padding = (0, 0)
                                            groups = 1
                                            padding_mode = zeros
                                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3D0F0>
                                            scale = 0.00016886177763808519
                                            zero_point = 17
                                          }
                                          methods {
                                            method __getstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6554.Conv2d):
                                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %scale : float = prim::GetAttr[name="scale"](%self)
                                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                                %training : bool = prim::GetAttr[name="training"](%self)
                                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                                return (%19)
                                          
                                            }
                                            method __setstate__ {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6554.Conv2d,
                                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                                %4 : int = prim::TupleIndex(%state.1, %3)
                                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                                %7 : int = prim::TupleIndex(%state.1, %6)
                                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                                 = prim::SetAttr[name="stride"](%self, %13)
                                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                                 = prim::SetAttr[name="padding"](%self, %16)
                                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                                 = prim::SetAttr[name="dilation"](%self, %19)
                                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                                 = prim::SetAttr[name="transposed"](%self, %22)
                                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                                %28 : int = prim::TupleIndex(%state.1, %27)
                                                 = prim::SetAttr[name="groups"](%self, %28)
                                                %31 : str = prim::TupleIndex(%state.1, %30)
                                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                                %41 : float = prim::TupleIndex(%state.1, %40)
                                                 = prim::SetAttr[name="scale"](%self, %41)
                                                %44 : int = prim::TupleIndex(%state.1, %43)
                                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                                 = prim::SetAttr[name="training"](%self, %47)
                                                return (%48)
                                          
                                            }
                                            method _weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6554.Conv2d):
                                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                                return (%2)
                                          
                                            }
                                            method set_weight_bias {
                                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6554.Conv2d,
                                                    %w.1 : Tensor,
                                                    %b.1 : Tensor?):
                                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                                  block0():
                                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                                    -> ()
                                                  block1():
                                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                                    -> ()
                                                return (%37)
                                          
                                            }
                                            method forward {
                                              graph(%self.1191 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6554.Conv2d,
                                                    %1 : QUInt8(30, 280, 1, 1, strides=[280, 1, 280, 280], requires_grad=0, device=cpu)):
                                                %_packed_params.269 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1191)
                                                %15 : float = prim::Constant[value=0.00016886177763808519](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %16 : int = prim::Constant[value=17](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                %input.309 : QUInt8(30, 1104, 1, 1, strides=[1104, 1, 1104, 1104], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.269, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                                return (%input.309)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                        module __torch__.torch.nn.modules.activation.___torch_mangle_6555.Sigmoid {
                                          parameters {
                                          }
                                          attributes {
                                            training = False
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1193 : __torch__.torch.nn.modules.activation.___torch_mangle_6555.Sigmoid,
                                                    %1 : QUInt8(30, 1104, 1, 1, strides=[1104, 1, 1104, 1104], requires_grad=0, device=cpu)):
                                                %2 : QUInt8(30, 1104, 1, 1, strides=[1104, 1, 1104, 1104], requires_grad=0, device=cpu) = aten::sigmoid(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.se.2 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\modules\activation.py:294:0
                                                return (%2)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                    module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6559.TorchMultiply {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                        mul_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6558.QFunctional object at 0000018BEA8C1AE0>
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1195 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6559.TorchMultiply,
                                                %1 : QUInt8(30, 1104, 3, 3, strides=[9936, 1, 3312, 1104], requires_grad=0, device=cpu),
                                                %2 : QUInt8(30, 1104, 1, 1, strides=[1104, 1, 1104, 1104], requires_grad=0, device=cpu)):
                                            %mul_func : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6558.QFunctional = prim::GetAttr[name="mul_func"](%self.1195)
                                            %activation_post_process.91 : __torch__.torch.nn.modules.linear.___torch_mangle_6557.Identity = prim::GetAttr[name="activation_post_process"](%mul_func)
                                            %5 : float = prim::Constant[value=0.0050564962439239025](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %6 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.311 : QUInt8(30, 1104, 3, 3, strides=[9936, 1, 3312, 1104], requires_grad=0, device=cpu) = quantized::mul(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.se.mul # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.91)
                                            return (%input.311)
                                      
                                        }
                                      }
                                      submodules {
                                        module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6558.QFunctional {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                            activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6557.Identity object at 0000018BEA8C1D60>
                                          }
                                          methods {
                                          }
                                          submodules {
                                            module __torch__.torch.nn.modules.linear.___torch_mangle_6557.Identity {
                                              parameters {
                                              }
                                              attributes {
                                                training = True
                                                _is_full_backward_hook = None
                                              }
                                              methods {
                                                method forward {
                                                  graph(%self.1197 : __torch__.torch.nn.modules.linear.___torch_mangle_6557.Identity):
                                                    %1 : NoneType = prim::Constant()
                                                    return (%1)
                                              
                                                }
                                              }
                                              submodules {
                                              }
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6563.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6561.Conv2d object at 0000018BEA8C3BE0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6562.Identity object at 0000018BEA8C3EE0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1199 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6563.ConvBNRelu,
                                            %1 : QUInt8(30, 1104, 3, 3, strides=[9936, 1, 3312, 1104], requires_grad=0, device=cpu)):
                                        %bn.121 : __torch__.torch.nn.modules.linear.___torch_mangle_6562.Identity = prim::GetAttr[name="bn"](%self.1199)
                                        %conv.225 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6561.Conv2d = prim::GetAttr[name="conv"](%self.1199)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.225, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.121)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6561.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 1104
                                        out_channels = 200
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3CF70>
                                        scale = 0.27006351947784424
                                        zero_point = 62
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6561.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6561.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6561.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6561.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1201 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6561.Conv2d,
                                                %1 : QUInt8(30, 1104, 3, 3, strides=[9936, 1, 3312, 1104], requires_grad=0, device=cpu)):
                                            %_packed_params.271 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1201)
                                            %15 : float = prim::Constant[value=0.27006351947784424](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %x.47 : QUInt8(30, 200, 3, 3, strides=[1800, 1, 600, 200], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.271, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_5.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%x.47)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6562.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1203 : __torch__.torch.nn.modules.linear.___torch_mangle_6562.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.pooling.___torch_mangle_6567.AdaptiveAvgPool2d {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self.1205 : __torch__.torch.nn.modules.pooling.___torch_mangle_6567.AdaptiveAvgPool2d,
                                %1 : QUInt8(30, 200, 3, 3, strides=[1800, 1, 600, 200], requires_grad=0, device=cpu)):
                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.avgpool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.avgpool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.avgpool
                            %Xq.7 : QUInt8(30, 200, 1, 1, strides=[200, 1, 200, 200], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.avgpool # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:1214:0
                            return (%Xq.7)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6570.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_6569.ModuleList object at 0000018BEA8C4660>
                      }
                      methods {
                        method forward {
                          graph(%self.941 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6570.QuantStubNested,
                                %1 : Float(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                            %stubs.17 : __torch__.torch.nn.modules.container.___torch_mangle_6569.ModuleList = prim::GetAttr[name="stubs"](%self.941)
                            %_0.45 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6568.Quantize = prim::GetAttr[name="0"](%stubs.17)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.45, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_6569.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6568.Quantize object at 0000018BEA8C5560>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6568.Quantize {
                              parameters {
                              }
                              attributes {
                                scale = ...
                                zero_point = ...
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.943 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6568.Quantize,
                                        %1 : Float(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                                    %2 : float = prim::Constant[value=0.073521420359611511](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.quant_stubs/__module.model.model.roi_heads.box_head.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    %3 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.quant_stubs/__module.model.model.roi_heads.box_head.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.quant_stubs/__module.model.model.roi_heads.box_head.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    %input.241 : QUInt8(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%1, %2, %3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.quant_stubs/__module.model.model.roi_heads.box_head.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    return (%input.241)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6573.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_6572.ModuleList object at 0000018BEA8C6EE0>
                      }
                      methods {
                        method forward {
                          graph(%self.1207 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6573.QuantStubNested,
                                %1 : QUInt8(30, 200, 1, 1, strides=[200, 1, 200, 200], requires_grad=0, device=cpu)):
                            %stubs.19 : __torch__.torch.nn.modules.container.___torch_mangle_6572.ModuleList = prim::GetAttr[name="stubs"](%self.1207)
                            %_0.61 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6571.DeQuantize = prim::GetAttr[name="0"](%stubs.19)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.61, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_6572.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6571.DeQuantize object at 0000018BEA8C6BE0>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6571.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.1209 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6571.DeQuantize,
                                        %1 : QUInt8(30, 200, 1, 1, strides=[200, 1, 200, 200], requires_grad=0, device=cpu)):
                                    %X.5 : Float(30, 200, 1, 1, strides=[200, 1, 200, 200], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.dequant_stubs/__module.model.model.roi_heads.box_head.dequant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:96:0
                                    return (%X.5)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6586.QuantWrapSubClass {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    cls_score = <__torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6576.Linear object at 0000018BEA8C7A60>
                    bbox_pred = <__torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6578.Linear object at 0000018BEA8C68E0>
                    quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6581.QuantStubNested object at 0000018BEA8C9560>
                    dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6585.QuantStubNested object at 0000018BEA8C8360>
                  }
                  methods {
                    method forward {
                      graph(%self.1211 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6586.QuantWrapSubClass,
                            %1 : Float(30, 200, 1, 1, strides=[200, 1, 200, 200], requires_grad=0, device=cpu)):
                        %dequant_stubs.7 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6585.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.1211)
                        %bbox_pred : __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6578.Linear = prim::GetAttr[name="bbox_pred"](%self.1211)
                        %cls_score : __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6576.Linear = prim::GetAttr[name="cls_score"](%self.1211)
                        %quant_stubs.7 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6581.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.1211)
                        %16 : Tensor = prim::CallMethod[name="forward"](%quant_stubs.7, %1)
                        %7 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:302:0
                        %8 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:302:0
                        %9 : QUInt8(30, 200, strides=[200, 1], requires_grad=0, device=cpu) = aten::flatten(%16, %7, %8), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:302:0
                        %17 : Tensor = prim::CallMethod[name="forward"](%cls_score, %9)
                        %18 : Tensor = prim::CallMethod[name="forward"](%bbox_pred, %9)
                        %19 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%dequant_stubs.7, %17, %18)
                        %13 : Float(30, 72, strides=[72, 1], requires_grad=0, device=cpu), %14 : Float(30, 19, strides=[19, 1], requires_grad=0, device=cpu) = prim::TupleUnpack(%19)
                        %15 : (Float(30, 72, strides=[72, 1], requires_grad=0, device=cpu), Float(30, 19, strides=[19, 1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%13, %14)
                        return (%15)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6576.Linear {
                      parameters {
                      }
                      attributes {
                        training = True
                        _is_full_backward_hook = None
                        _packed_params = <__torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6575.LinearPackedParams object at 0000018BEA8C7B60>
                      }
                      methods {
                        method forward {
                          graph(%self.1217 : __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6576.Linear,
                                %1 : QUInt8(30, 200, strides=[200, 1], requires_grad=0, device=cpu)):
                            %_packed_params.273 : __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6575.LinearPackedParams = prim::GetAttr[name="_packed_params"](%self.1217)
                            %_packed_params.275 : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%_packed_params.273)
                            %4 : float = prim::Constant[value=0.11318807303905487](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.cls_score # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                            %5 : int = prim::Constant[value=28](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.cls_score # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                            %Xq.9 : QUInt8(30, 19, strides=[19, 1], requires_grad=0, device=cpu) = quantized::linear(%1, %_packed_params.275, %4, %5), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.cls_score # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                            return (%Xq.9)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6575.LinearPackedParams {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            dtype = 12
                            _packed_params = <__torch__.torch.classes.quantized.LinearPackedParamsBase object at 0000018BE6D3ECF0>
                          }
                          methods {
                            method _weight_bias {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6575.LinearPackedParams):
                                %18 : str = prim::Constant[value="builtins.RuntimeError"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:46:18
                                %17 : str = prim::Constant[value="Unsupported dtype on dynamic quantized linear!"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:46:31
                                %10 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:43:27
                                %2 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:41:25
                                %28 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::Uninitialized()
                                %dtype.1 : int = prim::GetAttr[name="dtype"](%self)
                                %3 : bool = aten::eq(%dtype.1, %2) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:41:11
                                %30 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::If(%3) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:41:8
                                  block0():
                                    %_packed_params.1 : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                    %6 : Tensor, %7 : Tensor? = quantized::linear_unpack(%_packed_params.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:42:19
                                    %8 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::TupleConstruct(%6, %7)
                                    -> (%8)
                                  block1():
                                    %dtype : int = prim::GetAttr[name="dtype"](%self)
                                    %11 : bool = aten::eq(%dtype, %10) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:43:13
                                    %29 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::If(%11) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:43:8
                                      block0():
                                        %_packed_params : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %14 : Tensor, %15 : Tensor? = quantized::linear_unpack_fp16(%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:44:19
                                        %16 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::TupleConstruct(%14, %15)
                                        -> (%16)
                                      block1():
                                         = prim::RaiseException(%17, %18) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:46:12
                                        -> (%28)
                                    -> (%29)
                                return (%30)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6575.LinearPackedParams,
                                    %weight.1 : Tensor,
                                    %bias.1 : Tensor?):
                                %20 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:30:24
                                %18 : str = prim::Constant[value="builtins.RuntimeError"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:36:18
                                %17 : str = prim::Constant[value="Unsupported dtype on dynamic quantized linear!"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:36:31
                                %11 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:33:27
                                %4 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:31:25
                                %dtype.1 : int = prim::GetAttr[name="dtype"](%self)
                                %5 : bool = aten::eq(%dtype.1, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:31:11
                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:31:8
                                  block0():
                                    %9 : __torch__.torch.classes.quantized.LinearPackedParamsBase = quantized::linear_prepack(%weight.1, %bias.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:32:34
                                     = prim::SetAttr[name="_packed_params"](%self, %9)
                                    -> ()
                                  block1():
                                    %dtype : int = prim::GetAttr[name="dtype"](%self)
                                    %12 : bool = aten::eq(%dtype, %11) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:33:13
                                     = prim::If(%12) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:33:8
                                      block0():
                                        %16 : __torch__.torch.classes.quantized.LinearPackedParamsBase = quantized::linear_prepack_fp16(%weight.1, %bias.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:34:34
                                         = prim::SetAttr[name="_packed_params"](%self, %16)
                                        -> ()
                                      block1():
                                         = prim::RaiseException(%17, %18) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:36:12
                                        -> ()
                                    -> ()
                                return (%20)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                    module __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6578.Linear {
                      parameters {
                      }
                      attributes {
                        training = True
                        _is_full_backward_hook = None
                        _packed_params = <__torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6577.LinearPackedParams object at 0000018BEA8C72E0>
                      }
                      methods {
                        method forward {
                          graph(%self.1219 : __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6578.Linear,
                                %1 : QUInt8(30, 200, strides=[200, 1], requires_grad=0, device=cpu)):
                            %_packed_params.277 : __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6577.LinearPackedParams = prim::GetAttr[name="_packed_params"](%self.1219)
                            %_packed_params.279 : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%_packed_params.277)
                            %4 : float = prim::Constant[value=0.060246266424655914](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.bbox_pred # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                            %5 : int = prim::Constant[value=69](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.bbox_pred # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                            %Xq.11 : QUInt8(30, 72, strides=[72, 1], requires_grad=0, device=cpu) = quantized::linear(%1, %_packed_params.279, %4, %5), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.bbox_pred # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                            return (%Xq.11)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6577.LinearPackedParams {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            dtype = 12
                            _packed_params = <__torch__.torch.classes.quantized.LinearPackedParamsBase object at 0000018BE6D3FFF0>
                          }
                          methods {
                            method _weight_bias {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6577.LinearPackedParams):
                                %18 : str = prim::Constant[value="builtins.RuntimeError"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:46:18
                                %17 : str = prim::Constant[value="Unsupported dtype on dynamic quantized linear!"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:46:31
                                %10 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:43:27
                                %2 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:41:25
                                %28 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::Uninitialized()
                                %dtype.1 : int = prim::GetAttr[name="dtype"](%self)
                                %3 : bool = aten::eq(%dtype.1, %2) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:41:11
                                %30 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::If(%3) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:41:8
                                  block0():
                                    %_packed_params.1 : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                    %6 : Tensor, %7 : Tensor? = quantized::linear_unpack(%_packed_params.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:42:19
                                    %8 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::TupleConstruct(%6, %7)
                                    -> (%8)
                                  block1():
                                    %dtype : int = prim::GetAttr[name="dtype"](%self)
                                    %11 : bool = aten::eq(%dtype, %10) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:43:13
                                    %29 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::If(%11) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:43:8
                                      block0():
                                        %_packed_params : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %14 : Tensor, %15 : Tensor? = quantized::linear_unpack_fp16(%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:44:19
                                        %16 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::TupleConstruct(%14, %15)
                                        -> (%16)
                                      block1():
                                         = prim::RaiseException(%17, %18) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:46:12
                                        -> (%28)
                                    -> (%29)
                                return (%30)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.linear.___torch_mangle_6577.LinearPackedParams,
                                    %weight.1 : Tensor,
                                    %bias.1 : Tensor?):
                                %20 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:30:24
                                %18 : str = prim::Constant[value="builtins.RuntimeError"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:36:18
                                %17 : str = prim::Constant[value="Unsupported dtype on dynamic quantized linear!"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:36:31
                                %11 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:33:27
                                %4 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:31:25
                                %dtype.1 : int = prim::GetAttr[name="dtype"](%self)
                                %5 : bool = aten::eq(%dtype.1, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:31:11
                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:31:8
                                  block0():
                                    %9 : __torch__.torch.classes.quantized.LinearPackedParamsBase = quantized::linear_prepack(%weight.1, %bias.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:32:34
                                     = prim::SetAttr[name="_packed_params"](%self, %9)
                                    -> ()
                                  block1():
                                    %dtype : int = prim::GetAttr[name="dtype"](%self)
                                    %12 : bool = aten::eq(%dtype, %11) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:33:13
                                     = prim::If(%12) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:33:8
                                      block0():
                                        %16 : __torch__.torch.classes.quantized.LinearPackedParamsBase = quantized::linear_prepack_fp16(%weight.1, %bias.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:34:34
                                         = prim::SetAttr[name="_packed_params"](%self, %16)
                                        -> ()
                                      block1():
                                         = prim::RaiseException(%17, %18) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\linear.py:36:12
                                        -> ()
                                    -> ()
                                return (%20)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6581.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_6580.ModuleList object at 0000018BEA8C9FE0>
                      }
                      methods {
                        method forward {
                          graph(%self.1213 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6581.QuantStubNested,
                                %1 : Float(30, 200, 1, 1, strides=[200, 1, 200, 200], requires_grad=0, device=cpu)):
                            %stubs.21 : __torch__.torch.nn.modules.container.___torch_mangle_6580.ModuleList = prim::GetAttr[name="stubs"](%self.1213)
                            %_0.63 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6579.Quantize = prim::GetAttr[name="0"](%stubs.21)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.63, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_6580.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6579.Quantize object at 0000018BEA8C8160>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6579.Quantize {
                              parameters {
                              }
                              attributes {
                                scale = ...
                                zero_point = ...
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.1215 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6579.Quantize,
                                        %1 : Float(30, 200, 1, 1, strides=[200, 1, 200, 200], requires_grad=0, device=cpu)):
                                    %2 : float = prim::Constant[value=0.23095256090164185](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.quant_stubs/__module.model.model.roi_heads.box_predictor.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    %3 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.quant_stubs/__module.model.model.roi_heads.box_predictor.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.quant_stubs/__module.model.model.roi_heads.box_predictor.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    %x : QUInt8(30, 200, 1, 1, strides=[200, 1, 200, 200], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%1, %2, %3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.quant_stubs/__module.model.model.roi_heads.box_predictor.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    return (%x)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6585.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_6584.ModuleList object at 0000018BEA8C96E0>
                      }
                      methods {
                        method forward {
                          graph(%self.1221 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6585.QuantStubNested,
                                %1 : QUInt8(30, 19, strides=[19, 1], requires_grad=0, device=cpu),
                                %2 : QUInt8(30, 72, strides=[72, 1], requires_grad=0, device=cpu)):
                            %stubs.25 : __torch__.torch.nn.modules.container.___torch_mangle_6584.ModuleList = prim::GetAttr[name="stubs"](%self.1221)
                            %_1 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6583.DeQuantize = prim::GetAttr[name="1"](%stubs.25)
                            %stubs.23 : __torch__.torch.nn.modules.container.___torch_mangle_6584.ModuleList = prim::GetAttr[name="stubs"](%self.1221)
                            %_0.65 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6582.DeQuantize = prim::GetAttr[name="0"](%stubs.23)
                            %10 : Tensor = prim::CallMethod[name="forward"](%_0.65, %1)
                            %11 : Tensor = prim::CallMethod[name="forward"](%_1, %2)
                            %9 : (Float(30, 72, strides=[72, 1], requires_grad=0, device=cpu), Float(30, 19, strides=[19, 1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%11, %10)
                            return (%9)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_6584.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6582.DeQuantize object at 0000018BEA8C95E0>
                            1 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6583.DeQuantize object at 0000018BEA8C8260>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6582.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.1223 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6582.DeQuantize,
                                        %1 : QUInt8(30, 19, strides=[19, 1], requires_grad=0, device=cpu)):
                                    %input.313 : Float(30, 19, strides=[19, 1], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.dequant_stubs/__module.model.model.roi_heads.box_predictor.dequant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:96:0
                                    return (%input.313)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6583.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.1225 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6583.DeQuantize,
                                        %1 : QUInt8(30, 72, strides=[72, 1], requires_grad=0, device=cpu)):
                                    %deltas.5 : Float(30, 72, strides=[72, 1], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.dequant_stubs/__module.model.model.roi_heads.box_predictor.dequant_stubs.stubs.1 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:96:0
                                    return (%deltas.5)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.detectron2.modeling.poolers.___torch_mangle_6589.ROIPooler {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    level_poolers = <__torch__.torch.nn.modules.container.___torch_mangle_6588.ModuleList object at 0000018BEA8C84E0>
                  }
                  methods {
                    method forward {
                      graph(%self.1227 : __torch__.detectron2.modeling.poolers.___torch_mangle_6589.ROIPooler,
                            %1 : Float(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu),
                            %tensor : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu)):
                        %level_poolers : __torch__.torch.nn.modules.container.___torch_mangle_6588.ModuleList = prim::GetAttr[name="level_poolers"](%self.1227)
                        %_0.67 : __torch__.detectron2.layers.roi_align.___torch_mangle_6587.ROIAlign = prim::GetAttr[name="0"](%level_poolers)
                        %27 : Tensor[] = prim::ListConstruct(%tensor), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler
                        %28 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\poolers.py:95:0
                        %29 : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::cat(%27, %28), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\poolers.py:95:0
                        %30 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %31 : int = aten::size(%tensor, %30), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %32 : Long(device=cpu) = prim::NumToTensor(%31), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler
                        %36 : Tensor[] = prim::ListConstruct(%32), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler
                        %37 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\wrappers.py:32:0
                        %38 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::stack(%36, %37), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\wrappers.py:32:0
                        %39 : Function = prim::Constant[name="_convert_boxes_to_pooler_format"](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler
                        %rois : Tensor = prim::CallFunction(%39, %29, %38), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler
                        %42 : Tensor = prim::CallMethod[name="forward"](%_0.67, %rois, %1)
                        return (%42)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.___torch_mangle_6588.ModuleList {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.layers.roi_align.___torch_mangle_6587.ROIAlign object at 0000018BEA8C9A60>
                      }
                      methods {
                      }
                      submodules {
                        module __torch__.detectron2.layers.roi_align.___torch_mangle_6587.ROIAlign {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.1229 : __torch__.detectron2.layers.roi_align.___torch_mangle_6587.ROIAlign,
                                    %rois : Tensor,
                                    %2 : Float(1, 112, 14, 19, strides=[29792, 1, 2128, 112], requires_grad=0, device=cpu)):
                                %8 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler/__module.model.model.roi_heads.mask_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %9 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler/__module.model.model.roi_heads.mask_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %10 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler/__module.model.model.roi_heads.mask_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %11 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler/__module.model.model.roi_heads.mask_pooler.level_poolers.0
                                %boxes : Float(1, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::to(%rois, %8, %9, %10, %11), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler/__module.model.model.roi_heads.mask_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %18 : float = prim::Constant[value=0.0625](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler/__module.model.model.roi_heads.mask_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %19 : int = prim::Constant[value=14](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler/__module.model.model.roi_heads.mask_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %20 : int = prim::Constant[value=14](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler/__module.model.model.roi_heads.mask_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %21 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler/__module.model.model.roi_heads.mask_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %22 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler/__module.model.model.roi_heads.mask_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %X : Float(1, 112, 14, 14, strides=[21952, 196, 14, 1], requires_grad=0, device=cpu) = torchvision::roi_align(%2, %boxes, %18, %19, %20, %21, %22), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_pooler/__module.model.model.roi_heads.mask_pooler.level_poolers.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                return (%X)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6658.QuantWrapSubClass {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    feature_extractor = <__torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6649.FBNetModule object at 0000018BE9FE5D70>
                    predictor = <__torch__.d2go.modeling.backbone.modules.___torch_mangle_6651.MaskRCNNConv1x1Predictor object at 0000018BE9FE7C70>
                    quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6654.QuantStubNested object at 0000018BE9FE77F0>
                    dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6657.QuantStubNested object at 0000018BE9FE97F0>
                  }
                  methods {
                    method forward {
                      graph(%self.1231 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6658.QuantWrapSubClass,
                            %1 : Float(1, 112, 14, 14, strides=[21952, 196, 14, 1], requires_grad=0, device=cpu),
                            %class_pred : Long(1, strides=[2], requires_grad=0, device=cpu),
                            %tensor : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu)):
                        %dequant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6657.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.1231)
                        %predictor : __torch__.d2go.modeling.backbone.modules.___torch_mangle_6651.MaskRCNNConv1x1Predictor = prim::GetAttr[name="predictor"](%self.1231)
                        %feature_extractor : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6649.FBNetModule = prim::GetAttr[name="feature_extractor"](%self.1231)
                        %quant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6654.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.1231)
                        %76 : Tensor = prim::CallMethod[name="forward"](%quant_stubs, %1)
                        %77 : Tensor = prim::CallMethod[name="forward"](%feature_extractor, %76)
                        %78 : Tensor = prim::CallMethod[name="forward"](%predictor, %77)
                        %79 : Tensor = prim::CallMethod[name="forward"](%dequant_stubs, %78)
                        %17 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:143:0
                        %18 : int = aten::size(%79, %17), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:143:0
                        %num_masks : Long(device=cpu) = prim::NumToTensor(%18), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head
                        %20 : Scalar = aten::ScalarImplicit(%num_masks), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head
                        %30 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head
                        %31 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head
                        %32 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:150:0
                        %33 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:150:0
                        %34 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::arange(%20, %30, %31, %32, %33), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:150:0
                        %35 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head
                        %indices : Tensor = prim::CallFunction(%35, %34, %class_pred), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head
                        %37 : Tensor?[] = prim::ListConstruct(%indices, %class_pred), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head
                        %38 : Float(1, 28, 28, strides=[784, 28, 1], requires_grad=0, device=cpu) = aten::index(%79, %37), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:151:0
                        %39 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:151:0
                        %40 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:151:0
                        %41 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:151:0
                        %42 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:151:0
                        %43 : Float(1, 28, 28, strides=[784, 28, 1], requires_grad=0, device=cpu) = aten::slice(%38, %39, %40, %41, %42), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:151:0
                        %44 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:151:0
                        %45 : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%43, %44), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:151:0
                        %46 : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu) = aten::sigmoid(%45), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\modeling\roi_heads\mask_head.py:151:0
                        %47 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %48 : int = aten::size(%tensor, %47), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %49 : Long(device=cpu) = prim::NumToTensor(%48), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head
                        %50 : int = aten::Int(%49), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head
                        %54 : int[] = prim::ListConstruct(%50), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head
                        %55 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_tensor.py:789:0
                        %56 : Tensor[] = aten::split_with_sizes(%46, %54, %55), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_tensor.py:789:0
                        %57 : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%56), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head
                        return (%57)
                  
                    }
                  }
                  submodules {
                    module __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6649.FBNetModule {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.nn.modules.container.___torch_mangle_6648.Sequential object at 0000018BE9FE58F0>
                      }
                      methods {
                        method forward {
                          graph(%self.1237 : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_6649.FBNetModule,
                                %1 : QUInt8(1, 112, 14, 14, strides=[21952, 196, 14, 1], requires_grad=0, device=cpu)):
                            %_0.71 : __torch__.torch.nn.modules.container.___torch_mangle_6648.Sequential = prim::GetAttr[name="0"](%self.1237)
                            %4 : Tensor = prim::CallMethod[name="forward"](%_0.71, %1)
                            return (%4)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_6648.Sequential {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            fbnetv2_0_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6599.IRFBlock object at 0000018BEA8D2C60>
                            fbnetv2_0_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6612.IRFBlock object at 0000018BE9FC69F0>
                            fbnetv2_0_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6625.IRFBlock object at 0000018BE9FD12F0>
                            fbnetv2_0_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6636.IRFBlock object at 0000018BE9FDA1F0>
                            fbnetv2_0_4 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6647.IRFBlock object at 0000018BE9FE3970>
                          }
                          methods {
                            method forward {
                              graph(%self.1239 : __torch__.torch.nn.modules.container.___torch_mangle_6648.Sequential,
                                    %1 : QUInt8(1, 112, 14, 14, strides=[21952, 196, 14, 1], requires_grad=0, device=cpu)):
                                %fbnetv2_0_4 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6647.IRFBlock = prim::GetAttr[name="fbnetv2_0_4"](%self.1239)
                                %fbnetv2_0_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6636.IRFBlock = prim::GetAttr[name="fbnetv2_0_3"](%self.1239)
                                %fbnetv2_0_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6625.IRFBlock = prim::GetAttr[name="fbnetv2_0_2"](%self.1239)
                                %fbnetv2_0_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6612.IRFBlock = prim::GetAttr[name="fbnetv2_0_1"](%self.1239)
                                %fbnetv2_0_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6599.IRFBlock = prim::GetAttr[name="fbnetv2_0_0"](%self.1239)
                                %12 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_0, %1)
                                %13 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_1, %12)
                                %14 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_2, %13)
                                %15 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_3, %14)
                                %16 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_4, %15)
                                return (%16)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6599.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6593.ConvBNRelu object at 0000018BEA8CB960>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6595.ConvBNRelu object at 0000018BEA8CD360>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6598.ConvBNRelu object at 0000018BEA8CF6E0>
                              }
                              methods {
                                method forward {
                                  graph(%self.1241 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6599.IRFBlock,
                                        %1 : QUInt8(1, 112, 14, 14, strides=[21952, 196, 14, 1], requires_grad=0, device=cpu)):
                                    %pwl.63 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6598.ConvBNRelu = prim::GetAttr[name="pwl"](%self.1241)
                                    %dw.71 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6595.ConvBNRelu = prim::GetAttr[name="dw"](%self.1241)
                                    %pw.59 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6593.ConvBNRelu = prim::GetAttr[name="pw"](%self.1241)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%pw.59, %1)
                                    %9 : Tensor = prim::CallMethod[name="forward"](%dw.71, %8)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pwl.63, %9)
                                    return (%10)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6593.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6590.ConvReLU2d object at 0000018BEA8C88E0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6591.Identity object at 0000018BEA8CA1E0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6592.Identity object at 0000018BEA8CA360>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1243 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6593.ConvBNRelu,
                                            %1 : QUInt8(1, 112, 14, 14, strides=[21952, 196, 14, 1], requires_grad=0, device=cpu)):
                                        %relu.103 : __torch__.torch.nn.modules.linear.___torch_mangle_6592.Identity = prim::GetAttr[name="relu"](%self.1243)
                                        %bn.123 : __torch__.torch.nn.modules.linear.___torch_mangle_6591.Identity = prim::GetAttr[name="bn"](%self.1243)
                                        %conv.227 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6590.ConvReLU2d = prim::GetAttr[name="conv"](%self.1243)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.227, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.123)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.103)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6590.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 112
                                        out_channels = 448
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3F4F0>
                                        scale = 0.06510905921459198
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6590.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6590.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6590.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6590.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1245 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6590.ConvReLU2d,
                                                %1 : QUInt8(1, 112, 14, 14, strides=[21952, 196, 14, 1], requires_grad=0, device=cpu)):
                                            %_packed_params.281 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1245)
                                            %15 : float = prim::Constant[value=0.06510905921459198](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.317 : QUInt8(1, 448, 14, 14, strides=[87808, 1, 6272, 448], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.281, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.317)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6591.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1247 : __torch__.torch.nn.modules.linear.___torch_mangle_6591.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6592.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1249 : __torch__.torch.nn.modules.linear.___torch_mangle_6592.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6595.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6594.Conv2d object at 0000018BEA8CA6E0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1251 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6595.ConvBNRelu,
                                            %1 : QUInt8(1, 448, 14, 14, strides=[87808, 1, 6272, 448], requires_grad=0, device=cpu)):
                                        %conv.229 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6594.Conv2d = prim::GetAttr[name="conv"](%self.1251)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.229, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6594.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 448
                                        out_channels = 448
                                        kernel_size = (3, 3)
                                        stride = (2, 2)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 448
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3EAF0>
                                        scale = 0.012689515016973019
                                        zero_point = 56
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6594.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6594.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6594.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6594.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1253 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6594.Conv2d,
                                                %1 : QUInt8(1, 448, 14, 14, strides=[87808, 1, 6272, 448], requires_grad=0, device=cpu)):
                                            %_packed_params.283 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1253)
                                            %15 : float = prim::Constant[value=0.012689515016973019](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=56](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.319 : QUInt8(1, 448, 7, 7, strides=[21952, 1, 3136, 448], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.283, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.319)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6598.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6596.Conv2d object at 0000018BEA8CF460>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6597.Identity object at 0000018BEA8CE160>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1255 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6598.ConvBNRelu,
                                            %1 : QUInt8(1, 448, 7, 7, strides=[21952, 1, 3136, 448], requires_grad=0, device=cpu)):
                                        %bn.125 : __torch__.torch.nn.modules.linear.___torch_mangle_6597.Identity = prim::GetAttr[name="bn"](%self.1255)
                                        %conv.231 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6596.Conv2d = prim::GetAttr[name="conv"](%self.1255)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.231, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.125)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6596.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 448
                                        out_channels = 128
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3F7F0>
                                        scale = 0.10345242917537689
                                        zero_point = 65
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6596.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6596.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6596.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6596.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1257 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6596.Conv2d,
                                                %1 : QUInt8(1, 448, 7, 7, strides=[21952, 1, 3136, 448], requires_grad=0, device=cpu)):
                                            %_packed_params.285 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1257)
                                            %15 : float = prim::Constant[value=0.10345242917537689](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.321 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.285, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_0.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.321)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6597.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1259 : __torch__.torch.nn.modules.linear.___torch_mangle_6597.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6612.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6603.ConvBNRelu object at 0000018BE9FC2EF0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6605.ConvBNRelu object at 0000018BE9FC2B70>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6608.ConvBNRelu object at 0000018BE9FC4370>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6611.TorchAdd object at 0000018BE9FC51F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.1261 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6612.IRFBlock,
                                        %1 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu)):
                                    %res_conn.51 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6611.TorchAdd = prim::GetAttr[name="res_conn"](%self.1261)
                                    %pwl.65 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6608.ConvBNRelu = prim::GetAttr[name="pwl"](%self.1261)
                                    %dw.73 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6605.ConvBNRelu = prim::GetAttr[name="dw"](%self.1261)
                                    %pw.61 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6603.ConvBNRelu = prim::GetAttr[name="pw"](%self.1261)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.61, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.73, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.65, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.51, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6603.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6600.ConvReLU2d object at 0000018BEA8D32E0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6601.Identity object at 0000018BE9FC2A70>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6602.Identity object at 0000018BE9FC13F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1263 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6603.ConvBNRelu,
                                            %1 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu)):
                                        %relu.105 : __torch__.torch.nn.modules.linear.___torch_mangle_6602.Identity = prim::GetAttr[name="relu"](%self.1263)
                                        %bn.127 : __torch__.torch.nn.modules.linear.___torch_mangle_6601.Identity = prim::GetAttr[name="bn"](%self.1263)
                                        %conv.233 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6600.ConvReLU2d = prim::GetAttr[name="conv"](%self.1263)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.233, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.127)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.105)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6600.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 128
                                        out_channels = 768
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3F170>
                                        scale = 0.050910450518131256
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6600.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6600.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6600.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6600.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1265 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6600.ConvReLU2d,
                                                %1 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu)):
                                            %_packed_params.287 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1265)
                                            %15 : float = prim::Constant[value=0.050910450518131256](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.323 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.287, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.323)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6601.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1267 : __torch__.torch.nn.modules.linear.___torch_mangle_6601.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6602.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1269 : __torch__.torch.nn.modules.linear.___torch_mangle_6602.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6605.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6604.Conv2d object at 0000018BE9FC1170>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1271 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6605.ConvBNRelu,
                                            %1 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu)):
                                        %conv.235 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6604.Conv2d = prim::GetAttr[name="conv"](%self.1271)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.235, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6604.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 768
                                        out_channels = 768
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 768
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3E770>
                                        scale = 0.008350214920938015
                                        zero_point = 66
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6604.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6604.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6604.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6604.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1273 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6604.Conv2d,
                                                %1 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu)):
                                            %_packed_params.289 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1273)
                                            %15 : float = prim::Constant[value=0.008350214920938015](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.325 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.289, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.325)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6608.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6606.Conv2d object at 0000018BE9FC1770>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6607.Identity object at 0000018BE9FC21F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1275 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6608.ConvBNRelu,
                                            %1 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu)):
                                        %bn.129 : __torch__.torch.nn.modules.linear.___torch_mangle_6607.Identity = prim::GetAttr[name="bn"](%self.1275)
                                        %conv.237 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6606.Conv2d = prim::GetAttr[name="conv"](%self.1275)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.237, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.129)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6606.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 768
                                        out_channels = 128
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3FC70>
                                        scale = 0.10633838921785355
                                        zero_point = 74
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6606.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6606.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6606.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6606.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1277 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6606.Conv2d,
                                                %1 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu)):
                                            %_packed_params.291 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1277)
                                            %15 : float = prim::Constant[value=0.10633838921785355](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=74](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %17 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.291, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6607.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1279 : __torch__.torch.nn.modules.linear.___torch_mangle_6607.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6611.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6610.QFunctional object at 0000018BE9FC6570>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1281 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6611.TorchAdd,
                                            %1 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu)):
                                        %add_func.51 : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6610.QFunctional = prim::GetAttr[name="add_func"](%self.1281)
                                        %activation_post_process.93 : __torch__.torch.nn.modules.linear.___torch_mangle_6609.Identity = prim::GetAttr[name="activation_post_process"](%add_func.51)
                                        %5 : float = prim::Constant[value=0.12656402587890625](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=67](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.327 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_1.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.93)
                                        return (%input.327)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6610.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6609.Identity object at 0000018BE9FC6AF0>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6609.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1283 : __torch__.torch.nn.modules.linear.___torch_mangle_6609.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6625.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6616.ConvBNRelu object at 0000018BE9FC9B70>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6618.ConvBNRelu object at 0000018BE9FCAFF0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6621.ConvBNRelu object at 0000018BE9FCE670>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6624.TorchAdd object at 0000018BE9FCF7F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.1285 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6625.IRFBlock,
                                        %1 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu)):
                                    %res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6624.TorchAdd = prim::GetAttr[name="res_conn"](%self.1285)
                                    %pwl.67 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6621.ConvBNRelu = prim::GetAttr[name="pwl"](%self.1285)
                                    %dw.75 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6618.ConvBNRelu = prim::GetAttr[name="dw"](%self.1285)
                                    %pw.63 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6616.ConvBNRelu = prim::GetAttr[name="pw"](%self.1285)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.63, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.75, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.67, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6616.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6613.ConvReLU2d object at 0000018BE9FC8C70>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6614.Identity object at 0000018BE9FC7BF0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6615.Identity object at 0000018BE9FCADF0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1287 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6616.ConvBNRelu,
                                            %1 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu)):
                                        %relu.107 : __torch__.torch.nn.modules.linear.___torch_mangle_6615.Identity = prim::GetAttr[name="relu"](%self.1287)
                                        %bn.131 : __torch__.torch.nn.modules.linear.___torch_mangle_6614.Identity = prim::GetAttr[name="bn"](%self.1287)
                                        %conv.239 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6613.ConvReLU2d = prim::GetAttr[name="conv"](%self.1287)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.239, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.131)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.107)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6613.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 128
                                        out_channels = 768
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3E970>
                                        scale = 0.03661094605922699
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6613.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6613.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6613.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6613.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1289 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6613.ConvReLU2d,
                                                %1 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu)):
                                            %_packed_params.293 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1289)
                                            %15 : float = prim::Constant[value=0.03661094605922699](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.329 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.293, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.329)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6614.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1291 : __torch__.torch.nn.modules.linear.___torch_mangle_6614.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6615.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1293 : __torch__.torch.nn.modules.linear.___torch_mangle_6615.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6618.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6617.Conv2d object at 0000018BE9FC9E70>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1295 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6618.ConvBNRelu,
                                            %1 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu)):
                                        %conv.241 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6617.Conv2d = prim::GetAttr[name="conv"](%self.1295)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.241, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6617.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 768
                                        out_channels = 768
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 768
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3F470>
                                        scale = 0.0066626719199120998
                                        zero_point = 70
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6617.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6617.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6617.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6617.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1297 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6617.Conv2d,
                                                %1 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu)):
                                            %_packed_params.295 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1297)
                                            %15 : float = prim::Constant[value=0.0066626719199120998](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=70](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.331 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.295, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.331)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6621.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6619.Conv2d object at 0000018BE9FCB8F0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6620.Identity object at 0000018BE9FCD7F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1299 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6621.ConvBNRelu,
                                            %1 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu)):
                                        %bn.133 : __torch__.torch.nn.modules.linear.___torch_mangle_6620.Identity = prim::GetAttr[name="bn"](%self.1299)
                                        %conv.243 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6619.Conv2d = prim::GetAttr[name="conv"](%self.1299)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.243, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.133)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6619.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 768
                                        out_channels = 128
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3EBF0>
                                        scale = 0.1241278350353241
                                        zero_point = 64
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6619.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6619.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6619.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6619.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1301 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6619.Conv2d,
                                                %1 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu)):
                                            %_packed_params.297 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1301)
                                            %15 : float = prim::Constant[value=0.1241278350353241](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %17 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.297, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6620.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1303 : __torch__.torch.nn.modules.linear.___torch_mangle_6620.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6624.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6623.QFunctional object at 0000018BE9FCF770>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1305 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6624.TorchAdd,
                                            %1 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu)):
                                        %add_func : __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6623.QFunctional = prim::GetAttr[name="add_func"](%self.1305)
                                        %activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_6622.Identity = prim::GetAttr[name="activation_post_process"](%add_func)
                                        %5 : float = prim::Constant[value=0.1597774475812912](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %6 : int = prim::Constant[value=68](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %input.333 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_2.res_conn # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process)
                                        return (%input.333)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.functional_modules.___torch_mangle_6623.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_6622.Identity object at 0000018BE9FCF670>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_6622.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.1307 : __torch__.torch.nn.modules.linear.___torch_mangle_6622.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6636.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6629.ConvBNRelu object at 0000018BE9FD4A70>
                                upsample = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6630.Upsample object at 0000018BE9FD5070>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6632.ConvBNRelu object at 0000018BE9FD6670>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6635.ConvBNRelu object at 0000018BE9FD8D70>
                              }
                              methods {
                                method forward {
                                  graph(%self.1309 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6636.IRFBlock,
                                        %1 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu)):
                                    %pwl.69 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6635.ConvBNRelu = prim::GetAttr[name="pwl"](%self.1309)
                                    %dw.77 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6632.ConvBNRelu = prim::GetAttr[name="dw"](%self.1309)
                                    %upsample.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6630.Upsample = prim::GetAttr[name="upsample"](%self.1309)
                                    %pw.65 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6629.ConvBNRelu = prim::GetAttr[name="pw"](%self.1309)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.65, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%upsample.1, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%dw.77, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%pwl.69, %12)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6629.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6626.ConvReLU2d object at 0000018BE9FD1370>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6627.Identity object at 0000018BE9FD1CF0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6628.Identity object at 0000018BE9FD42F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1311 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6629.ConvBNRelu,
                                            %1 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu)):
                                        %relu.109 : __torch__.torch.nn.modules.linear.___torch_mangle_6628.Identity = prim::GetAttr[name="relu"](%self.1311)
                                        %bn.135 : __torch__.torch.nn.modules.linear.___torch_mangle_6627.Identity = prim::GetAttr[name="bn"](%self.1311)
                                        %conv.245 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6626.ConvReLU2d = prim::GetAttr[name="conv"](%self.1311)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.245, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.135)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.109)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6626.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 128
                                        out_channels = 768
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3F0F0>
                                        scale = 0.054473068565130234
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6626.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6626.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6626.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6626.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1313 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6626.ConvReLU2d,
                                                %1 : QUInt8(1, 128, 7, 7, strides=[6272, 1, 896, 128], requires_grad=0, device=cpu)):
                                            %_packed_params.299 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1313)
                                            %15 : float = prim::Constant[value=0.054473068565130234](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.335 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.299, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.335)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6627.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1315 : __torch__.torch.nn.modules.linear.___torch_mangle_6627.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6628.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1317 : __torch__.torch.nn.modules.linear.___torch_mangle_6628.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6630.Upsample {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1319 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6630.Upsample,
                                            %1 : QUInt8(1, 768, 7, 7, strides=[37632, 1, 5376, 768], requires_grad=0, device=cpu)):
                                        %2 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.upsample
                                        %3 : float = prim::Constant[value=2.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.upsample # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:3918:0
                                        %4 : float = prim::Constant[value=2.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.upsample # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:3918:0
                                        %5 : float[] = prim::ListConstruct(%3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.upsample
                                        %input.337 : QUInt8(1, 768, 14, 14, strides=[150528, 1, 10752, 768], requires_grad=0, device=cpu) = aten::upsample_nearest2d(%1, %2, %5), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.upsample # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:3918:0
                                        return (%input.337)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6632.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6631.Conv2d object at 0000018BE9FD3570>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1321 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6632.ConvBNRelu,
                                            %1 : QUInt8(1, 768, 14, 14, strides=[150528, 1, 10752, 768], requires_grad=0, device=cpu)):
                                        %conv.247 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6631.Conv2d = prim::GetAttr[name="conv"](%self.1321)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.247, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6631.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 768
                                        out_channels = 768
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 768
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3E4F0>
                                        scale = 0.013850843533873558
                                        zero_point = 60
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6631.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6631.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6631.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6631.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1323 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6631.Conv2d,
                                                %1 : QUInt8(1, 768, 14, 14, strides=[150528, 1, 10752, 768], requires_grad=0, device=cpu)):
                                            %_packed_params.301 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1323)
                                            %15 : float = prim::Constant[value=0.013850843533873558](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.339 : QUInt8(1, 768, 14, 14, strides=[150528, 1, 10752, 768], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.301, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.339)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6635.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6633.Conv2d object at 0000018BE9FD61F0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6634.Identity object at 0000018BE9FD7DF0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1325 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6635.ConvBNRelu,
                                            %1 : QUInt8(1, 768, 14, 14, strides=[150528, 1, 10752, 768], requires_grad=0, device=cpu)):
                                        %bn.137 : __torch__.torch.nn.modules.linear.___torch_mangle_6634.Identity = prim::GetAttr[name="bn"](%self.1325)
                                        %conv.249 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6633.Conv2d = prim::GetAttr[name="conv"](%self.1325)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.249, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.137)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6633.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 768
                                        out_channels = 128
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3FF70>
                                        scale = 0.2115606814622879
                                        zero_point = 64
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6633.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6633.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6633.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6633.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1327 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6633.Conv2d,
                                                %1 : QUInt8(1, 768, 14, 14, strides=[150528, 1, 10752, 768], requires_grad=0, device=cpu)):
                                            %_packed_params.303 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1327)
                                            %15 : float = prim::Constant[value=0.2115606814622879](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.341 : QUInt8(1, 128, 14, 14, strides=[25088, 1, 1792, 128], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.303, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_3.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.341)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6634.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1329 : __torch__.torch.nn.modules.linear.___torch_mangle_6634.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6647.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6640.ConvBNRelu object at 0000018BE9FDEDF0>
                                upsample = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6641.Upsample object at 0000018BE9FDD3F0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6643.ConvBNRelu object at 0000018BE9FE07F0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6646.ConvBNRelu object at 0000018BE9FE2C70>
                              }
                              methods {
                                method forward {
                                  graph(%self.1331 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_6647.IRFBlock,
                                        %1 : QUInt8(1, 128, 14, 14, strides=[25088, 1, 1792, 128], requires_grad=0, device=cpu)):
                                    %pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6646.ConvBNRelu = prim::GetAttr[name="pwl"](%self.1331)
                                    %dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6643.ConvBNRelu = prim::GetAttr[name="dw"](%self.1331)
                                    %upsample : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6641.Upsample = prim::GetAttr[name="upsample"](%self.1331)
                                    %pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6640.ConvBNRelu = prim::GetAttr[name="pw"](%self.1331)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%upsample, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%dw, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%pwl, %12)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6640.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6637.ConvReLU2d object at 0000018BE9FD98F0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6638.Identity object at 0000018BE9FDC470>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_6639.Identity object at 0000018BE9FDE0F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1333 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6640.ConvBNRelu,
                                            %1 : QUInt8(1, 128, 14, 14, strides=[25088, 1, 1792, 128], requires_grad=0, device=cpu)):
                                        %relu : __torch__.torch.nn.modules.linear.___torch_mangle_6639.Identity = prim::GetAttr[name="relu"](%self.1333)
                                        %bn.139 : __torch__.torch.nn.modules.linear.___torch_mangle_6638.Identity = prim::GetAttr[name="bn"](%self.1333)
                                        %conv.251 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6637.ConvReLU2d = prim::GetAttr[name="conv"](%self.1333)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.251, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.139)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6637.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 128
                                        out_channels = 384
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3E6F0>
                                        scale = 0.10326559841632843
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6637.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6637.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6637.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6637.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1335 : __torch__.torch.ao.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6637.ConvReLU2d,
                                                %1 : QUInt8(1, 128, 14, 14, strides=[25088, 1, 1792, 128], requires_grad=0, device=cpu)):
                                            %_packed_params.305 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1335)
                                            %15 : float = prim::Constant[value=0.10326559841632843](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.343 : QUInt8(1, 384, 14, 14, strides=[75264, 1, 5376, 384], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.305, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.pw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.pw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.343)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6638.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1337 : __torch__.torch.nn.modules.linear.___torch_mangle_6638.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6639.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1339 : __torch__.torch.nn.modules.linear.___torch_mangle_6639.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6641.Upsample {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1341 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6641.Upsample,
                                            %1 : QUInt8(1, 384, 14, 14, strides=[75264, 1, 5376, 384], requires_grad=0, device=cpu)):
                                        %2 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.upsample
                                        %3 : float = prim::Constant[value=2.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.upsample # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:3918:0
                                        %4 : float = prim::Constant[value=2.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.upsample # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:3918:0
                                        %5 : float[] = prim::ListConstruct(%3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.upsample
                                        %input.345 : QUInt8(1, 384, 28, 28, strides=[301056, 1, 10752, 384], requires_grad=0, device=cpu) = aten::upsample_nearest2d(%1, %2, %5), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.upsample # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\nn\functional.py:3918:0
                                        return (%input.345)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6643.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6642.Conv2d object at 0000018BE9FDE7F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1343 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6643.ConvBNRelu,
                                            %1 : QUInt8(1, 384, 28, 28, strides=[301056, 1, 10752, 384], requires_grad=0, device=cpu)):
                                        %conv.253 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6642.Conv2d = prim::GetAttr[name="conv"](%self.1343)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.253, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6642.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 384
                                        out_channels = 384
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 384
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3ED70>
                                        scale = 0.053558960556983948
                                        zero_point = 59
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6642.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6642.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6642.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6642.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1345 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6642.Conv2d,
                                                %1 : QUInt8(1, 384, 28, 28, strides=[301056, 1, 10752, 384], requires_grad=0, device=cpu)):
                                            %_packed_params.307 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1345)
                                            %15 : float = prim::Constant[value=0.053558960556983948](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=59](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input.347 : QUInt8(1, 384, 28, 28, strides=[301056, 1, 10752, 384], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.307, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.dw/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.dw.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input.347)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6646.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6644.Conv2d object at 0000018BE9FDF8F0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_6645.Identity object at 0000018BE9FE14F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.1347 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_6646.ConvBNRelu,
                                            %1 : QUInt8(1, 384, 28, 28, strides=[301056, 1, 10752, 384], requires_grad=0, device=cpu)):
                                        %bn : __torch__.torch.nn.modules.linear.___torch_mangle_6645.Identity = prim::GetAttr[name="bn"](%self.1347)
                                        %conv : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6644.Conv2d = prim::GetAttr[name="conv"](%self.1347)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6644.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 384
                                        out_channels = 64
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3FBF0>
                                        scale = 0.84708833694458008
                                        zero_point = 60
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6644.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6644.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                            %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                            %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                            %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                            %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                            %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                            %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                            %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                            %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                            %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                            %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                            %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                            %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                            %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                            %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                            %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6644.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6644.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                            %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                             = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.1349 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6644.Conv2d,
                                                %1 : QUInt8(1, 384, 28, 28, strides=[301056, 1, 10752, 384], requires_grad=0, device=cpu)):
                                            %_packed_params.309 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1349)
                                            %15 : float = prim::Constant[value=0.84708833694458008](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %16 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            %input : QUInt8(1, 64, 28, 28, strides=[50176, 1, 1792, 64], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.309, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.feature_extractor/__module.model.model.roi_heads.mask_head.feature_extractor.0/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.pwl/__module.model.model.roi_heads.mask_head.feature_extractor.0.fbnetv2_0_4.pwl.conv # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                            return (%input)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_6645.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.1351 : __torch__.torch.nn.modules.linear.___torch_mangle_6645.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.d2go.modeling.backbone.modules.___torch_mangle_6651.MaskRCNNConv1x1Predictor {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        mask_fcn_logits = <__torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6650.Conv2d object at 0000018BE9FE6A70>
                      }
                      methods {
                        method forward {
                          graph(%self.1353 : __torch__.d2go.modeling.backbone.modules.___torch_mangle_6651.MaskRCNNConv1x1Predictor,
                                %1 : QUInt8(1, 64, 28, 28, strides=[50176, 1, 1792, 64], requires_grad=0, device=cpu)):
                            %mask_fcn_logits : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6650.Conv2d = prim::GetAttr[name="mask_fcn_logits"](%self.1353)
                            %4 : Tensor = prim::CallMethod[name="forward"](%mask_fcn_logits, %1)
                            return (%4)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6650.Conv2d {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            in_channels = 64
                            out_channels = 18
                            kernel_size = (1, 1)
                            stride = (1, 1)
                            padding = (0, 0)
                            dilation = (1, 1)
                            transposed = False
                            output_padding = (0, 0)
                            groups = 1
                            padding_mode = zeros
                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000018BE6D3E1F0>
                            scale = 1.4873088598251343
                            zero_point = 97
                          }
                          methods {
                            method __getstate__ {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6650.Conv2d):
                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:132:17
                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                %groups : int = prim::GetAttr[name="groups"](%self)
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %scale : float = prim::GetAttr[name="scale"](%self)
                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                %training : bool = prim::GetAttr[name="training"](%self)
                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                return (%19)
                          
                            }
                            method __setstate__ {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6650.Conv2d,
                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                %48 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:169:21
                                %3 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:170:33
                                %6 : int = prim::Constant[value=1]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:171:34
                                %9 : int = prim::Constant[value=2]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:172:33
                                %12 : int = prim::Constant[value=3]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:173:28
                                %15 : int = prim::Constant[value=4]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:174:29
                                %18 : int = prim::Constant[value=5]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:175:30
                                %21 : int = prim::Constant[value=6]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:176:32
                                %24 : int = prim::Constant[value=7]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:177:36
                                %27 : int = prim::Constant[value=8]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:178:28
                                %30 : int = prim::Constant[value=9]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:179:34
                                %33 : int = prim::Constant[value=10]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:35
                                %36 : int = prim::Constant[value=11]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:46
                                %40 : int = prim::Constant[value=12]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:181:27
                                %43 : int = prim::Constant[value=13]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:182:32
                                %46 : int = prim::Constant[value=14]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:183:30
                                %4 : int = prim::TupleIndex(%state.1, %3)
                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                %7 : int = prim::TupleIndex(%state.1, %6)
                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                 = prim::SetAttr[name="stride"](%self, %13)
                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                 = prim::SetAttr[name="padding"](%self, %16)
                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                 = prim::SetAttr[name="dilation"](%self, %19)
                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                 = prim::SetAttr[name="transposed"](%self, %22)
                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                %28 : int = prim::TupleIndex(%state.1, %27)
                                 = prim::SetAttr[name="groups"](%self, %28)
                                %31 : str = prim::TupleIndex(%state.1, %30)
                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:180:8
                                %41 : float = prim::TupleIndex(%state.1, %40)
                                 = prim::SetAttr[name="scale"](%self, %41)
                                %44 : int = prim::TupleIndex(%state.1, %43)
                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                 = prim::SetAttr[name="training"](%self, %47)
                                return (%48)
                          
                            }
                            method _weight_bias {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6650.Conv2d):
                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:446:15
                                return (%2)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6650.Conv2d,
                                    %w.1 : Tensor,
                                    %b.1 : Tensor?):
                                %37 : NoneType = prim::Constant() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:437:4
                                %4 : str = prim::Constant[value="zeros"]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:32
                                %26 : int = prim::Constant[value=0]() # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:443:41
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:11
                                 = prim::If(%5) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:438:8
                                  block0():
                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:439:34
                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                    -> ()
                                  block1():
                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\conv.py:442:34
                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                    -> ()
                                return (%37)
                          
                            }
                            method forward {
                              graph(%self.1355 : __torch__.torch.ao.nn.quantized.modules.conv.___torch_mangle_6650.Conv2d,
                                    %1 : QUInt8(1, 64, 28, 28, strides=[50176, 1, 1792, 64], requires_grad=0, device=cpu)):
                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.1355)
                                %15 : float = prim::Constant[value=1.4873088598251343](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.predictor/__module.model.model.roi_heads.mask_head.predictor.mask_fcn_logits # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %16 : int = prim::Constant[value=97](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.predictor/__module.model.model.roi_heads.mask_head.predictor.mask_fcn_logits # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                %Xq : QUInt8(1, 18, 28, 28, strides=[14112, 1, 504, 18], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.predictor/__module.model.model.roi_heads.mask_head.predictor.mask_fcn_logits # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\_ops.py:442:0
                                return (%Xq)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6654.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_6653.ModuleList object at 0000018BE9FE8C70>
                      }
                      methods {
                        method forward {
                          graph(%self.1233 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6654.QuantStubNested,
                                %1 : Float(1, 112, 14, 14, strides=[21952, 196, 14, 1], requires_grad=0, device=cpu)):
                            %stubs.27 : __torch__.torch.nn.modules.container.___torch_mangle_6653.ModuleList = prim::GetAttr[name="stubs"](%self.1233)
                            %_0.69 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6652.Quantize = prim::GetAttr[name="0"](%stubs.27)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.69, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_6653.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6652.Quantize object at 0000018BE9FE8B70>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6652.Quantize {
                              parameters {
                              }
                              attributes {
                                scale = ...
                                zero_point = ...
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.1235 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6652.Quantize,
                                        %1 : Float(1, 112, 14, 14, strides=[21952, 196, 14, 1], requires_grad=0, device=cpu)):
                                    %2 : float = prim::Constant[value=0.06789860874414444](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.quant_stubs/__module.model.model.roi_heads.mask_head.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    %3 : int = prim::Constant[value=59](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.quant_stubs/__module.model.model.roi_heads.mask_head.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.quant_stubs/__module.model.model.roi_heads.mask_head.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    %input.315 : QUInt8(1, 112, 14, 14, strides=[21952, 196, 14, 1], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%1, %2, %3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.quant_stubs/__module.model.model.roi_heads.mask_head.quant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:63:0
                                    return (%input.315)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6657.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_6656.ModuleList object at 0000018BE9FE8970>
                      }
                      methods {
                        method forward {
                          graph(%self.1357 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_6657.QuantStubNested,
                                %1 : QUInt8(1, 18, 28, 28, strides=[14112, 1, 504, 18], requires_grad=0, device=cpu)):
                            %stubs : __torch__.torch.nn.modules.container.___torch_mangle_6656.ModuleList = prim::GetAttr[name="stubs"](%self.1357)
                            %_0 : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6655.DeQuantize = prim::GetAttr[name="0"](%stubs)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_6656.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.ao.nn.quantized.modules.___torch_mangle_6655.DeQuantize object at 0000018BE9FE8CF0>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6655.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.torch.ao.nn.quantized.modules.___torch_mangle_6655.DeQuantize,
                                        %1 : QUInt8(1, 18, 28, 28, strides=[14112, 1, 504, 18], requires_grad=0, device=cpu)):
                                    %pred_mask_logits : Float(1, 18, 28, 28, strides=[14112, 1, 504, 18], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.mask_head/__module.model.model.roi_heads.mask_head.dequant_stubs/__module.model.model.roi_heads.mask_head.dequant_stubs.stubs.0 # C:\Anaconda\envs\d2go_env\lib\site-packages\torch\ao\nn\quantized\modules\__init__.py:96:0
                                    return (%pred_mask_logits)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}
